{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8ed560-a9f5-4cf5-ba0c-c012f3e790e3",
   "metadata": {},
   "source": [
    "# 로컬 개발 코드\n",
    "- 로컬에서 주피터 노트북(Jupyter Notebook), 주피터 랩(JupyterLab) 또는 파이썬(Python)을 이용한다. \n",
    "- 사이킷 런(scikit-learn), 텐서플로우(tensorflow), 파이토치(pytorch)를 사용하여 딥러닝 프로그램을 개발한다.\n",
    "- 파일명: 0_local_Perspecive_NewsRec.ipynb\n",
    "\n",
    "### 로컬 개발 워크플로우(workflow)  \n",
    "- 로컬 개발 워크플로우를 다음의 4단계로 분리한다.\n",
    "\n",
    "1. 데이터 세트 준비(Data Setup)\n",
    "- 로컬 저장소에서 전처리 및 학습에 필요한 학습 데이터 세트를 준비한다.\n",
    "\n",
    "2. 데이터 전처리(Data Preprocessing)\n",
    "- 데이터 세트의 분석 및 정규화(Normalization)등의 전처리를 수행한다.\n",
    "- 데이터를 모델 학습에 사용할 수 있도록 가공한다.\n",
    "- 추론과정에서 필요한 경우, 데이터 전처리에 사용된 객체를 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "3. 학습 모델 훈련(Train Model)\n",
    "- 데이터를 훈련에 사용할 수 있도록 가공한 뒤에 학습 모델을 구성한다. \n",
    "- 학습 모델을 준비된 데이터 세트로 훈련시킨다.\n",
    "- 정확도(Accuracy)나 손실(Loss)등 학습 모델의 성능을 검증한다.\n",
    "- 학습 모델의 성능 검증 후, 학습 모델을 배포한다.\n",
    "- 배포할 학습 모델을 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "4. 추론(Inference)\n",
    "- 저장된 전처리 객체나 학습 모델 객체를 준비한다.\n",
    "- 추론에 필요한 테스트 데이터 세트를 준비한다.\n",
    "- 배포된 학습 모델을 통해 테스트 데이터에 대한 추론을 진행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29fd662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "absl-py                   2.1.0\n",
      "aiohttp                   3.9.5\n",
      "aiosignal                 1.3.1\n",
      "anyio                     4.4.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "async-timeout             4.0.3\n",
      "attrs                     23.2.0\n",
      "Babel                     2.15.0\n",
      "beautifulsoup4            4.12.3\n",
      "bertopic                  0.16.2\n",
      "bidict                    0.23.1\n",
      "bleach                    6.1.0\n",
      "Bottleneck                1.3.7\n",
      "Brotli                    1.0.9\n",
      "bs4                       0.0.2\n",
      "certifi                   2024.6.2\n",
      "cffi                      1.16.0\n",
      "chardet                   4.0.0\n",
      "charset-normalizer        2.0.4\n",
      "click                     8.1.7\n",
      "cmudict                   1.0.24\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "contourpy                 1.2.1\n",
      "cycler                    0.12.1\n",
      "Cython                    0.29.37\n",
      "debugpy                   1.8.2\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "Distance                  0.1.3\n",
      "emoji                     1.2.0\n",
      "exceptiongroup            1.2.1\n",
      "executing                 2.0.1\n",
      "faiss                     1.8.0\n",
      "fastjsonschema            2.20.0\n",
      "filelock                  3.13.1\n",
      "fonttools                 4.53.0\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.4.1\n",
      "fsspec                    2024.3.1\n",
      "future                    1.0.0\n",
      "gmpy2                     2.1.2\n",
      "grpcio                    1.64.1\n",
      "h11                       0.14.0\n",
      "hangul-jamo               1.0.1\n",
      "hdbscan                   0.8.37\n",
      "httpcore                  1.0.5\n",
      "httpx                     0.27.0\n",
      "huggingface-hub           0.23.4\n",
      "idna                      3.7\n",
      "importlib-metadata        7.0.1\n",
      "importlib_resources       6.4.0\n",
      "iniconfig                 2.0.0\n",
      "ipykernel                 6.29.4\n",
      "ipython                   8.18.1\n",
      "ipywidgets                8.1.3\n",
      "isoduration               20.11.0\n",
      "jamo                      0.4.1\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.4\n",
      "joblib                    1.4.2\n",
      "json5                     0.9.25\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.22.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.6.2\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.1\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.2.3\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.2\n",
      "jupyterlab_widgets        3.0.11\n",
      "kiwisolver                1.4.5\n",
      "kollocate                 0.0.2\n",
      "koparadigm                0.10.0\n",
      "kss                       6.0.4\n",
      "lightning-utilities       0.11.2\n",
      "llvmlite                  0.43.0\n",
      "Markdown                  3.6\n",
      "MarkupSafe                2.1.3\n",
      "matplotlib                3.9.0\n",
      "matplotlib-inline         0.1.7\n",
      "mecab-ko-dic-msvc         0.999\n",
      "mecab-ko-msvc             0.999\n",
      "mistune                   3.0.2\n",
      "mkl-fft                   1.3.8\n",
      "mkl-random                1.2.4\n",
      "mkl-service               2.4.0\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.0.5\n",
      "nbclient                  0.10.0\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.2.1\n",
      "nltk                      3.8.1\n",
      "notebook                  7.2.1\n",
      "notebook_shim             0.2.4\n",
      "numba                     0.60.0\n",
      "numexpr                   2.8.7\n",
      "numpy                     1.26.4\n",
      "overrides                 7.7.0\n",
      "packaging                 23.2\n",
      "pandas                    2.2.2\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pecab                     1.0.8\n",
      "pillow                    10.3.0\n",
      "pip                       24.0\n",
      "platformdirs              4.2.2\n",
      "plotly                    5.22.0\n",
      "pluggy                    1.5.0\n",
      "pretty-errors             1.2.25\n",
      "prometheus_client         0.20.0\n",
      "prompt_toolkit            3.0.47\n",
      "protobuf                  3.19.6\n",
      "psutil                    6.0.0\n",
      "pure-eval                 0.2.2\n",
      "pyarrow                   16.1.0\n",
      "pycparser                 2.22\n",
      "Pygments                  2.18.0\n",
      "pynndescent               0.5.13\n",
      "pyparsing                 3.1.2\n",
      "PySocks                   1.7.1\n",
      "pytest                    8.2.2\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytorch-lightning         1.2.8\n",
      "pytz                      2024.1\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.13\n",
      "PyYAML                    6.0\n",
      "pyzmq                     26.0.3\n",
      "qtconsole                 5.5.2\n",
      "QtPy                      2.4.1\n",
      "referencing               0.35.1\n",
      "regex                     2023.10.3\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.18.1\n",
      "sacremoses                0.1.1\n",
      "safetensors               0.4.2\n",
      "scikit-learn              1.4.2\n",
      "scipy                     1.13.1\n",
      "seaborn                   0.13.2\n",
      "Send2Trash                1.8.3\n",
      "sentence-transformers     2.2.2\n",
      "sentencepiece             0.2.0\n",
      "setuptools                69.5.1\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.5\n",
      "stack-data                0.6.3\n",
      "sympy                     1.12\n",
      "tenacity                  8.4.2\n",
      "tensorboard               2.17.0\n",
      "tensorboard-data-server   0.7.2\n",
      "terminado                 0.18.1\n",
      "threadpoolctl             3.5.0\n",
      "tinycss2                  1.3.0\n",
      "tokenizers                0.13.3\n",
      "tomli                     2.0.1\n",
      "torch                     2.2.0\n",
      "torchaudio                2.2.0\n",
      "torchmetrics              1.4.0\n",
      "torchvision               0.17.0\n",
      "tornado                   6.4.1\n",
      "tossi                     0.3.1\n",
      "tqdm                      4.66.4\n",
      "traitlets                 5.14.3\n",
      "transformers              4.23.0\n",
      "types-python-dateutil     2.9.0.20240316\n",
      "typing_extensions         4.11.0\n",
      "tzdata                    2023.3\n",
      "umap-learn                0.5.6\n",
      "Unidecode                 1.3.8\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.2\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.6.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "Werkzeug                  3.0.3\n",
      "wheel                     0.43.0\n",
      "Whoosh                    2.7.4\n",
      "widgetsnbextension        4.0.11\n",
      "win-inet-pton             1.1.0\n",
      "xlrd                      1.2.0\n",
      "yarl                      1.9.4\n",
      "zipp                      3.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4b2b2-b9f5-4d81-868b-fee458aa0dba",
   "metadata": {},
   "source": [
    "## 뉴스에 반하다\n",
    "- 이슈성 정보를 다루는 뉴스에서 기존 관점 다른 관점을 제공해 주어 확증 편향을 완화\n",
    "- 비판적인 사고력과 자기 객관화 능력 및 정보 분별력 등의 능력 신장에 도움을 주는 프로그램 구축을 목표로 함.\n",
    "\n",
    "### 사용할 데이터\n",
    "- (기존)매일 22시마다 기사 자동 수집 -> (변경: 고정 DB 사용) 민희진, 밀양사적제재, 북한 오물풍선, 의사 파업, 25만원 총 5개의 키워드로 각각 크롤링한 뉴스 (총 6437개)\n",
    "- json 파일(기사 데이터), npy 파일 (임베딩 데이터)\n",
    "- 문서 요약 데이터 (AI-HUB 제공)\n",
    "\n",
    "### 사용할 요소\n",
    "- 뉴스 제목, 링크, 기사본문\n",
    "- 요약모델 훈련을 위해 문서 요약 데이터 사용\n",
    "- 수집한 기사 본문 바탕으로 요약문장 뽑아내기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3e1822-3889-469c-83fc-05cbefa9ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import json\n",
    " \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import kss\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7247ba-2b2f-468e-bc04-ca64b66d73d2",
   "metadata": {},
   "source": [
    "## **1. 데이터셋 준비(Data Setup)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe3d6ae-1deb-407a-9855-7bef893c0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.zip 파일 압축 풀기\n",
    "zip_source_path = './dataset.zip'\n",
    "zip_target_path = './meta_data'\n",
    "\n",
    "extract_zip_file = zipfile.ZipFile(zip_source_path)\n",
    "extract_zip_file.extractall(zip_target_path)\n",
    " \n",
    "extract_zip_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fea1f-45d0-4c30-b641-15b63fc117e3",
   "metadata": {},
   "source": [
    "### 뉴스 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4a017f-3131-473e-8be8-146b2df2d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = './meta_data/dataset/'\n",
    "\n",
    "# 뉴스 데이터셋\n",
    "dataset='news.json'\n",
    "news_dataset=pd.read_json(my_path+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d728d91-2648-4b6d-a345-5227ec8df9a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>2526</td>\n",
       "      <td>北이 날린 '오물 풍선', 서울·경기서 90여개 발견</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/366/000...</td>\n",
       "      <td>북한이 지난달 28일 날려 보냈던 오물 풍선을 나흘 만에 다시 띄웠다고 합동참모본부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>1650</td>\n",
       "      <td>북한이 날린 ‘오물 풍선’ 경기·인천 곳곳서 발견…“피해 없어”</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/032/000...</td>\n",
       "      <td>북한이 날린 오물 풍선이 경기도와 인천에서 잇따라 발견돼 경찰과 군 당국이 수거해 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>3626</td>\n",
       "      <td>군 \"내일 또 北 '오물 풍선' 살포 가능성… 만지지 말고 신고\"</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/656/000...</td>\n",
       "      <td>북한이 최근 도발을 이어가는 가운데 우리 군은 토요일인 1일 북풍이 불 것으로 예고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>1865</td>\n",
       "      <td>軍 \"北 4차 오물 풍선 310여개\"…향후 남북 시나리오는?</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/015/000...</td>\n",
       "      <td>북한이 지난 9일 밤부터 300개가 넘는 오물 풍선을 남쪽에 띄워 보낸 것으로 확인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>6219</td>\n",
       "      <td>與이어 민주당 서울 당선인들 만나는 오세훈</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/020/000...</td>\n",
       "      <td>30일 시장공관서 회동, 보폭 넓혀여권내 “차기 대권 염두 둔 행보”여권 차기 대선...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                 title  \\\n",
       "2526   2526         北이 날린 '오물 풍선', 서울·경기서 90여개 발견   \n",
       "1650   1650   북한이 날린 ‘오물 풍선’ 경기·인천 곳곳서 발견…“피해 없어”   \n",
       "3626   3626  군 \"내일 또 北 '오물 풍선' 살포 가능성… 만지지 말고 신고\"   \n",
       "1865   1865     軍 \"北 4차 오물 풍선 310여개\"…향후 남북 시나리오는?   \n",
       "6219   6219               與이어 민주당 서울 당선인들 만나는 오세훈   \n",
       "\n",
       "                                                   link  \\\n",
       "2526  https://n.news.naver.com/mnews/article/366/000...   \n",
       "1650  https://n.news.naver.com/mnews/article/032/000...   \n",
       "3626  https://n.news.naver.com/mnews/article/656/000...   \n",
       "1865  https://n.news.naver.com/mnews/article/015/000...   \n",
       "6219  https://n.news.naver.com/mnews/article/020/000...   \n",
       "\n",
       "                                                article  \n",
       "2526  북한이 지난달 28일 날려 보냈던 오물 풍선을 나흘 만에 다시 띄웠다고 합동참모본부...  \n",
       "1650  북한이 날린 오물 풍선이 경기도와 인천에서 잇따라 발견돼 경찰과 군 당국이 수거해 ...  \n",
       "3626  북한이 최근 도발을 이어가는 가운데 우리 군은 토요일인 1일 북풍이 불 것으로 예고...  \n",
       "1865  북한이 지난 9일 밤부터 300개가 넘는 오물 풍선을 남쪽에 띄워 보낸 것으로 확인...  \n",
       "6219  30일 시장공관서 회동, 보폭 넓혀여권내 “차기 대권 염두 둔 행보”여권 차기 대선...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 뉴스 기사 예시 5개\n",
    "news_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a262b609-3d59-4862-9601-3c2df2d8db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 뉴스기사 수 , 컬럼 수)\n",
      "(6437, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"( 뉴스기사 수 , 컬럼 수)\")\n",
    "print(news_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce121e58-7a82-48ab-bfca-3bc1b54ae645",
   "metadata": {},
   "source": [
    "### 저장된 뉴스들의 요약 임베딩 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c89107-2525-4ab9-b0fb-044f9f0e60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 요약 임베딩 데이터\n",
    "dataset='summary_embedding.npy'\n",
    "summary_embedding_dataset=np.load(my_path+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbe09e20-95ea-4f8b-bba3-fe24accb7fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 뉴스 개수 ,임베딩 차원 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6437, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"( 뉴스 개수 ,임베딩 차원 )\")\n",
    "summary_embedding_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be29d176-6ab0-4fc1-b4b6-693cae19a1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.80979604e-01,  6.20539337e-02, -6.83445334e-02, -1.19693622e-01,\n",
       "        2.08823726e-01, -1.24537600e-02,  1.18500881e-01,  2.92633682e-01,\n",
       "        1.27883732e-01, -1.22530796e-01,  1.88773751e-01,  1.58757374e-01,\n",
       "        7.53097832e-02,  9.50985700e-02,  1.99547485e-02,  1.87469363e-01,\n",
       "        2.95771599e-01,  9.03890282e-02,  1.81211784e-01,  5.51250339e-01,\n",
       "        4.68128473e-02, -1.96054339e-01, -2.05385476e-01,  2.59385973e-01,\n",
       "       -2.40323737e-01, -1.36626616e-01,  4.44304973e-01, -2.42111281e-01,\n",
       "       -4.77627926e-02,  2.79585384e-02, -3.09917122e-01,  1.79996401e-01,\n",
       "        1.54761756e-02, -1.70492396e-01, -3.24941099e-01, -8.85238275e-02,\n",
       "        1.71700209e-01, -1.93334967e-02,  1.79288030e-01, -4.81512427e-01,\n",
       "        1.27589509e-01,  7.58003443e-05, -2.44617552e-01, -4.17773165e-02,\n",
       "       -1.59207672e-01,  2.16412395e-02,  2.14116201e-01,  9.37071070e-02,\n",
       "       -2.15679660e-01, -1.72768682e-01,  2.53318340e-01, -1.23410642e-01,\n",
       "       -2.44821072e-01, -3.28746915e-01, -2.58230209e-01,  1.05982825e-01,\n",
       "       -3.59924440e-03, -1.01242088e-01, -1.01576731e-01, -8.44142437e-02,\n",
       "        1.48059860e-01,  1.46052716e-02,  2.17478797e-01,  2.69541532e-01,\n",
       "        1.02762133e-05, -2.64144659e-01, -1.19165450e-01,  1.50048152e-01,\n",
       "        8.67998824e-02, -2.57185876e-01, -1.13905616e-01, -4.41240659e-03,\n",
       "        1.14259906e-01,  1.36371166e-01, -1.90132752e-01, -1.94488063e-01,\n",
       "        4.13919896e-01, -3.44066501e-01,  2.92964756e-01, -1.62649184e-01,\n",
       "        9.74547770e-03, -1.11651383e-01, -6.55310899e-02, -3.39726925e-01,\n",
       "        7.99174979e-02, -1.42821565e-01, -1.11291260e-01, -3.00508142e-01,\n",
       "        5.37751652e-02,  1.71349391e-01, -2.84691840e-01,  3.27201039e-02,\n",
       "       -2.50546962e-01,  1.70688599e-01, -2.44593665e-01,  3.17729115e-01,\n",
       "        4.02716070e-01, -1.70131773e-01, -9.65653807e-02,  2.01350719e-01,\n",
       "        1.56636849e-01,  1.92686573e-01,  2.73971826e-01,  1.20396025e-01,\n",
       "        3.65866840e-01, -1.01585582e-01,  1.60898671e-01,  1.91246435e-01,\n",
       "       -1.90956607e-01, -1.84263036e-01, -6.17366023e-02, -8.01492110e-02,\n",
       "        4.17187475e-02, -1.08386442e-01, -1.29042193e-01,  7.14366436e-02,\n",
       "       -2.84157693e-01, -1.41429156e-01, -2.41391584e-01,  1.33219749e-01,\n",
       "       -2.94684507e-02,  2.42987335e-01, -4.66544293e-02, -7.04013333e-02,\n",
       "        9.11332965e-02, -3.04981936e-02, -2.64742464e-01, -3.51791233e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_embedding_dataset[0] # 첫 번째 기사의 요약 임베딩 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149bb7f-e951-49b0-b994-6a7ce13ea8a3",
   "metadata": {},
   "source": [
    "### 저장된 뉴스들의 단락 데이터\n",
    "- index: 기사 번호\n",
    "- paragraph: 단락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f3b1393-1c41-459d-9241-14e0a142ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 기사들의 단락 데이터\n",
    "dataset='paragraph_data.json'\n",
    "paragraph_dataset=pd.read_json(my_path+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cef3e13-bd38-4f9c-ab78-96d49a1cd74b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>과거에 비해 다소 살이 빠진 듯한 방시혁 하이브 의장의 모습이 소셜미디어(sns) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>방 의장은 전날 자신의 인스타그램 계정에 진과 함께 찍은 사진을 공개하며 “성공적인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>이날 개최한 팬 이벤트는 진의 전역 후 첫 행사이자, bts의 데뷔 11주년 행사였...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>방시혁 하이브 의장이 지난달 28일 오후 무함마드 빈 자예드 알 나흐얀 아랍에미리트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>줄곧 침묵을 유지하던 방 의장은 지난달 17일 법원에 제출한 탄원서를 통해 “한 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33648</th>\n",
       "      <td>6435</td>\n",
       "      <td>이 대표는 경남 창원 민주당 경남도당에서 열린 현장 선거대책위원회에서 같은 당 김경...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33649</th>\n",
       "      <td>6435</td>\n",
       "      <td>이 대표는 전날 자신이 내놓은 ‘국민 1인당 25만원씩(총 13조원 추산) 민생회복...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33650</th>\n",
       "      <td>6435</td>\n",
       "      <td>국민의힘은 세 자녀 등록금 면제 대상은 34만명이고, 들어갈 예산은 1조4500억원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33651</th>\n",
       "      <td>6435</td>\n",
       "      <td>세 자녀 가구에 지원되는 전기요금, 도시가스, 지역난방비 감면을 두 자녀 가구로 확...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33652</th>\n",
       "      <td>6436</td>\n",
       "      <td>○…더불어민주당 경기 하남갑에 전략공천된 추미애, 코미디 프로그램에 출연, 이재명과...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33653 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                          paragraph\n",
       "0          0  과거에 비해 다소 살이 빠진 듯한 방시혁 하이브 의장의 모습이 소셜미디어(sns) ...\n",
       "1          0  방 의장은 전날 자신의 인스타그램 계정에 진과 함께 찍은 사진을 공개하며 “성공적인...\n",
       "2          0  이날 개최한 팬 이벤트는 진의 전역 후 첫 행사이자, bts의 데뷔 11주년 행사였...\n",
       "3          0  방시혁 하이브 의장이 지난달 28일 오후 무함마드 빈 자예드 알 나흐얀 아랍에미리트...\n",
       "4          0  줄곧 침묵을 유지하던 방 의장은 지난달 17일 법원에 제출한 탄원서를 통해 “한 사...\n",
       "...      ...                                                ...\n",
       "33648   6435  이 대표는 경남 창원 민주당 경남도당에서 열린 현장 선거대책위원회에서 같은 당 김경...\n",
       "33649   6435  이 대표는 전날 자신이 내놓은 ‘국민 1인당 25만원씩(총 13조원 추산) 민생회복...\n",
       "33650   6435  국민의힘은 세 자녀 등록금 면제 대상은 34만명이고, 들어갈 예산은 1조4500억원...\n",
       "33651   6435  세 자녀 가구에 지원되는 전기요금, 도시가스, 지역난방비 감면을 두 자녀 가구로 확...\n",
       "33652   6436  ○…더불어민주당 경기 하남갑에 전략공천된 추미애, 코미디 프로그램에 출연, 이재명과...\n",
       "\n",
       "[33653 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "830d81c4-4c04-4c2f-92da-7ddf99948891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 단락 총 개수 , 컬럼 수)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33653, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"( 단락 총 개수 , 컬럼 수)\")\n",
    "paragraph_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff748b7-d3b2-4493-8f67-d47f757b746b",
   "metadata": {},
   "source": [
    "### 저장된 뉴스들의 단락 임베딩 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7071fc5-8c68-40e1-b4c8-1156d7f24cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 기사들의 단락 임베딩 데이터\n",
    "dataset='paragraph_embedding.npy'\n",
    "paragraph_embedding_dataset=np.load(my_path+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87dc2330-e50f-46e2-bd25-3d537ed43761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 단락 총 개수 , 임베딩 차원 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33653, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"( 단락 총 개수 , 임베딩 차원 )\")\n",
    "paragraph_embedding_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6718ee0a-3954-48c6-959d-d54ab6f679c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.27881664e-01  1.14686206e-01 -3.37897390e-02 -1.89114317e-01\n",
      "  2.53429800e-01  5.00494204e-02  1.96555123e-01  2.81413555e-01\n",
      "  1.71784639e-01 -1.66616380e-01  2.19282180e-01  1.76256597e-01\n",
      " -7.33617367e-03  2.34767750e-01  5.44347195e-03  4.07325588e-02\n",
      "  1.38898820e-01  1.18467353e-01  3.30788307e-02  5.21330237e-01\n",
      "  1.35957694e-03 -1.89961404e-01 -1.63521573e-01  2.78955787e-01\n",
      " -2.86507934e-01 -2.54717767e-01  4.47581232e-01 -1.88536391e-01\n",
      " -8.64003524e-02  1.46690339e-01 -2.52024174e-01  2.27498025e-01\n",
      "  9.02265385e-02 -9.52593833e-02 -3.43573064e-01 -6.72127530e-02\n",
      "  1.05423577e-01  1.75513811e-02  1.22265011e-01 -4.44901586e-01\n",
      "  1.70518607e-01 -1.24860844e-02 -2.04270840e-01 -1.10439554e-01\n",
      " -1.18234046e-02  7.24388808e-02  2.57121265e-01  8.17412436e-02\n",
      " -1.05895422e-01 -1.48167774e-01  1.48221895e-01  4.64897156e-02\n",
      " -5.93772121e-02 -3.49758297e-01 -2.06938535e-01  1.65401340e-01\n",
      " -7.27411285e-02 -3.06901336e-02 -1.07786343e-01 -9.71050113e-02\n",
      "  1.97121829e-01  3.32890861e-02  1.92985997e-01  2.20371261e-01\n",
      " -1.27229886e-02 -3.56303245e-01 -9.87922251e-02  5.62584512e-02\n",
      "  1.33638933e-01 -2.01404244e-01 -9.41236019e-02  2.17463952e-02\n",
      "  1.45707324e-01  1.39304414e-01 -2.37362340e-01 -1.61136881e-01\n",
      "  3.73980194e-01 -4.02835667e-01  3.58195573e-01 -2.82543123e-01\n",
      " -4.82358336e-02 -1.95789099e-01 -1.22501515e-01 -2.48587251e-01\n",
      "  1.39765412e-01 -1.55362114e-01 -3.55676338e-02 -3.03247720e-01\n",
      "  6.18085207e-04  1.32466838e-01 -3.06282729e-01  8.85585602e-03\n",
      " -2.38801792e-01  1.40107781e-01 -2.26175487e-01  3.09051454e-01\n",
      "  3.95781696e-01 -1.41426131e-01 -1.06918842e-01  7.22622573e-02\n",
      "  6.72940984e-02  3.11411768e-01  3.60950619e-01  1.54879302e-01\n",
      "  3.00136983e-01 -1.38371333e-01  2.35705271e-01  1.63807705e-01\n",
      " -2.19902501e-01 -2.53790200e-01 -1.38265789e-01 -7.51607940e-02\n",
      "  4.27093804e-02 -1.32023260e-01 -1.90597564e-01  5.44844642e-02\n",
      " -2.11042255e-01 -1.96340814e-01 -1.63644359e-01  2.56985128e-01\n",
      " -1.84862893e-02  1.99931979e-01 -3.81284468e-02  1.44880265e-04\n",
      "  1.93769746e-02  1.16702979e-02 -2.17091024e-01  1.32574722e-01]\n"
     ]
    }
   ],
   "source": [
    "print(paragraph_embedding_dataset[0])# 첫번째 기사의 1번 단락 임베딩 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ff03a-fdaa-4fd8-ae42-6079fa2e8eb9",
   "metadata": {},
   "source": [
    "### 요약 모델 훈련을 위한 데이터셋\n",
    "- AI Hub 문서요약텍스트 데이터셋 (신문 기사 데이터셋)\n",
    "- https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe0e181-a750-40bd-b786-af7c984021cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / valid dataset\n",
    "train_dataset=pd.read_json(my_path+'train_original.json')\n",
    "valid_dataset=pd.read_json(my_path+'valid_original.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f4e8e08-da7c-4aff-9a70-3a8c49c5a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340626877', 'category': '정치', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340626896', 'category': '종합', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340626904', 'category': 'IT,과학', 'medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340627450', 'category': '사회', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340627465', 'category': '경제', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30117</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350851474', 'category': '종합', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30118</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350851925', 'category': '경제', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30119</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350854748', 'category': '종합', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350857648', 'category': '종합', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30121</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350861693', 'category': '경제', 'media_t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name        delivery_date  \\\n",
       "0      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "1      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "2      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "3      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "4      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "...          ...                  ...   \n",
       "30117  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "30118  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "30119  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "30120  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "30121  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "\n",
       "                                               documents  \n",
       "0      {'id': '340626877', 'category': '정치', 'media_t...  \n",
       "1      {'id': '340626896', 'category': '종합', 'media_t...  \n",
       "2      {'id': '340626904', 'category': 'IT,과학', 'medi...  \n",
       "3      {'id': '340627450', 'category': '사회', 'media_t...  \n",
       "4      {'id': '340627465', 'category': '경제', 'media_t...  \n",
       "...                                                  ...  \n",
       "30117  {'id': '350851474', 'category': '종합', 'media_t...  \n",
       "30118  {'id': '350851925', 'category': '경제', 'media_t...  \n",
       "30119  {'id': '350854748', 'category': '종합', 'media_t...  \n",
       "30120  {'id': '350857648', 'category': '종합', 'media_t...  \n",
       "30121  {'id': '350861693', 'category': '경제', 'media_t...  \n",
       "\n",
       "[30122 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b16a7-2b61-441e-a016-4762593b028d",
   "metadata": {},
   "source": [
    "## **2. 데이터 전처리 (Data Preprocessing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a511f6d-8edd-43f9-8a00-52d83b143813",
   "metadata": {},
   "source": [
    "### 데이터 준비 (Preparing Data)\n",
    "요약모델을 위한 데이터셋을 훈련에 사용할 수 있는 형태로 변형\n",
    "\n",
    "- 결측 데이터 삭제\n",
    "- 훈련/테스트 데이터셋을 9.5:0.5 비율로 나눔\n",
    "- 기존 데이터셋이었던 Bflysoft에서 제공한 뉴스 데이터가 비공개처리 되어 대체 데이터셋인 AI-HUB 문서 요약 데이터셋을 기존 데이터셋처럼 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7813e8b8-42d2-4211-b025-a6cb6fb2b448",
   "metadata": {},
   "source": [
    "#### 결측 데이터 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb70c753-c9cc-4901-adc0-9b521e53974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset 수:243983\n",
      "valid_dataset 수:30122\n"
     ]
    }
   ],
   "source": [
    "train_dataset=train_dataset.dropna()\n",
    "print(\"train_dataset 수:\"+str(len(train_dataset)))\n",
    "\n",
    "valid_dataset=valid_dataset.dropna()\n",
    "print(\"valid_dataset 수:\"+str(len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74946e26-6070-4e06-840f-46b11a21f54c",
   "metadata": {},
   "source": [
    "# 훈련 & 평가 데이터셋 생성\n",
    "\n",
    "훈련 데이터셋에서 0.05를 valid 데이터셋으로 사용 (https://github.com/KPFBERT/kpfbertsum/blob/main/kpfbert_summary.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d49569a0-d6fd-42dd-b789-25de1ed29845",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df=train_test_split(train_dataset, test_size=0.05)\n",
    "test_df=valid_dataset\n",
    "train_df=train_df.reset_index(drop=True)\n",
    "val_df=val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbf30642-a62c-4b3b-9f4b-4442a30bc495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 훈련 데이터 개수 , 검증 데이터 수, 테스트 데이터 수)\n",
      "(231783, 3) (12200, 3) (30122, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"( 훈련 데이터 개수 , 검증 데이터 수, 테스트 데이터 수)\")\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfef6ee-0334-4b1f-bf94-242852e97000",
   "metadata": {},
   "source": [
    "#### 기존 Bflysoft-뉴스기사 데이터셋에 맞춰 변환\n",
    "- 기존에 Bflysoft-뉴스기사 데이터셋에 맞춰 작성된 코드이나 해당 데이터셋이 비공개되어 AI-HUB 데이터셋을 변형시켜 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d6a6848-12e7-4ce0-8583-caa1eeb4ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    outs = []\n",
    "    for doc in data['documents']:\n",
    "        line = []\n",
    "        line.append(doc['media_name'])\n",
    "        line.append(doc['id'])\n",
    "        para = []\n",
    "        for sent in doc['text']:\n",
    "            for s in sent:\n",
    "                para.append(s['sentence'])\n",
    "        line.append(para)\n",
    "        line.append(doc['abstractive'][0])\n",
    "        line.append(doc['extractive'])\n",
    "        a = doc['extractive']\n",
    "        if a[0] == None or a[1] == None or a[2] == None:\n",
    "            continue\n",
    "        outs.append(line)\n",
    "\n",
    "    outs_df = pd.DataFrame(outs)\n",
    "    outs_df.columns = ['media', 'id', 'article_original', 'abstractive', 'extractive']\n",
    "    return outs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7dc11e1-523f-45f1-a8b8-577df4b8e907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전라일보</td>\n",
       "      <td>338837772</td>\n",
       "      <td>[최홍은기자l hiimnews@, ▲ 문재인 대통령이 25일 오후 청와대에서 열린 ...</td>\n",
       "      <td>문재인 대통령은 25일 “특권층의 불법적 행위와 외압에 의한 부실수사, 권력의 비호...</td>\n",
       "      <td>[2, 4, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  전라일보  338837772  [최홍은기자l hiimnews@, ▲ 문재인 대통령이 25일 오후 청와대에서 열린 ...   \n",
       "\n",
       "                                         abstractive extractive  \n",
       "0  문재인 대통령은 25일 “특권층의 불법적 행위와 외압에 의한 부실수사, 권력의 비호...  [2, 4, 6]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = preprocess_data(train_df)\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "162e65fd-fdff-4eb7-a5d8-848ee143fd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한국경제</td>\n",
       "      <td>340626877</td>\n",
       "      <td>[[ 박재원 기자 ] '대한민국 5G 홍보대사'를 자처한 문재인 대통령은 \"넓고, ...</td>\n",
       "      <td>8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...</td>\n",
       "      <td>[0, 1, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  한국경제  340626877  [[ 박재원 기자 ] '대한민국 5G 홍보대사'를 자처한 문재인 대통령은 \"넓고, ...   \n",
       "\n",
       "                                         abstractive extractive  \n",
       "0  8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...  [0, 1, 3]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = preprocess_data(test_df)\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a83ad4e7-7d14-4e1f-b5d6-8ab5bc401686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아시아경제</td>\n",
       "      <td>366155197</td>\n",
       "      <td>[김재원 국회 예결위원장과 맥주를 마시고 있다., 강기정 청와대 정무수석이 자유한국...</td>\n",
       "      <td>강기정 수석은 예결위 전체회의 참석을 위해 국회를 찾았지만 한국당 의원들은 강 수석...</td>\n",
       "      <td>[3, 6, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   media         id                                   article_original  \\\n",
       "0  아시아경제  366155197  [김재원 국회 예결위원장과 맥주를 마시고 있다., 강기정 청와대 정무수석이 자유한국...   \n",
       "\n",
       "                                         abstractive extractive  \n",
       "0  강기정 수석은 예결위 전체회의 참석을 위해 국회를 찾았지만 한국당 의원들은 강 수석...  [3, 6, 7]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = preprocess_data(val_df)\n",
    "val_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f360522-b2dc-47c3-922e-f21942a94b72",
   "metadata": {},
   "source": [
    "## **3. 학습 모델 훈련 (Train Model)**\n",
    "요약 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b846670b-2e46-4ee2-968f-b05f60bd3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27271784-7a46-4b44-af9b-d55f9f185552",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = 'jinmang2/kpfbert'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a93e4fda-936e-4360-9708-a903630aa4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 512\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c809980-a4f2-4b9c-a93f-6d1820f560e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 118\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DataLoader(\n\u001b[0;32m    113\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataset,\n\u001b[0;32m    114\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m    115\u001b[0m             num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# windows는 0으로 고정해야 에러 안난다. num_workers=2\u001b[39;00m\n\u001b[0;32m    116\u001b[0m         )\n\u001b[0;32m    117\u001b[0m data_module \u001b[38;5;241m=\u001b[39m SummDataModule(\n\u001b[1;32m--> 118\u001b[0m   \u001b[43mtrain_df\u001b[49m,\n\u001b[0;32m    119\u001b[0m   test_df,  \n\u001b[0;32m    120\u001b[0m   val_df,\n\u001b[0;32m    121\u001b[0m   tokenizer,\n\u001b[0;32m    122\u001b[0m   batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m    123\u001b[0m   max_token_len\u001b[38;5;241m=\u001b[39mMAX_TOKEN_COUNT\n\u001b[0;32m    124\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "class SummDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        data: pd.DataFrame, \n",
    "        tokenizer: BertTokenizer, \n",
    "        max_token_len: int = 512\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        tokenlist = []\n",
    "        for sent in data_row.article_original:\n",
    "            tokenlist.append(tokenizer(\n",
    "                text = sent,\n",
    "                add_special_tokens = True)) #, # Add '[CLS]' and '[SEP]'\n",
    "    \n",
    "        src = [] # 토크나이징 된 전체 문단\n",
    "        labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
    "        segs = []  #각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
    "        clss = []  #[CLS]토큰의 포지션값을 지정\n",
    "\n",
    "        odd = 0\n",
    "        for tkns in tokenlist:\n",
    "            if odd > 1 : odd = 0\n",
    "            clss = clss + [len(src)]\n",
    "            src = src + tkns['input_ids']\n",
    "            segs = segs + [odd] * len(tkns['input_ids'])\n",
    "            if tokenlist.index(tkns) in data_row.extractive :\n",
    "                labels = labels + [1]\n",
    "            else:\n",
    "                labels = labels + [0]\n",
    "            odd += 1\n",
    "        \n",
    "            #truncation\n",
    "            if len(src) == MAX_TOKEN_COUNT:\n",
    "                break\n",
    "            elif len(src) > MAX_TOKEN_COUNT:\n",
    "                src = src[:self.max_token_len - 1] + [src[-1]]\n",
    "                segs = segs[:self.max_token_len]\n",
    "                break\n",
    "    \n",
    "        #padding\n",
    "        if len(src) < MAX_TOKEN_COUNT:\n",
    "            src = src + [0]*(self.max_token_len - len(src))\n",
    "            segs = segs + [0]*(self.max_token_len - len(segs))\n",
    "            \n",
    "        if len(clss) < MAX_TOKEN_COUNT:\n",
    "            clss = clss + [-1]*(self.max_token_len - len(clss))\n",
    "        if len(labels) < MAX_TOKEN_COUNT:\n",
    "            labels = labels + [0]*(self.max_token_len - len(labels))\n",
    "\n",
    "        return dict(\n",
    "            src = torch.tensor(src),\n",
    "            segs = torch.tensor(segs),\n",
    "            clss = torch.tensor(clss),\n",
    "            labels= torch.FloatTensor(labels)\n",
    "        )\n",
    "class SummDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, test_df, val_df, tokenizer, batch_size=1, max_token_len=512):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.val_df = val_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = SummDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "        self.test_dataset = SummDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "    \n",
    "        self.val_dataset = SummDataset(\n",
    "            self.val_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
    "        )\n",
    "data_module = SummDataModule(\n",
    "  train_df,\n",
    "  test_df,  \n",
    "  val_df,\n",
    "  tokenizer,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3ed44-6b08-4a29-8bf3-e1fef57cd075",
   "metadata": {},
   "source": [
    "#### MODEL\n",
    "kpfBERT를 pretrained_bert로 불러와서 후처리 레이어를 추가하여 문장추출 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e443a18-650b-4965-a443-224df71c1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout, dim, max_len=5000):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) *\n",
    "                              -(math.log(10000.0) / dim)))\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, emb, step=None):\n",
    "        emb = emb * math.sqrt(self.dim)\n",
    "        if (step):\n",
    "            emb = emb + self.pe[:, step][:, None, :]\n",
    "\n",
    "        else:\n",
    "            emb = emb + self.pe[:, :emb.size(1)]\n",
    "        emb = self.dropout(emb)\n",
    "        return emb\n",
    "\n",
    "    def get_emb(self, emb):\n",
    "        return self.pe[:, :emb.size(1)]\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, d_ff, dropout):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadedAttention(\n",
    "            heads, d_model, dropout=dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, iter, query, inputs, mask):\n",
    "        if (iter != 0):\n",
    "            input_norm = self.layer_norm(inputs)\n",
    "        else:\n",
    "            input_norm = inputs\n",
    "\n",
    "        mask = mask.unsqueeze(1)\n",
    "        context = self.self_attn(input_norm, input_norm, input_norm,\n",
    "                                 mask=mask)\n",
    "        out = self.dropout(context) + inputs\n",
    "        return self.feed_forward(out)\n",
    "class ExtTransformerEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size=768, d_ff=2048, heads=8, dropout=0.2, num_inter_layers=2):\n",
    "        super(ExtTransformerEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_inter_layers = num_inter_layers\n",
    "        self.pos_emb = PositionalEncoding(dropout, hidden_size)\n",
    "        self.transformer_inter = nn.ModuleList(\n",
    "            [TransformerEncoderLayer(hidden_size, heads, d_ff, dropout)\n",
    "            for _ in range(num_inter_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.wo = nn.Linear(hidden_size, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, top_vecs, mask):\n",
    "        \"\"\" See :obj:`EncoderBase.forward()`\"\"\"\n",
    "\n",
    "        batch_size, n_sents = top_vecs.size(0), top_vecs.size(1)\n",
    "        pos_emb = self.pos_emb.pe[:, :n_sents]\n",
    "        x = top_vecs * mask[:, :, None].float()\n",
    "        x = x + pos_emb\n",
    "\n",
    "        for i in range(self.num_inter_layers):\n",
    "            x = self.transformer_inter[i](i, x, x, ~mask) \n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        sent_scores = self.sigmoid(self.wo(x))\n",
    "        sent_scores = sent_scores.squeeze(-1) * mask.float()\n",
    "\n",
    "        return sent_scores\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\" A two-layer Feed-Forward-Network with residual layer norm.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): the size of input for the first-layer of the FFN.\n",
    "        d_ff (int): the hidden layer size of the second-layer\n",
    "            of the FNN.\n",
    "        dropout (float): dropout probability in :math:`[0, 1)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def gelu(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        inter = self.dropout_1(self.gelu(self.w_1(self.layer_norm(x))))\n",
    "        output = self.dropout_2(self.w_2(inter))\n",
    "        return output + x\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention module from\n",
    "    \"Attention is All You Need\"\n",
    "    :cite:`DBLP:journals/corr/VaswaniSPUJGKP17`.\n",
    "\n",
    "    Similar to standard `dot` attention but uses\n",
    "    multiple attention distributions simulataneously\n",
    "    to select relevant items.\n",
    "\n",
    "    .. mermaid::\n",
    "\n",
    "       graph BT\n",
    "          A[key]\n",
    "          B[value]\n",
    "          C[query]\n",
    "          O[output]\n",
    "          subgraph Attn\n",
    "            D[Attn 1]\n",
    "            E[Attn 2]\n",
    "            F[Attn N]\n",
    "          end\n",
    "          A --> D\n",
    "          C --> D\n",
    "          A --> E\n",
    "          C --> E\n",
    "          A --> F\n",
    "          C --> F\n",
    "          D --> O\n",
    "          E --> O\n",
    "          F --> O\n",
    "          B --> O\n",
    "\n",
    "    Also includes several additional tricks.\n",
    "\n",
    "    Args:\n",
    "       head_count (int): number of parallel heads\n",
    "       model_dim (int): the dimension of keys/values/queries,\n",
    "           must be divisible by head_count\n",
    "       dropout (float): dropout parameter\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, head_count, model_dim, dropout=0.1, use_final_linear=True):\n",
    "        assert model_dim % head_count == 0\n",
    "        self.dim_per_head = model_dim // head_count\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.head_count = head_count\n",
    "\n",
    "        self.linear_keys = nn.Linear(model_dim,\n",
    "                                     head_count * self.dim_per_head)\n",
    "        self.linear_values = nn.Linear(model_dim,\n",
    "                                       head_count * self.dim_per_head)\n",
    "        self.linear_query = nn.Linear(model_dim,\n",
    "                                      head_count * self.dim_per_head)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.use_final_linear = use_final_linear\n",
    "        if (self.use_final_linear):\n",
    "            self.final_linear = nn.Linear(model_dim, model_dim)\n",
    "\n",
    "    def forward(self, key, value, query, mask=None,\n",
    "                layer_cache=None, type=None, predefined_graph_1=None):\n",
    "        \"\"\"\n",
    "        Compute the context vector and the attention vectors.\n",
    "\n",
    "        Args:\n",
    "           key (`FloatTensor`): set of `key_len`\n",
    "                key vectors `[batch, key_len, dim]`\n",
    "           value (`FloatTensor`): set of `key_len`\n",
    "                value vectors `[batch, key_len, dim]`\n",
    "           query (`FloatTensor`): set of `query_len`\n",
    "                 query vectors  `[batch, query_len, dim]`\n",
    "           mask: binary mask indicating which keys have\n",
    "                 non-zero attention `[batch, query_len, key_len]`\n",
    "        Returns:\n",
    "           (`FloatTensor`, `FloatTensor`) :\n",
    "\n",
    "           * output context vectors `[batch, query_len, dim]`\n",
    "           * one of the attention vectors `[batch, query_len, key_len]`\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = key.size(0)\n",
    "        dim_per_head = self.dim_per_head\n",
    "        head_count = self.head_count\n",
    "        key_len = key.size(1)\n",
    "        query_len = query.size(1)\n",
    "\n",
    "        def shape(x):\n",
    "            \"\"\"  projection \"\"\"\n",
    "            return x.view(batch_size, -1, head_count, dim_per_head) \\\n",
    "                .transpose(1, 2)\n",
    "\n",
    "        def unshape(x):\n",
    "            \"\"\"  compute context \"\"\"\n",
    "            return x.transpose(1, 2).contiguous() \\\n",
    "                .view(batch_size, -1, head_count * dim_per_head)\n",
    "\n",
    "        # 1) Project key, value, and query.\n",
    "        if layer_cache is not None:\n",
    "            if type == \"self\":\n",
    "                query, key, value = self.linear_query(query), \\\n",
    "                                    self.linear_keys(query), \\\n",
    "                                    self.linear_values(query)\n",
    "\n",
    "                key = shape(key)\n",
    "                value = shape(value)\n",
    "\n",
    "                if layer_cache is not None:\n",
    "                    device = key.device\n",
    "                    if layer_cache[\"self_keys\"] is not None:\n",
    "                        key = torch.cat(\n",
    "                            (layer_cache[\"self_keys\"].to(device), key),\n",
    "                            dim=2)\n",
    "                    if layer_cache[\"self_values\"] is not None:\n",
    "                        value = torch.cat(\n",
    "                            (layer_cache[\"self_values\"].to(device), value),\n",
    "                            dim=2)\n",
    "                    layer_cache[\"self_keys\"] = key\n",
    "                    layer_cache[\"self_values\"] = value\n",
    "            elif type == \"context\":\n",
    "                query = self.linear_query(query)\n",
    "                if layer_cache is not None:\n",
    "                    if layer_cache[\"memory_keys\"] is None:\n",
    "                        key, value = self.linear_keys(key), \\\n",
    "                                     self.linear_values(value)\n",
    "                        key = shape(key)\n",
    "                        value = shape(value)\n",
    "                    else:\n",
    "                        key, value = layer_cache[\"memory_keys\"], \\\n",
    "                                     layer_cache[\"memory_values\"]\n",
    "                    layer_cache[\"memory_keys\"] = key\n",
    "                    layer_cache[\"memory_values\"] = value\n",
    "                else:\n",
    "                    key, value = self.linear_keys(key), \\\n",
    "                                 self.linear_values(value)\n",
    "                    key = shape(key)\n",
    "                    value = shape(value)\n",
    "        else:\n",
    "            key = self.linear_keys(key)\n",
    "            value = self.linear_values(value)\n",
    "            query = self.linear_query(query)\n",
    "            key = shape(key)\n",
    "            value = shape(value)\n",
    "\n",
    "        query = shape(query)\n",
    "\n",
    "        key_len = key.size(2)\n",
    "        query_len = query.size(2)\n",
    "\n",
    "        # 2) Calculate and scale scores.\n",
    "        query = query / math.sqrt(dim_per_head)\n",
    "        scores = torch.matmul(query, key.transpose(2, 3))\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).expand_as(scores)\n",
    "            scores = scores.masked_fill(mask, -1e18) # how can i fix it to use fp16...\n",
    "\n",
    "        # 3) Apply attention dropout and compute context vectors.\n",
    "\n",
    "        attn = self.softmax(scores)\n",
    "\n",
    "        if (not predefined_graph_1 is None):\n",
    "            attn_masked = attn[:, -1] * predefined_graph_1\n",
    "            attn_masked = attn_masked / (torch.sum(attn_masked, 2).unsqueeze(2) + 1e-9)\n",
    "\n",
    "            attn = torch.cat([attn[:, :-1], attn_masked.unsqueeze(1)], 1)\n",
    "\n",
    "        drop_attn = self.dropout(attn)\n",
    "        if (self.use_final_linear):\n",
    "            context = unshape(torch.matmul(drop_attn, value))\n",
    "            output = self.final_linear(context)\n",
    "            return output\n",
    "        else:\n",
    "            context = torch.matmul(drop_attn, value)\n",
    "            return context\n",
    "\n",
    "class Summarizer(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.max_pos = 512\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME) #, return_dict=True)\n",
    "        self.ext_layer = ExtTransformerEncoder()\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.loss = nn.BCELoss(reduction='none')\n",
    "    \n",
    "        for p in self.ext_layer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, src, segs, clss, labels=None): #, input_ids, attention_mask, labels=None):\n",
    "        \n",
    "        mask_src = ~(src == 0) #1 - (src == 0)\n",
    "        mask_cls = ~(clss == -1) #1 - (clss == -1)\n",
    "\n",
    "        top_vec = self.bert(src, token_type_ids=segs, attention_mask=mask_src)\n",
    "        top_vec = top_vec.last_hidden_state\n",
    "        \n",
    "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n",
    "        sents_vec = sents_vec * mask_cls[:, :, None].float()\n",
    "\n",
    "        sent_scores = self.ext_layer(sents_vec, mask_cls).squeeze(-1)\n",
    "        \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.loss(sent_scores, labels)\n",
    "            \n",
    "            loss = (loss * mask_cls.float()).sum() / len(labels)\n",
    "        \n",
    "        return loss, sent_scores\n",
    "    \n",
    "    def step(self, batch):\n",
    "\n",
    "        src = batch['src']\n",
    "        if len(batch['labels']) > 0 :\n",
    "            labels = batch['labels']\n",
    "        else:\n",
    "            labels = None\n",
    "        segs = batch['segs']\n",
    "        clss = batch['clss']\n",
    "        \n",
    "        loss, sent_scores = self(src, segs, clss, labels)    \n",
    "        \n",
    "        return loss, sent_scores, labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def acc_loss(self, outputs):\n",
    "        total_loss = 0\n",
    "        hit_cnt = 0\n",
    "        for outp in outputs:\n",
    "            labels = outp['labels'].cpu()\n",
    "            predictions, idxs = outp['predictions'].cpu().sort()\n",
    "            loss = outp['loss'].cpu()\n",
    "            for label, idx in zip(labels, idxs):\n",
    "                for i in range(1,3):\n",
    "                    if label[idx[-i-1]] == 1 : \n",
    "                        hit_cnt += 1\n",
    "\n",
    "            total_loss += loss\n",
    "            \n",
    "        avg_loss = total_loss / len(outputs)\n",
    "        acc = hit_cnt / (3*len(outputs)*len(labels))\n",
    "        \n",
    "        return acc, avg_loss\n",
    "        \n",
    "    def training_epoch_end(self, outputs):\n",
    "        \n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "        \n",
    "        print('acc:', acc, 'avg_loss:', avg_loss)\n",
    "        \n",
    "        self.log('avg_train_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "        \n",
    "        print('val_acc:', acc, 'avg_val_loss:', avg_loss)\n",
    "        \n",
    "        self.log('avg_val_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        \n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "        \n",
    "        print('test_acc:', acc, 'avg_test_loss:', avg_loss)\n",
    "        \n",
    "        self.log('avg_test_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "\n",
    "        steps_per_epoch=len(train_df) // BATCH_SIZE\n",
    "        total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "        \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=steps_per_epoch,\n",
    "            num_training_steps=total_training_steps\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=dict(\n",
    "                scheduler=scheduler,\n",
    "                interval='step'\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce3f50-f879-495b-a856-11b311b01c88",
   "metadata": {},
   "source": [
    "### 모델 컴파일 및 학습 (Compile and Train Model)\n",
    "\n",
    "- Fine Tuning\n",
    "- 가장 최적의 결과를 낸 모델을 checkpoints/best-checkpoint.ckpt 로 저장\n",
    "- lightning_logs/kpfBERT_Summary/version_x/ 하위에 fine-tuning 로그가 저장됨, x는 실행순서 번호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45192d76-e02b-410a-b1c4-bff6617f924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jinmang2/kpfbert and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7bfa604-785a-4739-a303-51c086beb766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "지정된 파일을 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "#windows\n",
    "!rmdir /s /q lightning_logs\n",
    "!rmdir /s /q  checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92b7108b-2e53-4e07-a84e-2eaaaff3e4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16100), started 2 days, 22:56:35 ago. (Use '!kill 16100' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b23d146-53a8-44a7-b37d-b60c93e00f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"avg_val_loss\",\n",
    "    mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27918148-3dc3-4470-ab47-b15a165c250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"kpfBERT_Summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc17947-5d99-481d-9744-5a118d069b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='avg_val_loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03c03712-f00d-4fe8-8e4b-44d3aa6ce6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    "    gpus=0,\n",
    "    #progress_bar_refresh_rate=30\n",
    "#     precision=16, #소스 수정 또는 패키지 재설치 필요... 런타임 에러.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb39a907-c8a9-4dde-9916-78c007a09712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyj_0\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name      | Type                  | Params\n",
      "----------------------------------------------------\n",
      "0 | bert      | BertModel             | 114 M \n",
      "1 | ext_layer | ExtTransformerEncoder | 11.0 M\n",
      "2 | loss      | BCELoss               | 0     \n",
      "----------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "500.230   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.16666666666666666 avg_val_loss: tensor(24.4402)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6557e26358a6475e9ddd793f28cf57a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyj_0\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\utilities\\distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0, global step 1133: avg_val_loss reached 24.44023 (best 24.44023), saving model to \"checkpoints\\best-checkpoint.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46891ece-23e9-422a-8b44-c44003404d9b",
   "metadata": {},
   "source": [
    "### 모델 평가 (Evaluate Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de7f1aef-e304-463c-9b03-4a4bd4aff754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b99e4f1fdb74c138d9243dbc3d84254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:916\u001b[0m, in \u001b[0;36mTrainer.test\u001b[1;34m(self, model, test_dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    914\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__test_given_model(model, test_dataloaders)\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 916\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__test_using_best_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_running_stage(\u001b[38;5;28;01mNone\u001b[39;00m, model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:957\u001b[0m, in \u001b[0;36mTrainer.__test_using_best_weights\u001b[1;34m(self, ckpt_path, test_dataloaders)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;66;03m# run tests\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtested_ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path\n\u001b[1;32m--> 957\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;66;03m# teardown\u001b[39;00m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_function_implemented(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteardown\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:499\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch()\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_dispatch()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:540\u001b[0m, in \u001b[0;36mTrainer.dispatch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdispatch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting:\n\u001b[1;32m--> 540\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_testing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstart_predicting(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py:76\u001b[0m, in \u001b[0;36mAccelerator.start_testing\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_testing\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer):\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_testing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py:118\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_testing\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_testing\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrainer\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# double dispatch to initiate the test loop\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:787\u001b[0m, in \u001b[0;36mTrainer.run_test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;66;03m# only load test dataloader for testing\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;66;03m# self.reset_test_dataloader(ref_model)\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_test_evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 787\u001b[0m     eval_loop_results, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_loop_results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:726\u001b[0m, in \u001b[0;36mTrainer.run_evaluation\u001b[1;34m(self, max_batches, on_epoch)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_step_and_end\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 726\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    727\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\u001b[38;5;241m.\u001b[39mevaluation_step_end(output)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# hook + store predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\evaluation_loop.py:162\u001b[0m, in \u001b[0;36mEvaluationLoop.evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    160\u001b[0m     model_ref\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 162\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     model_ref\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py:195\u001b[0m, in \u001b[0;36mAccelerator.test_step\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    192\u001b[0m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mtest_step_context(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_type_plugin\u001b[38;5;241m.\u001b[39mtest_step_context():\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py:134\u001b[0m, in \u001b[0;36mTrainingTypePlugin.test_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mtest_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[29], line 349\u001b[0m, in \u001b[0;36mSummarizer.test_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m--> 349\u001b[0m     loss, sent_scores, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m: sent_scores, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels}\n",
      "Cell \u001b[1;32mIn[29], line 329\u001b[0m, in \u001b[0;36mSummarizer.step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    326\u001b[0m segs \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    327\u001b[0m clss \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 329\u001b[0m loss, sent_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, sent_scores, labels\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[29], line 303\u001b[0m, in \u001b[0;36mSummarizer.forward\u001b[1;34m(self, src, segs, clss, labels)\u001b[0m\n\u001b[0;32m    300\u001b[0m mask_src \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m(src \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m#1 - (src == 0)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m mask_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m(clss \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#1 - (clss == -1)\u001b[39;00m\n\u001b[1;32m--> 303\u001b[0m top_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_src\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m top_vec \u001b[38;5;241m=\u001b[39m top_vec\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m    306\u001b[0m sents_vec \u001b[38;5;241m=\u001b[39m top_vec[torch\u001b[38;5;241m.\u001b[39marange(top_vec\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), clss]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1005\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1007\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1008\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1009\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1027\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    594\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    595\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    596\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 603\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:489\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    479\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:419\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    411\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    418\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 419\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    429\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:347\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    344\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1856\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1860\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ba85f-4824-41f4-af85-03c8493513a7",
   "metadata": {},
   "source": [
    "## **4. 추론 (Inference)**\n",
    "\n",
    "1. 훈련한 요약 모델을 바탕으로 테스트 뉴스 데이터의 요약본 추출 및 임베딩\n",
    "3. 피어슨 상관관계를 이용하여 기존 뉴스 요약 임베딩 데이터와 비교 (threshold=0.55)\n",
    "4. 높은 유사도를 가진 뉴스 데이터(최대 100개)를 추출\n",
    "5. 테스트 뉴스의 단락 데이터 생성 및 임베딩\n",
    "6. 저장된 단락 임베딩 데이터와 테스트 뉴스의 단락 데이터를 이용하여 BERTopic으로 클러스터링 진행\n",
    "7. 클러스터링 결과 바탕으로 다른 뉴스 3개 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d2d22-653b-4bca-8172-3d12961413c3",
   "metadata": {},
   "source": [
    "##### 테스트 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72b9ada3-f20c-460c-ac4c-f9844ae0c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.zip 파일을 dataset 폴더에 압축을 풀어준다.\n",
    "zip_source_path = './test_dataset.zip'\n",
    "zip_target_path = './meta_data'\n",
    "\n",
    "extract_zip_file = zipfile.ZipFile(zip_source_path)\n",
    "extract_zip_file.extractall(zip_target_path)\n",
    " \n",
    "extract_zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9b1e920-eddc-45bc-b888-e058ea92b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path='./meta_data/test_dataset/'\n",
    "\n",
    "test_name='test.json'\n",
    "with open(my_path+test_name, encoding='utf8') as f:\n",
    "    test_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aa736cf-1947-4608-be02-7f540b526d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_article=test_dataset['article']\n",
    "target_link=test_dataset['link']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573bf4d-647e-46e2-a025-211831a4cf58",
   "metadata": {},
   "source": [
    "#### 테스트 뉴스의 본문 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c315201-3b4f-49bf-939a-663e21f26a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련법안 당론 채택 예고더불어민주당 이재명 대표가 민생회복지원금과 관련해 고수해오던 ‘보편 지원’ 주장을 내려놨다. 정부여당을 향해 “차등 지원도 수용하겠다”며 이른 시일 내 협의하자고 제안한 것이다. 하지만 여당은 ‘차등 지원’을 전제로 하더라도 여전히 민생회복지원금 자체에 부정적인 모습이다. 민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금 제도 시행을 촉구해왔다.이 대표는 29일 당 최고위원회의에서 “민생회복지원금은 소득 지원 효과도 있지만 지역·지방 소비를 늘려서 경제를 활성화하는 경제 정책이다. 반드시 지원해야 한다”며 “골목경제가 살아나면 정부여당 지지율도 올라가고 좋지 않냐”고 말했다.끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열린 최고위원회의에서 윤석열 대통령과 이종섭 전 국방부 장관의 통화 사실을 보도한 자료를 보며 정청래 최고위원과 대화하고 있다. 남제현 선임기자이 대표는 윤석열 대통령과 정부여당을 향해 “우리가 지원금을 반드시 (전 국민에게) 똑같이 지급하라는 주장을 더 이상 하지 않겠다”며 “우리가 지향하는 가치는 보편 지원에 있긴 하지만 굳이 어렵다면 차등 지원도 수용하겠다”고 했다. 그러면서 고소득층 대상 매칭 지원 등 구체적 방안도 제시했다. 이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫기 때문”이라며 “우리가 양보할 테니 경기도 살리고 민생도 살리는 정책을 수용해주시고, 구체적 내용은 신속하게 만나서 협의하면 좋겠다”고 했다.이번 제안은 이 대표의 ‘실용 정치’ 행보의 일환으로 해석된다. 연금개혁안에 이어 민생 관련 사안에 대한 책임정당 모습을 선점하기 위한 포석이기도 하다. 민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시 한 번 양보한 안을 냈다”며 “민생과 경제를 책임지는 대통령과 정부여당의 답이 있을 것”이라고 말했다. 이 대표는 여야가 연금개혁과 관련해 이견을 보이던 소득대체율과 관련해 여당안인 ‘44%안’을 수용하겠단 뜻을 밝히며 연금개혁 처리를 압박했지만, 대통령실과 여당이 협상에 응하지 않으면서 21대 국회 임기 내 연금개혁 처리가 불발된 터다.민주당은 30일 22대 국회 첫 의원총회를 열고 민생회복지원금 지급을 포함한 민생위기특별조치법을 당론으로 채택한 뒤 발의할 예정이다.끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열린 기자간담회에서 야당이 단독 처리한 5개 법안 중 세월호지원법을 제외한 4개 법안에 대통령의 재의요구권을 건의하겠다고 밝히고 있다. 남제현 선임기자다만 여당에선 이 대표 제안에 대해 부정적 기류가 여전히 강한 모습이다. 국민의힘 추경호 원내대표는 이날 기자간담회에서 이 대표 제안과 관련해 “민생회복지원금 관련해서는 입장을 여러 차례 말씀드렸다. 그걸로 대신하겠다”고 답했다. 국민의힘은 최근 민주당 진성준 정책위의장이 선별 지원 협의 가능성을 언급한 데 대해 “추경으로 빚내서 현금 지원하겠다는 발상은 결코 해결책이 될 수 없다”고 비판한 바 있다.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d809526-48a6-418d-9654-f45d681a899a",
   "metadata": {},
   "source": [
    "### 요약모델 이용해서 테스트 뉴스의 요약본 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43c0789e-380b-46e3-b1e3-d793a146c668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jinmang2/kpfbert and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 훈련된 요약 모델 로드\n",
    "trained_model = Summarizer.load_from_checkpoint(\n",
    "    'checkpoints/best-checkpoint.ckpt',\n",
    "    strict=False\n",
    ")\n",
    "trained_model.eval()\n",
    "trained_model.freeze()\n",
    "\n",
    "# 문장 분리 함수\n",
    "def data_process(text):\n",
    "    # 문장 분리 하고,\n",
    "    sents = kss.split_sentences(text)\n",
    "\n",
    "    # 데이터 가공하고,\n",
    "    tokenlist = []\n",
    "    for sent in sents:\n",
    "        tokenlist.append(tokenizer(\n",
    "            text=sent,\n",
    "            add_special_tokens=True))  # , # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "    src = []  # 토크나이징 된 전체 문단\n",
    "    labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
    "    segs = []  # 각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
    "    clss = []  # [CLS]토큰의 포지션값을 지정\n",
    "\n",
    "    odd = 0\n",
    "\n",
    "    for tkns in tokenlist:\n",
    "\n",
    "        if odd > 1:\n",
    "            odd = 0\n",
    "        clss = clss + [len(src)]\n",
    "        src = src + tkns['input_ids']\n",
    "        segs = segs + [odd] * len(tkns['input_ids'])\n",
    "        odd += 1\n",
    "\n",
    "        # truncation\n",
    "        if len(src) == MAX_TOKEN_COUNT:\n",
    "            break\n",
    "        elif len(src) > MAX_TOKEN_COUNT:\n",
    "            src = src[:MAX_TOKEN_COUNT - 1] + [src[-1]]\n",
    "            segs = segs[:MAX_TOKEN_COUNT]\n",
    "            break\n",
    "\n",
    "    # padding\n",
    "    if len(src) < MAX_TOKEN_COUNT:\n",
    "        src = src + [0]*(MAX_TOKEN_COUNT - len(src))\n",
    "        segs = segs + [0]*(MAX_TOKEN_COUNT - len(segs))\n",
    "\n",
    "    if len(clss) < MAX_TOKEN_COUNT:\n",
    "        clss = clss + [-1]*(MAX_TOKEN_COUNT - len(clss))\n",
    "\n",
    "    return dict(\n",
    "        sents=sents,  # 정답 출력을 위해...\n",
    "        src=torch.tensor(src),\n",
    "        segs=torch.tensor(segs),\n",
    "        clss=torch.tensor(clss),\n",
    "    )\n",
    "\n",
    "# 요약본 추출 함수\n",
    "def summarize_test(text):\n",
    "    data = data_process(text.replace('\\n', ''))\n",
    "\n",
    "    # trained_model에 넣어 결과값 반환\n",
    "    _, rtn = trained_model(data['src'].unsqueeze(\n",
    "        0), data['segs'].unsqueeze(0), data['clss'].unsqueeze(0))\n",
    "    rtn = rtn.squeeze()\n",
    "\n",
    "    # 예측 결과값을 받기 위한 프로세스\n",
    "    rtn_sort, idx = rtn.sort(descending=True)\n",
    "\n",
    "    rtn_sort = rtn_sort.tolist()\n",
    "    idx = idx.tolist()\n",
    "\n",
    "    end_idx = rtn_sort.index(0)\n",
    "\n",
    "    rtn_sort = rtn_sort[:end_idx]\n",
    "    idx = idx[:end_idx]\n",
    "\n",
    "    if len(idx) > 3:\n",
    "        rslt = idx[:3]\n",
    "    else:\n",
    "        rslt = idx\n",
    "\n",
    "    summ = []\n",
    "    for i, r in enumerate(rslt):\n",
    "        summ.append(data['sents'][r])\n",
    "\n",
    "    return summ\n",
    "\n",
    "# 요약본 결과 반환\n",
    "def summarize_article(target_article):\n",
    "    target_summary = summarize_test(target_article)\n",
    "    return target_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a830588-8981-48ce-9090-3085b48686be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: Oh! You have mecab in your environment. Kss will take this as a backend! :D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_summary=summarize_article(target_article)\n",
    "target_summary=\" \".join(target_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17f66461-d724-4949-8c4a-2b3feac1787e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정부여당을 향해 “차등 지원도 수용하겠다”며 이른 시일 내 협의하자고 제안한 것이다. 당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련법안 당론 채택 예고더불어민주당 이재명 대표가 민생회복지원금과 관련해 고수해오던 ‘보편 지원’ 주장을 내려놨다. 하지만 여당은 ‘차등 지원’을 전제로 하더라도 여전히 민생회복지원금 자체에 부정적인 모습이다.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7bf1b1-52d8-4ed1-a603-c48f62229000",
   "metadata": {},
   "source": [
    "### 추출한 요약모델 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42161209-4e8a-4c80-b546-be22aaf65126",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('bongsoo/kpf-sbert-128d-v1')  # 임베딩 모델\n",
    "model.max_seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1af141a-92a7-4bf1-adc3-7b33e81f9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_summary_embedding = model.encode(target_summary,normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f172ff5f-9e7f-48ff-a4c1-b1935580eef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_summary_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43486f44-c560-4690-9d59-2a170ff6b20a",
   "metadata": {},
   "source": [
    "### 테스트 요약 임베딩과 수집 기사 요약 임베딩 유사도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3804283-f46a-4957-954e-2a468cc1c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피어슨 상관계수 구하기\n",
    "def pearson_similarity(a, b):\n",
    "    return np.dot((a-np.mean(a)), (b-np.mean(b)))/((np.linalg.norm(a-np.mean(a)))*(np.linalg.norm(b-np.mean(b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00754be7-6bcd-4114-a2bf-4e8d1a5fefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피어슨 상관계수 기반으로 계산\n",
    "threshold = 0.55  # 최소 유사도 threshold\n",
    "similar_list = []\n",
    "for i in range(len(summary_embedding_dataset)):\n",
    "    similarity = pearson_similarity(target_summary_embedding, summary_embedding_dataset[i])\n",
    "\n",
    "    if similarity > threshold:\n",
    "        similar_list.append((similarity, i)) # threshold 이상이면 유사한 기사 리스트에 추가\n",
    "\n",
    "# 유사도 기준 내림차순 정렬\n",
    "sorted_similar_list = sorted(similar_list, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# 100개 이상이면 100개만 추려서 반환\n",
    "if len(similar_list) > 100:\n",
    "    similar_index_list=[item[1] for item in sorted_similar_list[:100]]\n",
    "\n",
    "# 100개 이하면 모두 반환\n",
    "else:\n",
    "    similar_index_list=[item[1] for item in sorted_similar_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2123b84-08ea-4116-99a1-58d138a6ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5523, 5532, 5525, 5544, 5545, 5530, 5751, 5540, 5542, 5992, 5619, 6280, 5943, 5849, 5527, 6293, 6048, 5807, 5538, 5750, 5990, 6120, 5938, 5721, 5533, 5675, 5594, 6315, 3328, 434, 6099, 6246, 5732, 5976, 5697, 5801, 5664, 6376, 3435, 6124, 5554, 6140]\n"
     ]
    }
   ],
   "source": [
    "print(similar_index_list) # 유사한 기사들의 index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d41dd5-41c5-4920-9cd0-8c9f559fb79c",
   "metadata": {},
   "source": [
    "### 테스트 기사의 단락 생성\n",
    "- 1 단락 = 3 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f2ac48c-62dd-4f3c-a21d-5d5be341790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_paragraphs(article, sentences_per_paragraph=3):\n",
    "    sentences = kss.split_sentences(article)\n",
    "    paragraphs = []\n",
    "    paragraph = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 20:\n",
    "            # 보통 한 줄에 20자 정도 넘어가야 유의미한 정보가 포함된 문장임\n",
    "            paragraph.append(sentence)\n",
    "        if len(paragraph) == sentences_per_paragraph:  # 3줄 이상이면\n",
    "            paragraphs.append(\" \".join(paragraph))  # 3줄을 하나로 합치기\n",
    "            paragraph = []\n",
    "\n",
    "        # 남아있는 문장들 중 20자가 넘어가면 단락으로 추가\n",
    "    if paragraph and len(paragraph) > 20:\n",
    "        paragraphs.append(\" \".join(paragraph))\n",
    "\n",
    "    return paragraphs  # 단락 데이터 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "471ad700-94a5-4393-a7e3-55bb7431e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_paragraphs=split_into_paragraphs(target_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50f668ea-7a21-4c3c-9469-f9e61ebc5824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련법안 당론 채택 예고더불어민주당 이재명 대표가 민생회복지원금과 관련해 고수해오던 ‘보편 지원’ 주장을 내려놨다. 정부여당을 향해 “차등 지원도 수용하겠다”며 이른 시일 내 협의하자고 제안한 것이다. 하지만 여당은 ‘차등 지원’을 전제로 하더라도 여전히 민생회복지원금 자체에 부정적인 모습이다.',\n",
       " '민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금 제도 시행을 촉구해왔다. 이 대표는 29일 당 최고위원회의에서 “민생회복지원금은 소득 지원 효과도 있지만 지역·지방 소비를 늘려서 경제를 활성화하는 경제 정책이다. 반드시 지원해야 한다”며 “골목경제가 살아나면 정부여당 지지율도 올라가고 좋지 않냐”고 말했다.',\n",
       " '끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열린 최고위원회의에서 윤석열 대통령과 이종섭 전 국방부 장관의 통화 사실을 보도한 자료를 보며 정청래 최고위원과 대화하고 있다. 남제현 선임기자이 대표는 윤석열 대통령과 정부여당을 향해 “우리가 지원금을 반드시 (전 국민에게) 똑같이 지급하라는 주장을 더 이상 하지 않겠다”며 “우리가 지향하는 가치는 보편 지원에 있긴 하지만 굳이 어렵다면 차등 지원도 수용하겠다”고 했다. 그러면서 고소득층 대상 매칭 지원 등 구체적 방안도 제시했다.',\n",
       " '이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫기 때문”이라며 “우리가 양보할 테니 경기도 살리고 민생도 살리는 정책을 수용해주시고, 구체적 내용은 신속하게 만나서 협의하면 좋겠다”고 했다. 이번 제안은 이 대표의 ‘실용 정치’ 행보의 일환으로 해석된다. 연금개혁안에 이어 민생 관련 사안에 대한 책임정당 모습을 선점하기 위한 포석이기도 하다.',\n",
       " '민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시 한 번 양보한 안을 냈다”며 “민생과 경제를 책임지는 대통령과 정부여당의 답이 있을 것”이라고 말했다. 이 대표는 여야가 연금개혁과 관련해 이견을 보이던 소득대체율과 관련해 여당안인 ‘44%안’을 수용하겠단 뜻을 밝히며 연금개혁 처리를 압박했지만, 대통령실과 여당이 협상에 응하지 않으면서 21대 국회 임기 내 연금개혁 처리가 불발된 터다. 민주당은 30일 22대 국회 첫 의원총회를 열고 민생회복지원금 지급을 포함한 민생위기특별조치법을 당론으로 채택한 뒤 발의할 예정이다.',\n",
       " '끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열린 기자간담회에서 야당이 단독 처리한 5개 법안 중 세월호지원법을 제외한 4개 법안에 대통령의 재의요구권을 건의하겠다고 밝히고 있다. 남제현 선임기자다만 여당에선 이 대표 제안에 대해 부정적 기류가 여전히 강한 모습이다. 국민의힘 추경호 원내대표는 이날 기자간담회에서 이 대표 제안과 관련해 “민생회복지원금 관련해서는 입장을 여러 차례 말씀드렸다. 그걸로 대신하겠다”고 답했다.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34448faf-b5cc-441f-b1c3-d093873670e4",
   "metadata": {},
   "source": [
    "#### pandas 형식으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46633ccb-f976-4cec-a009-87f000483d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_paragraph_data = []\n",
    "for data in target_paragraphs:\n",
    "    target_paragraph_data.append([-1]+[data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0356e419-3064-48af-9f8b-a95b508d2fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1,\n",
       "  '당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련법안 당론 채택 예고더불어민주당 이재명 대표가 민생회복지원금과 관련해 고수해오던 ‘보편 지원’ 주장을 내려놨다. 정부여당을 향해 “차등 지원도 수용하겠다”며 이른 시일 내 협의하자고 제안한 것이다. 하지만 여당은 ‘차등 지원’을 전제로 하더라도 여전히 민생회복지원금 자체에 부정적인 모습이다.'],\n",
       " [-1,\n",
       "  '민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금 제도 시행을 촉구해왔다. 이 대표는 29일 당 최고위원회의에서 “민생회복지원금은 소득 지원 효과도 있지만 지역·지방 소비를 늘려서 경제를 활성화하는 경제 정책이다. 반드시 지원해야 한다”며 “골목경제가 살아나면 정부여당 지지율도 올라가고 좋지 않냐”고 말했다.'],\n",
       " [-1,\n",
       "  '끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열린 최고위원회의에서 윤석열 대통령과 이종섭 전 국방부 장관의 통화 사실을 보도한 자료를 보며 정청래 최고위원과 대화하고 있다. 남제현 선임기자이 대표는 윤석열 대통령과 정부여당을 향해 “우리가 지원금을 반드시 (전 국민에게) 똑같이 지급하라는 주장을 더 이상 하지 않겠다”며 “우리가 지향하는 가치는 보편 지원에 있긴 하지만 굳이 어렵다면 차등 지원도 수용하겠다”고 했다. 그러면서 고소득층 대상 매칭 지원 등 구체적 방안도 제시했다.'],\n",
       " [-1,\n",
       "  '이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫기 때문”이라며 “우리가 양보할 테니 경기도 살리고 민생도 살리는 정책을 수용해주시고, 구체적 내용은 신속하게 만나서 협의하면 좋겠다”고 했다. 이번 제안은 이 대표의 ‘실용 정치’ 행보의 일환으로 해석된다. 연금개혁안에 이어 민생 관련 사안에 대한 책임정당 모습을 선점하기 위한 포석이기도 하다.'],\n",
       " [-1,\n",
       "  '민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시 한 번 양보한 안을 냈다”며 “민생과 경제를 책임지는 대통령과 정부여당의 답이 있을 것”이라고 말했다. 이 대표는 여야가 연금개혁과 관련해 이견을 보이던 소득대체율과 관련해 여당안인 ‘44%안’을 수용하겠단 뜻을 밝히며 연금개혁 처리를 압박했지만, 대통령실과 여당이 협상에 응하지 않으면서 21대 국회 임기 내 연금개혁 처리가 불발된 터다. 민주당은 30일 22대 국회 첫 의원총회를 열고 민생회복지원금 지급을 포함한 민생위기특별조치법을 당론으로 채택한 뒤 발의할 예정이다.'],\n",
       " [-1,\n",
       "  '끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열린 기자간담회에서 야당이 단독 처리한 5개 법안 중 세월호지원법을 제외한 4개 법안에 대통령의 재의요구권을 건의하겠다고 밝히고 있다. 남제현 선임기자다만 여당에선 이 대표 제안에 대해 부정적 기류가 여전히 강한 모습이다. 국민의힘 추경호 원내대표는 이날 기자간담회에서 이 대표 제안과 관련해 “민생회복지원금 관련해서는 입장을 여러 차례 말씀드렸다. 그걸로 대신하겠다”고 답했다.']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_paragraph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cc3ebd5-b135-41c1-9cc4-9dba8e315626",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_paragraph_data = pd.DataFrame(data=target_paragraph_data, columns=['index', 'paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbcc6140-6f19-4683-bc3d-0de412081819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          paragraph\n",
       "0     -1  당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련...\n",
       "1     -1  민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금...\n",
       "2     -1  끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열...\n",
       "3     -1  이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫...\n",
       "4     -1  민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시...\n",
       "5     -1  끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_paragraph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3f235-0f9a-459a-b1e4-77e2e83d332f",
   "metadata": {},
   "source": [
    "#### 위에서 구한 유사한 기사 인덱스를 이용해서 유사한 기사 데이터만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc2cec1d-04c9-4a16-9b4b-ddb1b38e8521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>과거에 비해 다소 살이 빠진 듯한 방시혁 하이브 의장의 모습이 소셜미디어(sns) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>방 의장은 전날 자신의 인스타그램 계정에 진과 함께 찍은 사진을 공개하며 “성공적인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>이날 개최한 팬 이벤트는 진의 전역 후 첫 행사이자, bts의 데뷔 11주년 행사였...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>방시혁 하이브 의장이 지난달 28일 오후 무함마드 빈 자예드 알 나흐얀 아랍에미리트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>줄곧 침묵을 유지하던 방 의장은 지난달 17일 법원에 제출한 탄원서를 통해 “한 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33648</th>\n",
       "      <td>6435</td>\n",
       "      <td>이 대표는 경남 창원 민주당 경남도당에서 열린 현장 선거대책위원회에서 같은 당 김경...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33649</th>\n",
       "      <td>6435</td>\n",
       "      <td>이 대표는 전날 자신이 내놓은 ‘국민 1인당 25만원씩(총 13조원 추산) 민생회복...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33650</th>\n",
       "      <td>6435</td>\n",
       "      <td>국민의힘은 세 자녀 등록금 면제 대상은 34만명이고, 들어갈 예산은 1조4500억원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33651</th>\n",
       "      <td>6435</td>\n",
       "      <td>세 자녀 가구에 지원되는 전기요금, 도시가스, 지역난방비 감면을 두 자녀 가구로 확...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33652</th>\n",
       "      <td>6436</td>\n",
       "      <td>○…더불어민주당 경기 하남갑에 전략공천된 추미애, 코미디 프로그램에 출연, 이재명과...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33653 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                          paragraph\n",
       "0          0  과거에 비해 다소 살이 빠진 듯한 방시혁 하이브 의장의 모습이 소셜미디어(sns) ...\n",
       "1          0  방 의장은 전날 자신의 인스타그램 계정에 진과 함께 찍은 사진을 공개하며 “성공적인...\n",
       "2          0  이날 개최한 팬 이벤트는 진의 전역 후 첫 행사이자, bts의 데뷔 11주년 행사였...\n",
       "3          0  방시혁 하이브 의장이 지난달 28일 오후 무함마드 빈 자예드 알 나흐얀 아랍에미리트...\n",
       "4          0  줄곧 침묵을 유지하던 방 의장은 지난달 17일 법원에 제출한 탄원서를 통해 “한 사...\n",
       "...      ...                                                ...\n",
       "33648   6435  이 대표는 경남 창원 민주당 경남도당에서 열린 현장 선거대책위원회에서 같은 당 김경...\n",
       "33649   6435  이 대표는 전날 자신이 내놓은 ‘국민 1인당 25만원씩(총 13조원 추산) 민생회복...\n",
       "33650   6435  국민의힘은 세 자녀 등록금 면제 대상은 34만명이고, 들어갈 예산은 1조4500억원...\n",
       "33651   6435  세 자녀 가구에 지원되는 전기요금, 도시가스, 지역난방비 감면을 두 자녀 가구로 확...\n",
       "33652   6436  ○…더불어민주당 경기 하남갑에 전략공천된 추미애, 코미디 프로그램에 출연, 이재명과...\n",
       "\n",
       "[33653 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e04d8eb-ce6c-4690-b64b-0c231b18f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_embedding_dataset=paragraph_embedding_dataset[paragraph_dataset['index'].isin(similar_index_list)] \n",
    "paragraph_dataset=paragraph_dataset[paragraph_dataset['index'].isin(similar_index_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62c21c7d-ac3c-47f9-abc8-532d92b36531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>434</td>\n",
       "      <td>하이브와 경영권 분쟁 중인 민희진 어도어 대표가 자신을 응원해주는 뉴진스 팬덤 ‘버...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>434</td>\n",
       "      <td>아울러 “이 감사함을 다 어떻게 표현해야 할지 모르겠다. 그분들 덕분에 이상한 선택...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>434</td>\n",
       "      <td>기자회견 말미에는 “변호사 수임료를 내서 지금은 현금이 없는데 100억원 이상은 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>434</td>\n",
       "      <td>하이브는 가처분 인용 후 밝힌 입장대로 어도어 임시 주주총회에서 민 대표 해임에 대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>434</td>\n",
       "      <td>민 대표 측 인사인 기존 어도어 사내이사 신모 부대표와 김모 이사는 해임했다. 이로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33208</th>\n",
       "      <td>6376</td>\n",
       "      <td>이 대표는 윤 대통령과 전화통화를 나눈 지난 19일 자신의 유튜브로 중계한 ‘당원과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33209</th>\n",
       "      <td>6376</td>\n",
       "      <td>최상목 경제부총리 겸 기획재정부 장관도 18일(현지시간) 제2차 주요 20개국(g2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33210</th>\n",
       "      <td>6376</td>\n",
       "      <td>채상병 특검법의 경우 총선 직후 국민의힘에서도 “찬성표를 던질 계획(안철수 의원)”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33211</th>\n",
       "      <td>6376</td>\n",
       "      <td>대통령실의 의제를 놓고 여권에선 국무총리 인준과 의정 갈등 해법 논의, 중대재해처벌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33212</th>\n",
       "      <td>6376</td>\n",
       "      <td>앞서 정부·여당이 추진한 2년 유예안은 민주당 반대로 지난 2월 최종 결렬됐다. 한...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                          paragraph\n",
       "2146     434  하이브와 경영권 분쟁 중인 민희진 어도어 대표가 자신을 응원해주는 뉴진스 팬덤 ‘버...\n",
       "2147     434  아울러 “이 감사함을 다 어떻게 표현해야 할지 모르겠다. 그분들 덕분에 이상한 선택...\n",
       "2148     434  기자회견 말미에는 “변호사 수임료를 내서 지금은 현금이 없는데 100억원 이상은 사...\n",
       "2149     434  하이브는 가처분 인용 후 밝힌 입장대로 어도어 임시 주주총회에서 민 대표 해임에 대...\n",
       "2150     434  민 대표 측 인사인 기존 어도어 사내이사 신모 부대표와 김모 이사는 해임했다. 이로...\n",
       "...      ...                                                ...\n",
       "33208   6376  이 대표는 윤 대통령과 전화통화를 나눈 지난 19일 자신의 유튜브로 중계한 ‘당원과...\n",
       "33209   6376  최상목 경제부총리 겸 기획재정부 장관도 18일(현지시간) 제2차 주요 20개국(g2...\n",
       "33210   6376  채상병 특검법의 경우 총선 직후 국민의힘에서도 “찬성표를 던질 계획(안철수 의원)”...\n",
       "33211   6376  대통령실의 의제를 놓고 여권에선 국무총리 인준과 의정 갈등 해법 논의, 중대재해처벌...\n",
       "33212   6376  앞서 정부·여당이 추진한 2년 유예안은 민주당 반대로 지난 2월 최종 결렬됐다. 한...\n",
       "\n",
       "[273 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65ba2054-fce7-4a14-8214-6c4385fa1f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2956844 ,  0.24776833, -0.22421744, ..., -0.2747291 ,\n",
       "        -0.3685873 , -0.1613878 ],\n",
       "       [-0.17203742, -0.08865188, -0.03015941, ..., -0.04877322,\n",
       "        -0.40851593, -0.14290863],\n",
       "       [-0.32551047,  0.00878766,  0.14862892, ..., -0.01757442,\n",
       "        -0.3642966 , -0.0799266 ],\n",
       "       ...,\n",
       "       [-0.25395983, -0.15503576, -0.09961025, ..., -0.25965226,\n",
       "        -0.40697244,  0.02721978],\n",
       "       [-0.08125061, -0.06931539, -0.24182789, ...,  0.118022  ,\n",
       "        -0.39579332, -0.11885818],\n",
       "       [-0.22527277, -0.1938359 ,  0.03289722, ..., -0.37068295,\n",
       "        -0.2277479 , -0.04157471]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_embedding_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d82b8ae-716b-4c24-935e-52cb744b4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embeddings = model.encode(target_paragraph_data['paragraph'].tolist())  # 현재 읽고 있는 기사 단락 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5b6c739-ac3e-4ec1-915c-3ea90a9dd987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 128)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68abd510-695d-4d01-8f40-3d37daa550fc",
   "metadata": {},
   "source": [
    "#### 현재 읽고 있는 기사 데이터와 유사한 기사 데이터를 합쳐서 훈련 데이터로 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13a0b8ef-61d4-461d-8e5d-3e4cc829a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paragraph_embeddings=np.vstack((target_embeddings, paragraph_embedding_dataset))\n",
    "train_paragraph_data = pd.concat([target_paragraph_data, paragraph_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43643edc-7c73-4479-92fa-1a7e4ae3883d",
   "metadata": {},
   "source": [
    "#### BERTopic을 이용한 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4de1a2f0-e893-47da-9b85-e12063f6b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTopic(embedding_model='bongsoo/kpf-sbert-128d-v1', min_topic_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35fec701-8762-4d4c-ad73-06d21e58d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = model.fit_transform(documents=train_paragraph_data['paragraph'], embeddings=train_paragraph_embeddings)  # 클러스터링 만들기\n",
    "train_paragraph_data['topic'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d5f16e4-383c-44e0-85bb-526e2bdb84dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 읽고 있는 기사의 토픽 모델링\n",
    "target_paragraph_data = pd.merge(target_paragraph_data, train_paragraph_data[['paragraph', 'topic']], on='paragraph', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ffdf1f2a-003a-401a-91d1-c27aadf027fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'topic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'topic'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 토픽이 -1, 0은 제외\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m target_paragraph_data \u001b[38;5;241m=\u001b[39m target_paragraph_data[\u001b[43mtarget_paragraph_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'topic'"
     ]
    }
   ],
   "source": [
    "# 토픽이 -1, 0은 제외\n",
    "target_paragraph_data = target_paragraph_data[target_paragraph_data['topic'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354264b6-add8-4acf-aaa3-854c85cd772b",
   "metadata": {},
   "source": [
    "#### 결과 출력을 위한 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9661d6-c271-4108-9bf8-0a25f8eff107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_paragraph_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtarget_paragraph_data\u001b[49m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# 만약 토픽이 없다면\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo Topic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m     various_news_index\u001b[38;5;241m=\u001b[39msimilar_index_list \u001b[38;5;66;03m# 유사한 기사 3개 출력\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_paragraph_data' is not defined"
     ]
    }
   ],
   "source": [
    "if len(target_paragraph_data)==0: # 만약 토픽이 없다면\n",
    "    print('No Topic')\n",
    "    various_news_index=similar_index_list # 유사한 기사 3개 출력\n",
    "\n",
    "else:\n",
    "    paragraph_dataset=pd.merge(paragraph_dataset, train_paragraph_data[['paragraph','topic']], on='paragraph', how='inner')\n",
    "    paragraph_dataset=paragraph_dataset[paragraph_dataset['topic']>0]\n",
    "\n",
    "    topic_embeddings=model.topic_embeddings_\n",
    "    topic_embeddings=topic_embeddings[1:]\n",
    "\n",
    "    target_topic = target_paragraph_data['topic'].value_counts().idxmax()\n",
    "    target_topic_embedding = topic_embeddings[target_topic]\n",
    "\n",
    "    num_topics = len(model.get_topic_freq()) - 1\n",
    "\n",
    "    # faiss를 이용해서 토픽 간 코사인 유사도 계산\n",
    "    index = faiss.IndexFlatIP(128)\n",
    "    faiss.normalize_L2(topic_embeddings)\n",
    "    index.add(topic_embeddings)\n",
    "    distances, indices = index.search(np.expand_dims(target_topic_embedding, axis=0), num_topics)\n",
    "\n",
    "    # 가장 유사도가 낮은 토픽 순으로 단락 정렬\n",
    "    indices = indices[0][::-1]\n",
    "    indices = np.delete(indices, np.where(indices == 0)[0][0])\n",
    "    paragraph_dataset['topic'] = pd.Categorical(paragraph_dataset['topic'], categories=indices, ordered=True)\n",
    "    paragraph_dataset = paragraph_dataset.sort_values('topic')\n",
    "\n",
    "\n",
    "\n",
    "    # 토픽이 3개 이상이면\n",
    "    if num_topics - 2 > 3:\n",
    "        index_counts = paragraph_dataset.groupby(\n",
    "            'topic')['index'].value_counts().rename('count').reset_index()\n",
    "        most_common_index_per_topic = index_counts.loc[index_counts.groupby('topic')[\n",
    "            'count'].idxmax()]\n",
    "        most_common_index_per_topic=most_common_index_per_topic.drop_duplicates(subset='index') # 중복 제거\n",
    "\n",
    "        various_news_index=most_common_index_per_topic['index'].tolist()\n",
    "\n",
    "    else: # 토픽이 3개 이하이면 나온 것 모두 반환\n",
    "        paragraph_dataset=paragraph_dataset.drop_duplicates(subset='index') #중복 제거\n",
    "        various_news_index=paragraph_dataset['index'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bcd75e-9a2d-460c-bd62-9bf0e6604489",
   "metadata": {},
   "source": [
    "#### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b417da6-d2fd-4ec1-9b9c-2981cc7446f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "various_news_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c30b24-bdbe-4f8e-9c7d-b3bb697b55ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_link in news_dataset['link']:\n",
    "    same_news_index=news_dataset[news_dataset['link']==target_link].index\n",
    "    various_news_index.remove(same_news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5979db1-f87a-4dde-a848-1454c863bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "various_news=news_dataset.loc[various_news_index][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a49be-8a98-49a7-99fd-c837837de3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "various_news"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
