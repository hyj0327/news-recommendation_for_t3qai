{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf6a968-ab42-4f2b-88d3-d67a86c30bc1",
   "metadata": {},
   "source": [
    "# 플랫폼 업로드를 쉽게하기 위한 로컬 개발 코드\n",
    "- T3Q.ai(T3Q.cep + T3Q.dl): 빅데이터/인공지능 통합 플랫폼\n",
    "- 플랫폼 업로드를 쉽게하기 위하여 로컬에서 아래의 코드(파일1)를 개발한다.\n",
    "- 파일 1(파일명): 1_local_platform_image_classification.ipynb\n",
    "\n",
    "### 전처리 객체 또는 학습모델 객체\n",
    "- 전처리 객체나 학습모델 객체는 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "### 데이터셋 (학습 데이터/테스트 데이터)\n",
    "- 학습과 테스트에 사용되는 데이터를 나누어 관리한다.\n",
    "- 학습 데이터: dataset 폴더 아래에 저장하거나 dataset.zip 파일 형태로 저장한다.\n",
    "- 테스트 데이터: test_dataset 폴더 아래에 저장하거나 test_dataset.zip 파일 형태로 저장한다.\n",
    "\n",
    "### 로컬 개발 워크플로우(workflow)  \n",
    "- 로컬 개발 워크플로우를 다음의 4단계로 분리한다.\n",
    "\n",
    "1. 데이터셋 준비(Data Setup)\n",
    "- 로컬 저장소에서 전처리 및 학습에 필요한 학습 데이터셋을 준비한다.\n",
    "\n",
    "2. 데이터 전처리(Data Preprocessing)\n",
    "- 데이터셋의 분석 및 정규화(Normalization)등의 전처리를 수행한다.\n",
    "- 데이터를 모델 학습에 사용할 수 있도록 가공한다.\n",
    "- 추론과정에서 필요한 경우, 데이터 전처리에 사용된 객체를 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "3. 학습 모델 훈련(Train Model)\n",
    "- 데이터를 훈련에 사용할 수 있도록 가공한 뒤에 학습 모델을 구성한다. \n",
    "- 학습 모델을 준비된 데이터셋으로 훈련시킨다.\n",
    "- 정확도(Accuracy)나 손실(Loss)등 학습 모델의 성능을 검증한다.\n",
    "- 학습 모델의 성능 검증 후, 학습 모델을 배포한다.\n",
    "- 배포할 학습 모델을 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "4. 추론(Inference)\n",
    "- 저장된 전처리 객체나 학습 모델 객체를 준비한다.\n",
    "- 추론에 필요한 테스트 데이터셋을 준비한다.\n",
    "- 배포된 학습 모델을 통해 테스트 데이터에 대한 추론을 진행한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa1c01-373f-48bf-ac3e-5a968d796cc7",
   "metadata": {},
   "source": [
    "# 인공지능 통합플랫폼(T3Q.ai) 프로세스를 이해하고 인공지능 쉽게 하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71cc7ce2-4ba2-40f2-a8fd-53b8cf71adf1",
   "metadata": {},
   "source": [
    "1. 머신러닝(Machine Learning)과 딥러닝(Deep Learning) 프로그래밍 패턴\n",
    "\n",
    "(1) 데이터셋 불러오기(Dataset Loading)\n",
    "(2) 데이터 전처리(Data Preprocessing)\n",
    "   - 데이터 정규화(Normalization)\n",
    "   - 학습과 테스트 데이터 분할(Train/Test Data Split) 등\n",
    "(3) 학습 모델 구성(Train Model Build)\n",
    "(4) 학습(Model Training)\n",
    "(5) 학습 모델 성능 검증(Model Performance Validation)\n",
    "(6) 학습 모델 저장(배포) 하기(Model Save)\n",
    "(7) 추론 데이터 전처리((Data Preprocessing)\n",
    "(8) 추론(Inference) 또는 예측(Prediction) \n",
    "(9) 추론 결과 데이터 후처리(Data Postprocessing) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1957e35-fe12-4a2f-a7b8-e553815aab19",
   "metadata": {},
   "source": [
    "2. 빅데이터/인공지능 통합 플랫폼[ T3Q.ai ]에서 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    " - 7개의 함수로 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    "\n",
    "(1) process_for_train(pm) 함수\n",
    " - 데이터셋 준비(Dataset Setup) \n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(2) init_svc(im, rule) 함수\n",
    " - 전처리 객체 불러오기\n",
    "   에 필요한 코드 작성(생략 가능)\n",
    "\n",
    "(3) transform(df, params, batch_id) 함수\n",
    "- 추론 데이터 전처리(Data Preprocessing)\n",
    "  에 필요한 코드 작성(생략 가능)\n",
    "\n",
    "(4) train() 함수 \n",
    " - 데이터셋 불러오기(Dataset Loading)\n",
    " - 데이터 전처리(Data Preprocessing)\n",
    " - 학습 모델 구성(Train Model Build)\n",
    " - 학습(Model Training)\n",
    " - 학습 모델 성능 검증(Model Performance Validation)\n",
    " - 전처리 객체 저장\n",
    " - 학습 모델 저장(배포) 하기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(5) init_model() 함수 \n",
    " - 전처리 객체 불러오기\n",
    " - 학습모델 객체 불러오기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(6_a) inference_dataframe(df, model_info_dict) 함수\n",
    " - df(pandas DataFrame) 입력에 대한 추론 처리 기능\n",
    " - 추론시 입력 데이터에 대한 전처리(Data Preprocessing)\n",
    " - 추론(Inference) 또는 예측(Prediction) \n",
    " - 추론 결과 데이터 후처리(Data Postprocessing) \n",
    "\n",
    "(6_b) inference_file(files, model_info_dict) 함수\n",
    " - files 입력에 대한 추론 처리 기능\n",
    " - 추론시 입력 데이터에 대한 전처리(Data Preprocessing)\n",
    " - 추론(Inference) 또는 예측(Prediction) \n",
    " - 추론 결과 데이터 후처리(Data Postprocessing) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "941957b6-3714-441f-82a8-44245138ac10",
   "metadata": {},
   "source": [
    "3. 전처리 모듈 관리, 학습 알고리즘 관리 함수 설명\n",
    "\n",
    "1) [preprocess.py] 전처리모듈 관리 함수 \n",
    "\n",
    "def process_for_train(pm):\n",
    "    \"\"\"\n",
    "    (1) 입력: pm\n",
    "      # pm.source_path: 학습플랫폼/데이터셋 관리 메뉴에서 저장한 데이터를 불러오는 경로\n",
    "      # pm.target_path: 처리 완료된 데이터를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # 데이터셋 관리 메뉴에서 저장한 데이터를 불러와서 필요한 처리를 수행\n",
    "      # 처리 완료된 데이터를 저장하는 기능, pm.target_path에 저장\n",
    "      # 실행환경 등록에서 General 선택: train() 함수의 T3QAI_TRAIN_DATA_PATH를 통해 데이터를 불러와서 전처리와 학습을 수행 \n",
    "    \"\"\"\n",
    "\n",
    "def init_svc(im, rule):\n",
    "    \"\"\"\n",
    "    (1) 입력: im, rule\n",
    "    (2) 출력: 전처리 객체를 딕셔너리(dictionary) 객체에 담아 리턴(return)\n",
    "    (3) 설명: \n",
    "      # process_for_train(pm) 함수에서 저장한 전처리 객체와 데이터에 적용된 룰(rule)을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "    \"\"\"\n",
    "\n",
    "    return {}\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: 추론모델관리와 추론API관리, 실시간 추론을 통해 전달되는 추론 입력 데이터(dataframe 형태)\n",
    "      # params: init_svc(im, rule) 함수의 리턴(return) 값을 params 변수로 전달\n",
    "    (2) 출력: df\n",
    "    (3) 설명: \n",
    "      # df(추론 입력 데이터)에 대한 전처리를 수행한 후 전처리 된 데이터를 inference_dataframe(df, model_info_dict) 함수의 \n",
    "      입력 df에 전달하는 기능\n",
    "      # df(추론 입력 데이터)를 전처리 없이 inference_dataframe(df, model_info_dict) 함수의 입력 df에 리턴(return)\n",
    "    \"\"\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c1e6842-f7c8-4750-b5a9-a26bee23a388",
   "metadata": {},
   "source": [
    "2-1) [train.py] 학습 알고리즘 관리 함수\n",
    "\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, T3QAI_TRAIN_DATA_PATH\n",
    "\"\"\"\n",
    "(1) 설명:\n",
    "  # t3qai_client : 플랫폼과의 연동을 위한 클라이언트 모듈\n",
    "  # T3QAI_TRAIN_DATA_PATH : pm.target_path에서 저장한 전처리 데이터 경로\n",
    "  # T3QAI_TRAIN_MODEL_PATH : 학습 모델 저장 경로\n",
    "  # T3QAI_TRAIN_OUTPUT_PATH : 학습 결과 출력파일 저장 경로\n",
    "\"\"\"\n",
    "      \n",
    "def train():\n",
    "    \"\"\"\n",
    "    (1) 입력: None\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # pm.target_path에 저장한 데이터를 T3QAI_TRAIN_DATA_PATH 에서 불러오기\n",
    "      # 데이터 전처리와 학습 모델을 구성하고 모델 학습을 수행\n",
    "      # 학습 모델의 성능을 검증하고 배포할 학습 모델을 저장\n",
    "      # 전처리 객체와 학습 모델 객체를 T3QAI_TRAIN_MODEL_PATH 에 저장\n",
    "      # 학습 결과를 파일(이미지, 텍스트 등) 형태로 T3QAI_TRAIN_OUTPUT_PATH 에 저장 \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea423231-461e-4cc9-9c99-d2e80dc73feb",
   "metadata": {},
   "source": [
    "2-2) [inference_service.py] 학습 알고리즘 관리 함수\n",
    "\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_INIT_MODEL_PATH\n",
    "\"\"\"\n",
    "(1) 설명:\n",
    "  # T3QAI_INIT_MODEL_PATH : train() 함수에서 T3QAI_TRAIN_MODEL_PATH 에 저장한 전처리 객체와 \n",
    "                            학습 모델 객체 등을 추론 하기 위해 불러오는 경로\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    \"\"\"\n",
    "    (1) 입력: None\n",
    "    (2) 출력: 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 객체에 담아 리턴(return)\n",
    "    (3) 설명: \n",
    "      # T3QAI_TRAIN_MODEL_PATH에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 기능\n",
    "      # 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "      # 리턴(return) 값을 inference_dataframe(df,model_info_dict), \n",
    "      inference_file(files, model_info_dict) 함수의 입력 model_info_dict 변수로 전달\n",
    "    \"\"\"\n",
    "    return { **params }\n",
    "\n",
    "def inference_dataframe(df, model_info_dict):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, model_info_dict\n",
    "      # df: transform(df, params, batch_id)함수의 리턴(return) 값으로 전달된 df, \n",
    "      추론 입력 데이터(dataframe 형태)\n",
    "      # model_info_dict: init_model() 함수의 return 값을 model_info_dict 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model = model_info_dict.get('model') 또는 \n",
    "                                          model = model_info_dict['model']\n",
    "        ## 전처리(pca) 객체 사용 예시     pca = model_info_dict.get['pca'] 또는\n",
    "                                          pca = model_info_dict['pca']\n",
    "                                          \n",
    "    (2) 출력: 추론 결과 딕셔너리(dictionary) 형태 \n",
    "            result = {'inference': inference_result}\n",
    "\n",
    "                            \n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 df(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 df(추론 입력 데이터)에 대한 추론(예측)을 수행\n",
    "      # 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    \"\"\"\n",
    "    return {**result}\n",
    "\n",
    "def inference_file(files, model_info_dict):\n",
    "    \"\"\"\n",
    "    (1) 입력: files, model_info_dict\n",
    "      # files: 추론 하고자 하는 파일 형태의 입력 \n",
    "      # model_info_dict: init_model() 함수의 return 값을 model_info_dict 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model = model_info_dict.get('model') 또는 \n",
    "                                          model = model_info_dict['model']\n",
    "        ## 전처리(pca) 객체 사용 예시     pca = model_info_dict.get['pca'] 또는\n",
    "                                          pca = model_info_dict['pca']\n",
    "        \n",
    "    (2) 출력: a. 추론 결과 딕셔너리(dictionary) 형태 \n",
    "                  result = {'inference': inference_result}\n",
    "              b. 추론 결과 DownloadFile 형태\n",
    "                  result = DownloadFile(file_path=resultfilepath, file_name=filename1)\n",
    "                  result = DownloadFile(file_obj=resultfileobj, file_name=filename2)\n",
    "              c. 추론 결과 DownloadFile의 list형태\n",
    "                  result = [DownloadFile(file_path=resultfilepath, file_name=filename), \n",
    "                            DownloadFile(file_obj=resultfileobj, file_name=filename), ...]\n",
    "              \n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 files(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 files(추론 입력 데이터)에 추론(예측)을 수행\n",
    "      # 추론 결과를 a.딕셔너리(dictionary) 형태, b.DownloadFile 형태, c.DownloadFile의 list 형태로 리턴(return)\n",
    "    \"\"\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2d1568-a3d0-4b2d-9bb5-87e8ca391621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspecive_NewsRec_preprocess.py\n",
    "\n",
    "'''\n",
    "from Perspecive_NewsRec_preprocess_sub import exec_process\n",
    "'''\n",
    "\n",
    "import logging\n",
    "\n",
    "def process_for_train(pm):\n",
    "    exec_process(pm)\n",
    "    logging.info('[hunmin log] the end line of the function [process_for_train]')\n",
    "\n",
    "\n",
    "def init_svc(im, rule):\n",
    "    return {}\n",
    "\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    logging.info('[hunmin log] df.shape : {}'.format(df.shape))\n",
    "    logging.info('[hunmin log] type(df) : {}'.format(type(df)))\n",
    "    logging.info('[hunmin log] the end line of the function [transform]')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc005f5a-f12f-42d0-b6ff-59f2af5c0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspecive_NewsRec_preprocess_sub.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import logging\n",
    "\n",
    "\n",
    "def exec_process(pm):\n",
    "    logging.info('[hunmin log] the start line of the function [exec_process]')\n",
    "\n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(pm.source_path)\n",
    "\n",
    "    # pm.source_path의 dataset.zip 파일을\n",
    "    # pm.target_path 경로에 압축해제\n",
    "    my_zip_path = os.path.join(pm.source_path, 'dataset.zip')\n",
    "    extract_zip_file = zipfile.ZipFile(my_zip_path)\n",
    "    extract_zip_file.extractall(pm.target_path)\n",
    "    extract_zip_file.close()\n",
    "\n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(pm.target_path)\n",
    "\n",
    "    logging.info('[hunmin log] the finish line of the function [exec_process]')\n",
    "\n",
    "# 저장 파일 확인\n",
    "def list_files_directories(path):\n",
    "    # Get the list of all files and directories in current working directory\n",
    "    dir_list = os.listdir(path)\n",
    "    logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
    "    logging.info('[hunmin log] dir_list : {}'.format(dir_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed994509-63d0-4e4d-a86f-428753611fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import logging\n",
    "import os\n",
    "'''\n",
    "from train_sub import exec_train\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, \\\n",
    "    T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    logging.info('[train.py] main() start')\n",
    "    result = None\n",
    "    result_msg = \"success\"\n",
    "    tc.train_start()\n",
    "    try:\n",
    "        train()\n",
    "    except Exception as e:\n",
    "        result = e\n",
    "        result_msg = e\n",
    "        logging.info('error log : {}'.format(e))\n",
    "    tc.train_finish(result, result_msg)\n",
    "\n",
    "\n",
    "def train():\n",
    "    exec_train()\n",
    "    logging.info('[hunmin log] the end line of the function [train]')\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#ㄴㄴ    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3c6a90-4734-45d9-bf52-c10cc366be93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#  train_sub.py\n",
    "\n",
    "'''\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, \\\n",
    "    T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH, T3QAI_INIT_MODEL_PATH\n",
    "'''\n",
    "import logging\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tqdm\n",
    "\n",
    "\n",
    "gpus = 1\n",
    "RANDOM_SEED = 42\n",
    "BERT_MODEL_NAME = 'jinmang2/kpfbert'\n",
    "MAX_TOKEN_COUNT = 512\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# exec_train() 호출 함수\n",
    "###########################################################################\n",
    "def preprocess_data(data):\n",
    "    outs = []\n",
    "    for doc in data['documents']:\n",
    "        line = []\n",
    "        line.append(doc['media_name'])\n",
    "        line.append(doc['id'])\n",
    "        para = []\n",
    "        for sent in doc['text']:\n",
    "            for s in sent:\n",
    "                para.append(s['sentence'])\n",
    "        line.append(para)\n",
    "        line.append(doc['abstractive'][0])\n",
    "        line.append(doc['extractive'])\n",
    "        a = doc['extractive']\n",
    "        if a[0] == None or a[1] == None or a[2] == None:\n",
    "            continue\n",
    "        outs.append(line)\n",
    "\n",
    "    outs_df = pd.DataFrame(outs)\n",
    "    outs_df.columns = ['media', 'id',\n",
    "                       'article_original', 'abstractive', 'extractive']\n",
    "    return outs_df\n",
    "\n",
    "\n",
    "class SummDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: BertTokenizer,\n",
    "        max_token_len: int = 512\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        tokenlist = []\n",
    "        for sent in data_row.article_original:\n",
    "            tokenlist.append(tokenizer(\n",
    "                text=sent,\n",
    "                add_special_tokens=True))  # , # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "        src = []  # 토크나이징 된 전체 문단\n",
    "        labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
    "        segs = []  # 각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
    "        clss = []  # [CLS]토큰의 포지션값을 지정\n",
    "\n",
    "        odd = 0\n",
    "        for tkns in tokenlist:\n",
    "            if odd > 1:\n",
    "                odd = 0\n",
    "            clss = clss + [len(src)]\n",
    "            src = src + tkns['input_ids']\n",
    "            segs = segs + [odd] * len(tkns['input_ids'])\n",
    "            if tokenlist.index(tkns) in data_row.extractive:\n",
    "                labels = labels + [1]\n",
    "            else:\n",
    "                labels = labels + [0]\n",
    "            odd += 1\n",
    "\n",
    "            # truncation\n",
    "            if len(src) == MAX_TOKEN_COUNT:\n",
    "                break\n",
    "            elif len(src) > MAX_TOKEN_COUNT:\n",
    "                src = src[:self.max_token_len - 1] + [src[-1]]\n",
    "                segs = segs[:self.max_token_len]\n",
    "                break\n",
    "\n",
    "        # padding\n",
    "        if len(src) < MAX_TOKEN_COUNT:\n",
    "            src = src + [0]*(self.max_token_len - len(src))\n",
    "            segs = segs + [0]*(self.max_token_len - len(segs))\n",
    "\n",
    "        if len(clss) < MAX_TOKEN_COUNT:\n",
    "            clss = clss + [-1]*(self.max_token_len - len(clss))\n",
    "        if len(labels) < MAX_TOKEN_COUNT:\n",
    "            labels = labels + [0]*(self.max_token_len - len(labels))\n",
    "\n",
    "        return dict(\n",
    "            src=torch.tensor(src),\n",
    "            segs=torch.tensor(segs),\n",
    "            clss=torch.tensor(clss),\n",
    "            labels=torch.FloatTensor(labels)\n",
    "        )\n",
    "\n",
    "\n",
    "class SummDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, test_df, val_df, tokenizer, batch_size=1, max_token_len=512):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.val_df = val_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = SummDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "        self.test_dataset = SummDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "        self.val_dataset = SummDataset(\n",
    "            self.val_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0  # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0  # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0  # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
    "        )\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout, dim, max_len=5000):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) *\n",
    "                              -(math.log(10000.0) / dim)))\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, emb, step=None):\n",
    "        emb = emb * math.sqrt(self.dim)\n",
    "        if (step):\n",
    "            emb = emb + self.pe[:, step][:, None, :]\n",
    "\n",
    "        else:\n",
    "            emb = emb + self.pe[:, :emb.size(1)]\n",
    "        emb = self.dropout(emb)\n",
    "        return emb\n",
    "\n",
    "    def get_emb(self, emb):\n",
    "        return self.pe[:, :emb.size(1)]\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, d_ff, dropout):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadedAttention(\n",
    "            heads, d_model, dropout=dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, iter, query, inputs, mask):\n",
    "        if (iter != 0):\n",
    "            input_norm = self.layer_norm(inputs)\n",
    "        else:\n",
    "            input_norm = inputs\n",
    "\n",
    "        mask = mask.unsqueeze(1)\n",
    "        context = self.self_attn(input_norm, input_norm, input_norm,\n",
    "                                 mask=mask)\n",
    "        out = self.dropout(context) + inputs\n",
    "        return self.feed_forward(out)\n",
    "\n",
    "\n",
    "class ExtTransformerEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size=768, d_ff=2048, heads=8, dropout=0.2, num_inter_layers=2):\n",
    "        super(ExtTransformerEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_inter_layers = num_inter_layers\n",
    "        self.pos_emb = PositionalEncoding(dropout, hidden_size)\n",
    "        self.transformer_inter = nn.ModuleList(\n",
    "            [TransformerEncoderLayer(hidden_size, heads, d_ff, dropout)\n",
    "             for _ in range(num_inter_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.wo = nn.Linear(hidden_size, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, top_vecs, mask):\n",
    "        \"\"\" See :obj:`EncoderBase.forward()`\"\"\"\n",
    "\n",
    "        batch_size, n_sents = top_vecs.size(0), top_vecs.size(1)\n",
    "        pos_emb = self.pos_emb.pe[:, :n_sents]\n",
    "        x = top_vecs * mask[:, :, None].float()\n",
    "        x = x + pos_emb\n",
    "\n",
    "        for i in range(self.num_inter_layers):\n",
    "            x = self.transformer_inter[i](i, x, x, ~mask)\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        sent_scores = self.sigmoid(self.wo(x))\n",
    "        sent_scores = sent_scores.squeeze(-1) * mask.float()\n",
    "\n",
    "        return sent_scores\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\" A two-layer Feed-Forward-Network with residual layer norm.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): the size of input for the first-layer of the FFN.\n",
    "        d_ff (int): the hidden layer size of the second-layer\n",
    "            of the FNN.\n",
    "        dropout (float): dropout probability in :math:`[0, 1)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def gelu(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        inter = self.dropout_1(self.gelu(self.w_1(self.layer_norm(x))))\n",
    "        output = self.dropout_2(self.w_2(inter))\n",
    "        return output + x\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention module from\n",
    "    \"Attention is All You Need\"\n",
    "    :cite:`DBLP:journals/corr/VaswaniSPUJGKP17`.\n",
    "\n",
    "    Similar to standard `dot` attention but uses\n",
    "    multiple attention distributions simulataneously\n",
    "    to select relevant items.\n",
    "\n",
    "    .. mermaid::\n",
    "\n",
    "       graph BT\n",
    "          A[key]\n",
    "          B[value]\n",
    "          C[query]\n",
    "          O[output]\n",
    "          subgraph Attn\n",
    "            D[Attn 1]\n",
    "            E[Attn 2]\n",
    "            F[Attn N]\n",
    "          end\n",
    "          A --> D\n",
    "          C --> D\n",
    "          A --> E\n",
    "          C --> E\n",
    "          A --> F\n",
    "          C --> F\n",
    "          D --> O\n",
    "          E --> O\n",
    "          F --> O\n",
    "          B --> O\n",
    "\n",
    "    Also includes several additional tricks.\n",
    "\n",
    "    Args:\n",
    "       head_count (int): number of parallel heads\n",
    "       model_dim (int): the dimension of keys/values/queries,\n",
    "           must be divisible by head_count\n",
    "       dropout (float): dropout parameter\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, head_count, model_dim, dropout=0.1, use_final_linear=True):\n",
    "        assert model_dim % head_count == 0\n",
    "        self.dim_per_head = model_dim // head_count\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.head_count = head_count\n",
    "\n",
    "        self.linear_keys = nn.Linear(model_dim,\n",
    "                                     head_count * self.dim_per_head)\n",
    "        self.linear_values = nn.Linear(model_dim,\n",
    "                                       head_count * self.dim_per_head)\n",
    "        self.linear_query = nn.Linear(model_dim,\n",
    "                                      head_count * self.dim_per_head)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.use_final_linear = use_final_linear\n",
    "        if (self.use_final_linear):\n",
    "            self.final_linear = nn.Linear(model_dim, model_dim)\n",
    "\n",
    "    def forward(self, key, value, query, mask=None,\n",
    "                layer_cache=None, type=None, predefined_graph_1=None):\n",
    "        \"\"\"\n",
    "        Compute the context vector and the attention vectors.\n",
    "\n",
    "        Args:\n",
    "           key (`FloatTensor`): set of `key_len`\n",
    "                key vectors `[batch, key_len, dim]`\n",
    "           value (`FloatTensor`): set of `key_len`\n",
    "                value vectors `[batch, key_len, dim]`\n",
    "           query (`FloatTensor`): set of `query_len`\n",
    "                 query vectors  `[batch, query_len, dim]`\n",
    "           mask: binary mask indicating which keys have\n",
    "                 non-zero attention `[batch, query_len, key_len]`\n",
    "        Returns:\n",
    "           (`FloatTensor`, `FloatTensor`) :\n",
    "\n",
    "           * output context vectors `[batch, query_len, dim]`\n",
    "           * one of the attention vectors `[batch, query_len, key_len]`\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = key.size(0)\n",
    "        dim_per_head = self.dim_per_head\n",
    "        head_count = self.head_count\n",
    "        key_len = key.size(1)\n",
    "        query_len = query.size(1)\n",
    "\n",
    "        def shape(x):\n",
    "            \"\"\"  projection \"\"\"\n",
    "            return x.view(batch_size, -1, head_count, dim_per_head) \\\n",
    "                .transpose(1, 2)\n",
    "\n",
    "        def unshape(x):\n",
    "            \"\"\"  compute context \"\"\"\n",
    "            return x.transpose(1, 2).contiguous() \\\n",
    "                .view(batch_size, -1, head_count * dim_per_head)\n",
    "\n",
    "        # 1) Project key, value, and query.\n",
    "        if layer_cache is not None:\n",
    "            if type == \"self\":\n",
    "                query, key, value = self.linear_query(query), \\\n",
    "                    self.linear_keys(query), \\\n",
    "                    self.linear_values(query)\n",
    "\n",
    "                key = shape(key)\n",
    "                value = shape(value)\n",
    "\n",
    "                if layer_cache is not None:\n",
    "                    device = key.device\n",
    "                    if layer_cache[\"self_keys\"] is not None:\n",
    "                        key = torch.cat(\n",
    "                            (layer_cache[\"self_keys\"].to(device), key),\n",
    "                            dim=2)\n",
    "                    if layer_cache[\"self_values\"] is not None:\n",
    "                        value = torch.cat(\n",
    "                            (layer_cache[\"self_values\"].to(device), value),\n",
    "                            dim=2)\n",
    "                    layer_cache[\"self_keys\"] = key\n",
    "                    layer_cache[\"self_values\"] = value\n",
    "            elif type == \"context\":\n",
    "                query = self.linear_query(query)\n",
    "                if layer_cache is not None:\n",
    "                    if layer_cache[\"memory_keys\"] is None:\n",
    "                        key, value = self.linear_keys(key), \\\n",
    "                            self.linear_values(value)\n",
    "                        key = shape(key)\n",
    "                        value = shape(value)\n",
    "                    else:\n",
    "                        key, value = layer_cache[\"memory_keys\"], \\\n",
    "                            layer_cache[\"memory_values\"]\n",
    "                    layer_cache[\"memory_keys\"] = key\n",
    "                    layer_cache[\"memory_values\"] = value\n",
    "                else:\n",
    "                    key, value = self.linear_keys(key), \\\n",
    "                        self.linear_values(value)\n",
    "                    key = shape(key)\n",
    "                    value = shape(value)\n",
    "        else:\n",
    "            key = self.linear_keys(key)\n",
    "            value = self.linear_values(value)\n",
    "            query = self.linear_query(query)\n",
    "            key = shape(key)\n",
    "            value = shape(value)\n",
    "\n",
    "        query = shape(query)\n",
    "\n",
    "        key_len = key.size(2)\n",
    "        query_len = query.size(2)\n",
    "\n",
    "        # 2) Calculate and scale scores.\n",
    "        query = query / math.sqrt(dim_per_head)\n",
    "        scores = torch.matmul(query, key.transpose(2, 3))\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).expand_as(scores)\n",
    "            # how can i fix it to use fp16...\n",
    "            scores = scores.masked_fill(mask, -1e18)\n",
    "\n",
    "        # 3) Apply attention dropout and compute context vectors.\n",
    "\n",
    "        attn = self.softmax(scores)\n",
    "\n",
    "        if (not predefined_graph_1 is None):\n",
    "            attn_masked = attn[:, -1] * predefined_graph_1\n",
    "            attn_masked = attn_masked / \\\n",
    "                (torch.sum(attn_masked, 2).unsqueeze(2) + 1e-9)\n",
    "\n",
    "            attn = torch.cat([attn[:, :-1], attn_masked.unsqueeze(1)], 1)\n",
    "\n",
    "        drop_attn = self.dropout(attn)\n",
    "        if (self.use_final_linear):\n",
    "            context = unshape(torch.matmul(drop_attn, value))\n",
    "            output = self.final_linear(context)\n",
    "            return output\n",
    "        else:\n",
    "            context = torch.matmul(drop_attn, value)\n",
    "            return context\n",
    "\n",
    "\n",
    "class Summarizer(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.max_pos = 512\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            BERT_MODEL_NAME)  # , return_dict=True)\n",
    "        self.ext_layer = ExtTransformerEncoder()\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.loss = nn.BCELoss(reduction='none')\n",
    "\n",
    "        for p in self.ext_layer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)\n",
    "\n",
    "    # , input_ids, attention_mask, labels=None):\n",
    "    def forward(self, src, segs, clss, labels=None):\n",
    "\n",
    "        mask_src = ~(src == 0)  # 1 - (src == 0)\n",
    "        mask_cls = ~(clss == -1)  # 1 - (clss == -1)\n",
    "\n",
    "        top_vec = self.bert(src, token_type_ids=segs, attention_mask=mask_src)\n",
    "        top_vec = top_vec.last_hidden_state\n",
    "\n",
    "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n",
    "        sents_vec = sents_vec * mask_cls[:, :, None].float()\n",
    "\n",
    "        sent_scores = self.ext_layer(sents_vec, mask_cls).squeeze(-1)\n",
    "\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.loss(sent_scores, labels)\n",
    "\n",
    "            loss = (loss * mask_cls.float()).sum() / len(labels)\n",
    "\n",
    "        return loss, sent_scores\n",
    "\n",
    "    def step(self, batch):\n",
    "\n",
    "        src = batch['src']\n",
    "        if len(batch['labels']) > 0:\n",
    "            labels = batch['labels']\n",
    "        else:\n",
    "            labels = None\n",
    "        segs = batch['segs']\n",
    "        clss = batch['clss']\n",
    "\n",
    "        loss, sent_scores = self(src, segs, clss, labels)\n",
    "\n",
    "        return loss, sent_scores, labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def acc_loss(self, outputs):\n",
    "        total_loss = 0\n",
    "        hit_cnt = 0\n",
    "        for outp in outputs:\n",
    "            labels = outp['labels'].cpu()\n",
    "            predictions, idxs = outp['predictions'].cpu().sort()\n",
    "            loss = outp['loss'].cpu()\n",
    "            for label, idx in zip(labels, idxs):\n",
    "                for i in range(1, 3):\n",
    "                    if label[idx[-i-1]] == 1:\n",
    "                        hit_cnt += 1\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "        avg_loss = total_loss / len(outputs)\n",
    "        acc = hit_cnt / (3*len(outputs)*len(labels))\n",
    "\n",
    "        return acc, avg_loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "\n",
    "        print('acc:', acc, 'avg_loss:', avg_loss)\n",
    "        logging.info(\n",
    "            '[hunmin log] training_epoch_end avg_loss : {}'.format(avg_loss))\n",
    "\n",
    "        self.log('avg_train_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "\n",
    "        print('val_acc:', acc, 'avg_val_loss:', avg_loss)\n",
    "\n",
    "        logging.info(\n",
    "            '[hunmin log] training_epoch_end avg_val_loss : {}'.format(avg_loss))\n",
    "\n",
    "        self.log('avg_val_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "\n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "\n",
    "        print('test_acc:', acc, 'avg_test_loss:', avg_loss)\n",
    "\n",
    "        logging.info(\n",
    "            '[hunmin log] training_epoch_end avg_test_loss : {}'.format(avg_loss))\n",
    "\n",
    "        self.log('avg_test_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "\n",
    "        steps_per_epoch = len(train_df) // BATCH_SIZE\n",
    "        total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=steps_per_epoch,\n",
    "            num_training_steps=total_training_steps\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=dict(\n",
    "                scheduler=scheduler,\n",
    "                interval='step'\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def exec_train():\n",
    "    logging.info('[hunmin log] the start line of the function [exec_train]')\n",
    "    logging.info('[hunmin log] T3QAI_TRAIN_DATA_PATH : {}'.format(\n",
    "        T3QAI_TRAIN_DATA_PATH))\n",
    "\n",
    "    logging.info(f'[hunmin log] pytorch-lightning ver : {pl.__version__}')\n",
    "\n",
    "    my_path = os.path.join(T3QAI_TRAIN_DATA_PATH, 'dataset') + '/'\n",
    "\n",
    "    train_dataset = pd.read_json(my_path+'train_original.json')\n",
    "    valid_dataset = pd.read_json(my_path+'valid_original.json')\n",
    "\n",
    "    train_dataset = train_dataset.dropna()\n",
    "    valid_dataset = valid_dataset.dropna()\n",
    "\n",
    "    news_dataset = pd.read_json(my_path+'news.json')\n",
    "    summary_embedding_dataset = np.load(my_path+'summary_embedding.npy')\n",
    "    paragraph_dataset = pd.read_json(my_path+'paragraph_data.json')\n",
    "    paragraph_embedding_dataset = np.load(my_path+'paragraph_embedding.npy')\n",
    "\n",
    "    # topic에 필요한 데이터 옮기기\n",
    "    os.makedirs(T3QAI_TRAIN_MODEL_PATH+\"/\"+\"dataset\", exist_ok=True)\n",
    "    topic_data_path = os.path.join(T3QAI_TRAIN_MODEL_PATH, 'dataset') + '/'\n",
    "\n",
    "    news_dataset.to_json(topic_data_path+'news.json')\n",
    "    np.save(topic_data_path+'summary_embedding.npy', summary_embedding_dataset)\n",
    "    paragraph_dataset.to_json(topic_data_path+'paragraph_data.json')\n",
    "    np.save(topic_data_path+'paragraph_embedding.npy',\n",
    "            paragraph_embedding_dataset)\n",
    "\n",
    "    global train_df\n",
    "    global test_df\n",
    "    global val_df\n",
    "\n",
    "    train_df, val_df = train_test_split(train_dataset, test_size=0.05)\n",
    "    test_df = valid_dataset\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "    train_df = preprocess_data(train_df)\n",
    "    test_df = preprocess_data(test_df)\n",
    "    val_df = preprocess_data(val_df)\n",
    "\n",
    "    train_df = train_df.sample(frac=0.05)\n",
    "    test_df = test_df.sample(frac=0.05)\n",
    "    val_df = val_df.sample(frac=0.05)\n",
    "\n",
    "    logging.info('[hunmin log] train_df : {}'.format(train_df.shape))\n",
    "    logging.info('[hunmin log] val_df : {}'.format(val_df.shape))\n",
    "    logging.info('[hunmin log] test_df : {}'.format(test_df.shape))\n",
    "\n",
    "    pl.seed_everything(RANDOM_SEED)\n",
    "    global tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "    data_module = SummDataModule(\n",
    "        train_df, test_df, val_df, tokenizer, batch_size=BATCH_SIZE, max_token_len=MAX_TOKEN_COUNT)\n",
    "    model = Summarizer()\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=T3QAI_TRAIN_MODEL_PATH,\n",
    "        filename=\"best-checkpoint\",\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor=\"avg_val_loss\",\n",
    "        mode=\"min\"\n",
    "    )\n",
    "\n",
    "    directory = 'lightning_logs'\n",
    "\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "        logging.info(\n",
    "            f\"'{directory}' directory and all its contents have been deleted.\")\n",
    "    else:\n",
    "        logging.info(f\"'{directory}' directory does not exist.\")\n",
    "\n",
    "    logger = TensorBoardLogger('lightning_logs', name=\"kpfBERT_Summary\")\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='avg_val_loss', patience=3, verbose=True)\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        callbacks=[early_stopping_callback],\n",
    "        max_epochs=N_EPOCHS,\n",
    "        gpus=1,\n",
    "        progress_bar_refresh_rate=30\n",
    "    )\n",
    "\n",
    "    # 모델 학습 (Train Model)\n",
    "    logging.info('trainer.fit')\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    # 모델 평가 (Evaluate Model)\n",
    "    logging.info('trainer.test')\n",
    "    trainer.test(verbose=True)\n",
    "\n",
    "    # 저장 파일 확인\n",
    "\n",
    "    logging.info('[hunmin log] the finish line of the function [exec_train]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3273597-124d-4849-9b31-4202e4635a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_service.py\n",
    "\n",
    "\"\"\"\n",
    "from inference_service_sub import exec_init_model, exec_inference_dataframe, exec_inference_file\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "def init_model():\n",
    "    params = exec_init_model()\n",
    "    logging.info('[hunmin log] the end line of the function [init_model]')\n",
    "    return { **params }\n",
    "\n",
    "\n",
    "def inference_dataframe(df, model_info_dict):\n",
    "    result = exec_inference_dataframe(df, model_info_dict)\n",
    "    logging.info('[hunmin log] the end line of the function [inference_dataframe]')\n",
    "    return { **result }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88fee159-322a-4b84-85c6-dcf8498e79fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "# inference_service_sub.py\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "from bertopic import BERTopic\n",
    "import kss\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from transformers import BertModel, BertTokenizer, AdamW,  get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "'''\n",
    "from t3qai_client import DownloadFile\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, T3QAI_TRAIN_DATA_PATH, \\\n",
    "    T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH, T3QAI_INIT_MODEL_PATH\n",
    "'''\n",
    "\n",
    "MAX_TOKEN_COUNT = 512\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 4\n",
    "BERT_MODEL_NAME = 'jinmang2/kpfbert'\n",
    "\n",
    "\n",
    "def exec_init_model():\n",
    "    logging.info('[hunmin log] T3QAI_INIT_MODEL_PATH : {}'.format(\n",
    "        T3QAI_INIT_MODEL_PATH))\n",
    "\n",
    "    trained_model = Summarizer.load_from_checkpoint(\n",
    "        os.path.join(T3QAI_INIT_MODEL_PATH, 'best-checkpoint.ckpt'),\n",
    "        strict=False\n",
    "    )\n",
    "\n",
    "    model = BERTopic(\n",
    "        embedding_model='bongsoo/kpf-sbert-128d-v1', min_topic_size=5)\n",
    "    embedding_model = SentenceTransformer(\n",
    "        'bongsoo/kpf-sbert-128d-v1')  # 임베딩 모델\n",
    "\n",
    "    model_info_dict = {\n",
    "        \"summary_model\": trained_model,\n",
    "        \"model\": model,\n",
    "        \"embedding_model\": embedding_model\n",
    "    }\n",
    "\n",
    "    return model_info_dict\n",
    "\n",
    "\n",
    "def exec_inference_dataframe(df, model_info_dict):\n",
    "\n",
    "    logging.info(\n",
    "        '[hunmin log] the start line of the function [exec_inference_dataframe]')\n",
    "\n",
    "    # 학습 모델 준비\n",
    "    trained_model = model_info_dict['summary_model']\n",
    "\n",
    "    # 뉴스 데이터셋 불러오기\n",
    "    my_path = os.path.join(T3QAI_INIT_MODEL_PATH, 'dataset') + '/'\n",
    "\n",
    "    news_dataset = pd.read_json(my_path+'news.json')\n",
    "    summary_embedding_dataset = np.load(my_path+'summary_embedding.npy')\n",
    "    paragraph_dataset = pd.read_json(my_path+'paragraph_data.json')\n",
    "    paragraph_embedding_dataset = np.load(my_path+'paragraph_embedding.npy')\n",
    "\n",
    "    logging.info('[hunmin log] news_dataset : {}'.format(news_dataset.shape))\n",
    "    logging.info('[hunmin log] summary_embedding_dataset : {}'.format(\n",
    "        summary_embedding_dataset.shape))\n",
    "    logging.info('[hunmin log] paragraph_dataset : {}'.format(\n",
    "        paragraph_dataset.shape))\n",
    "    logging.info('[hunmin log] paragraph_embedding_dataset : {}'.format(\n",
    "        paragraph_embedding_dataset.shape))\n",
    "\n",
    "    # data preprocess\n",
    "    logging.info('[hunmin log] load dataframe: {}'.format(df))\n",
    "    target_link = df.iloc[0, 0]\n",
    "    target_data = fetch_article_data(target_link)\n",
    "    target_article = target_data['article']\n",
    "\n",
    "    # Summary\n",
    "    target_summary_ = summarize_article(trained_model, target_article)\n",
    "    target_summary = \" \".join(target_summary_)\n",
    "    logging.info('[hunmin log] target_summary : {}'.format(target_summary))\n",
    "\n",
    "    # Summary -> Embedding\n",
    "    model = model_info_dict['embedding_model']\n",
    "    target_summary_embedding = model.encode(\n",
    "        target_summary, normalize_embeddings=True)\n",
    "\n",
    "    logging.info('start Similarity')\n",
    "\n",
    "    # Similarity\n",
    "    threshold = 0.55\n",
    "    similar_list = []\n",
    "    for i in range(len(summary_embedding_dataset)):\n",
    "        similarity = pearson_similarity(\n",
    "            target_summary_embedding, summary_embedding_dataset[i])\n",
    "\n",
    "        if similarity > threshold:\n",
    "            # threshold 이상이면 유사한 기사 리스트에 추가\n",
    "            similar_list.append((similarity, i))\n",
    "\n",
    "    # 유사도 기준 내림차순 정렬\n",
    "    sorted_similar_list = sorted(\n",
    "        similar_list, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # 100개 이상이면 100개만 추려서 반환\n",
    "    if len(similar_list) > 100:\n",
    "        similar_index_list = [item[1] for item in sorted_similar_list[:100]]\n",
    "\n",
    "    # 100개 이하면 모두 반환\n",
    "    else:\n",
    "        similar_index_list = [item[1] for item in sorted_similar_list]\n",
    "\n",
    "    logging.info('end Similarity')\n",
    "\n",
    "    target_paragraphs = split_into_paragraphs(target_article)\n",
    "    target_paragraph_data = []\n",
    "    for data in target_paragraphs:\n",
    "        target_paragraph_data.append([-1]+[data])\n",
    "\n",
    "    target_paragraph_data = pd.DataFrame(\n",
    "        data=target_paragraph_data, columns=['index', 'paragraph'])\n",
    "\n",
    "    paragraph_embedding_dataset = paragraph_embedding_dataset[paragraph_dataset['index'].isin(\n",
    "        similar_index_list)]\n",
    "    paragraph_dataset = paragraph_dataset[paragraph_dataset['index'].isin(\n",
    "        similar_index_list)]\n",
    "\n",
    "    target_embeddings = model.encode(\n",
    "        target_paragraph_data['paragraph'].tolist())  # 현재 읽고 있는 기사 단락 임베딩\n",
    "\n",
    "    train_paragraph_embeddings = np.vstack(\n",
    "        (target_embeddings, paragraph_embedding_dataset))\n",
    "    train_paragraph_data = pd.concat(\n",
    "        [target_paragraph_data, paragraph_dataset], axis=0)\n",
    "\n",
    "    logging.info('Start BERTopic')\n",
    "\n",
    "    model = model_info_dict['model']\n",
    "\n",
    "    topics, probs = model.fit_transform(\n",
    "        documents=train_paragraph_data['paragraph'], embeddings=train_paragraph_embeddings)  # 클러스터링 만들기\n",
    "    train_paragraph_data['topic'] = topics\n",
    "    target_paragraph_data = pd.merge(target_paragraph_data, train_paragraph_data[[\n",
    "                                     'paragraph', 'topic']], on='paragraph', how='inner')\n",
    "\n",
    "    # 토픽이 -1, 0은 제외\n",
    "    target_paragraph_data = target_paragraph_data[target_paragraph_data['topic'] > 0]\n",
    "\n",
    "    if len(target_paragraph_data) == 0:  # 만약 토픽이 없다면\n",
    "        print('No Topic')\n",
    "        various_news_index = similar_index_list  # 유사한 기사 3개 출력\n",
    "\n",
    "    else:\n",
    "        paragraph_dataset = pd.merge(paragraph_dataset, train_paragraph_data[[\n",
    "                                     'paragraph', 'topic']], on='paragraph', how='inner')\n",
    "        paragraph_dataset = paragraph_dataset[paragraph_dataset['topic'] > 0]\n",
    "\n",
    "        topic_embeddings = model.topic_embeddings_\n",
    "        topic_embeddings = topic_embeddings[1:]\n",
    "\n",
    "        target_topic = target_paragraph_data['topic'].value_counts().idxmax()\n",
    "        target_topic_embedding = topic_embeddings[target_topic]\n",
    "\n",
    "        num_topics = len(model.get_topic_freq()) - 1\n",
    "\n",
    "        # faiss를 이용해서 토픽 간 코사인 유사도 계산\n",
    "        index = faiss.IndexFlatIP(128)\n",
    "        faiss.normalize_L2(topic_embeddings)\n",
    "        index.add(topic_embeddings)\n",
    "        distances, indices = index.search(np.expand_dims(\n",
    "            target_topic_embedding, axis=0), num_topics)\n",
    "\n",
    "        # 가장 유사도가 낮은 토픽 순으로 단락 정렬\n",
    "        indices = indices[0][::-1]\n",
    "        indices = np.delete(indices, np.where(indices == 0)[0][0])\n",
    "        paragraph_dataset['topic'] = pd.Categorical(\n",
    "            paragraph_dataset['topic'], categories=indices, ordered=True)\n",
    "        paragraph_dataset = paragraph_dataset.sort_values('topic')\n",
    "\n",
    "        if num_topics - 2 > 3:\n",
    "            index_counts = paragraph_dataset.groupby(\n",
    "                'topic')['index'].value_counts().rename('count').reset_index()\n",
    "            most_common_index_per_topic = index_counts.loc[index_counts.groupby('topic')[\n",
    "                'count'].idxmax()]\n",
    "            most_common_index_per_topic = most_common_index_per_topic.drop_duplicates(\n",
    "                subset='index')  # 중복 제거\n",
    "\n",
    "            various_news_index = most_common_index_per_topic['index'].tolist()\n",
    "\n",
    "        else:  # 토픽이 3개 이하이면 나온 것 모두 반환\n",
    "            paragraph_dataset = paragraph_dataset.drop_duplicates(\n",
    "                subset='index')  # 중복 제거\n",
    "            various_news_index = paragraph_dataset['index'].tolist()\n",
    "\n",
    "    if target_link in news_dataset['link']:\n",
    "        same_news_index = news_dataset[news_dataset['link']\n",
    "                                       == target_link].index\n",
    "        various_news_index.remove(same_news_index)\n",
    "\n",
    "    logging.info('END BERTopic')\n",
    "\n",
    "    various_news = news_dataset.loc[various_news_index][:3]\n",
    "    result = various_news\n",
    "\n",
    "    result = {\n",
    "        \"news\": {\n",
    "            \"link1\": list(various_news[['link']].iloc[0].values),\n",
    "            \"link2\": list(various_news[['link']].iloc[1].values),\n",
    "            \"link3\": list(various_news[['link']].iloc[2].values)},\n",
    "        \"summary\": {\n",
    "            \"sentence1\": target_summary_[0],\n",
    "            \"sentence2\": target_summary_[1],\n",
    "            \"sentence3\": target_summary_[2]}\n",
    "    }\n",
    "\n",
    "    logging.info('[hunmin log] result : {}'.format(result))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# exec_inference_dataframe() 호출 함수\n",
    "###########################################################################\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout, dim, max_len=5000):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) *\n",
    "                              -(math.log(10000.0) / dim)))\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, emb, step=None):\n",
    "        emb = emb * math.sqrt(self.dim)\n",
    "        if (step):\n",
    "            emb = emb + self.pe[:, step][:, None, :]\n",
    "\n",
    "        else:\n",
    "            emb = emb + self.pe[:, :emb.size(1)]\n",
    "        emb = self.dropout(emb)\n",
    "        return emb\n",
    "\n",
    "    def get_emb(self, emb):\n",
    "        return self.pe[:, :emb.size(1)]\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, d_ff, dropout):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadedAttention(\n",
    "            heads, d_model, dropout=dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, iter, query, inputs, mask):\n",
    "        if (iter != 0):\n",
    "            input_norm = self.layer_norm(inputs)\n",
    "        else:\n",
    "            input_norm = inputs\n",
    "\n",
    "        mask = mask.unsqueeze(1)\n",
    "        context = self.self_attn(input_norm, input_norm, input_norm,\n",
    "                                 mask=mask)\n",
    "        out = self.dropout(context) + inputs\n",
    "        return self.feed_forward(out)\n",
    "\n",
    "\n",
    "class ExtTransformerEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size=768, d_ff=2048, heads=8, dropout=0.2, num_inter_layers=2):\n",
    "        super(ExtTransformerEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_inter_layers = num_inter_layers\n",
    "        self.pos_emb = PositionalEncoding(dropout, hidden_size)\n",
    "        self.transformer_inter = nn.ModuleList(\n",
    "            [TransformerEncoderLayer(hidden_size, heads, d_ff, dropout)\n",
    "             for _ in range(num_inter_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.wo = nn.Linear(hidden_size, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, top_vecs, mask):\n",
    "        \"\"\" See :obj:`EncoderBase.forward()`\"\"\"\n",
    "\n",
    "        batch_size, n_sents = top_vecs.size(0), top_vecs.size(1)\n",
    "        pos_emb = self.pos_emb.pe[:, :n_sents]\n",
    "        x = top_vecs * mask[:, :, None].float()\n",
    "        x = x + pos_emb\n",
    "\n",
    "        for i in range(self.num_inter_layers):\n",
    "            x = self.transformer_inter[i](i, x, x, ~mask)\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        sent_scores = self.sigmoid(self.wo(x))\n",
    "        sent_scores = sent_scores.squeeze(-1) * mask.float()\n",
    "\n",
    "        return sent_scores\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\" A two-layer Feed-Forward-Network with residual layer norm.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): the size of input for the first-layer of the FFN.\n",
    "        d_ff (int): the hidden layer size of the second-layer\n",
    "            of the FNN.\n",
    "        dropout (float): dropout probability in :math:`[0, 1)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def gelu(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        inter = self.dropout_1(self.gelu(self.w_1(self.layer_norm(x))))\n",
    "        output = self.dropout_2(self.w_2(inter))\n",
    "        return output + x\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention module from\n",
    "    \"Attention is All You Need\"\n",
    "    :cite:`DBLP:journals/corr/VaswaniSPUJGKP17`.\n",
    "\n",
    "    Similar to standard `dot` attention but uses\n",
    "    multiple attention distributions simulataneously\n",
    "    to select relevant items.\n",
    "\n",
    "    .. mermaid::\n",
    "\n",
    "       graph BT\n",
    "          A[key]\n",
    "          B[value]\n",
    "          C[query]\n",
    "          O[output]\n",
    "          subgraph Attn\n",
    "            D[Attn 1]\n",
    "            E[Attn 2]\n",
    "            F[Attn N]\n",
    "          end\n",
    "          A --> D\n",
    "          C --> D\n",
    "          A --> E\n",
    "          C --> E\n",
    "          A --> F\n",
    "          C --> F\n",
    "          D --> O\n",
    "          E --> O\n",
    "          F --> O\n",
    "          B --> O\n",
    "\n",
    "    Also includes several additional tricks.\n",
    "\n",
    "    Args:\n",
    "       head_count (int): number of parallel heads\n",
    "       model_dim (int): the dimension of keys/values/queries,\n",
    "           must be divisible by head_count\n",
    "       dropout (float): dropout parameter\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, head_count, model_dim, dropout=0.1, use_final_linear=True):\n",
    "        assert model_dim % head_count == 0\n",
    "        self.dim_per_head = model_dim // head_count\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.head_count = head_count\n",
    "\n",
    "        self.linear_keys = nn.Linear(model_dim,\n",
    "                                     head_count * self.dim_per_head)\n",
    "        self.linear_values = nn.Linear(model_dim,\n",
    "                                       head_count * self.dim_per_head)\n",
    "        self.linear_query = nn.Linear(model_dim,\n",
    "                                      head_count * self.dim_per_head)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.use_final_linear = use_final_linear\n",
    "        if (self.use_final_linear):\n",
    "            self.final_linear = nn.Linear(model_dim, model_dim)\n",
    "\n",
    "    def forward(self, key, value, query, mask=None,\n",
    "                layer_cache=None, type=None, predefined_graph_1=None):\n",
    "        \"\"\"\n",
    "        Compute the context vector and the attention vectors.\n",
    "\n",
    "        Args:\n",
    "           key (`FloatTensor`): set of `key_len`\n",
    "                key vectors `[batch, key_len, dim]`\n",
    "           value (`FloatTensor`): set of `key_len`\n",
    "                value vectors `[batch, key_len, dim]`\n",
    "           query (`FloatTensor`): set of `query_len`\n",
    "                 query vectors  `[batch, query_len, dim]`\n",
    "           mask: binary mask indicating which keys have\n",
    "                 non-zero attention `[batch, query_len, key_len]`\n",
    "        Returns:\n",
    "           (`FloatTensor`, `FloatTensor`) :\n",
    "\n",
    "           * output context vectors `[batch, query_len, dim]`\n",
    "           * one of the attention vectors `[batch, query_len, key_len]`\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = key.size(0)\n",
    "        dim_per_head = self.dim_per_head\n",
    "        head_count = self.head_count\n",
    "        key_len = key.size(1)\n",
    "        query_len = query.size(1)\n",
    "\n",
    "        def shape(x):\n",
    "            \"\"\"  projection \"\"\"\n",
    "            return x.view(batch_size, -1, head_count, dim_per_head) \\\n",
    "                .transpose(1, 2)\n",
    "\n",
    "        def unshape(x):\n",
    "            \"\"\"  compute context \"\"\"\n",
    "            return x.transpose(1, 2).contiguous() \\\n",
    "                .view(batch_size, -1, head_count * dim_per_head)\n",
    "\n",
    "        # 1) Project key, value, and query.\n",
    "        if layer_cache is not None:\n",
    "            if type == \"self\":\n",
    "                query, key, value = self.linear_query(query), \\\n",
    "                    self.linear_keys(query), \\\n",
    "                    self.linear_values(query)\n",
    "\n",
    "                key = shape(key)\n",
    "                value = shape(value)\n",
    "\n",
    "                if layer_cache is not None:\n",
    "                    device = key.device\n",
    "                    if layer_cache[\"self_keys\"] is not None:\n",
    "                        key = torch.cat(\n",
    "                            (layer_cache[\"self_keys\"].to(device), key),\n",
    "                            dim=2)\n",
    "                    if layer_cache[\"self_values\"] is not None:\n",
    "                        value = torch.cat(\n",
    "                            (layer_cache[\"self_values\"].to(device), value),\n",
    "                            dim=2)\n",
    "                    layer_cache[\"self_keys\"] = key\n",
    "                    layer_cache[\"self_values\"] = value\n",
    "            elif type == \"context\":\n",
    "                query = self.linear_query(query)\n",
    "                if layer_cache is not None:\n",
    "                    if layer_cache[\"memory_keys\"] is None:\n",
    "                        key, value = self.linear_keys(key), \\\n",
    "                            self.linear_values(value)\n",
    "                        key = shape(key)\n",
    "                        value = shape(value)\n",
    "                    else:\n",
    "                        key, value = layer_cache[\"memory_keys\"], \\\n",
    "                            layer_cache[\"memory_values\"]\n",
    "                    layer_cache[\"memory_keys\"] = key\n",
    "                    layer_cache[\"memory_values\"] = value\n",
    "                else:\n",
    "                    key, value = self.linear_keys(key), \\\n",
    "                        self.linear_values(value)\n",
    "                    key = shape(key)\n",
    "                    value = shape(value)\n",
    "        else:\n",
    "            key = self.linear_keys(key)\n",
    "            value = self.linear_values(value)\n",
    "            query = self.linear_query(query)\n",
    "            key = shape(key)\n",
    "            value = shape(value)\n",
    "\n",
    "        query = shape(query)\n",
    "\n",
    "        key_len = key.size(2)\n",
    "        query_len = query.size(2)\n",
    "\n",
    "        # 2) Calculate and scale scores.\n",
    "        query = query / math.sqrt(dim_per_head)\n",
    "        scores = torch.matmul(query, key.transpose(2, 3))\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).expand_as(scores)\n",
    "            # how can i fix it to use fp16...\n",
    "            scores = scores.masked_fill(mask, -1e18)\n",
    "\n",
    "        # 3) Apply attention dropout and compute context vectors.\n",
    "\n",
    "        attn = self.softmax(scores)\n",
    "\n",
    "        if (not predefined_graph_1 is None):\n",
    "            attn_masked = attn[:, -1] * predefined_graph_1\n",
    "            attn_masked = attn_masked / \\\n",
    "                (torch.sum(attn_masked, 2).unsqueeze(2) + 1e-9)\n",
    "\n",
    "            attn = torch.cat([attn[:, :-1], attn_masked.unsqueeze(1)], 1)\n",
    "\n",
    "        drop_attn = self.dropout(attn)\n",
    "        if (self.use_final_linear):\n",
    "            context = unshape(torch.matmul(drop_attn, value))\n",
    "            output = self.final_linear(context)\n",
    "            return output\n",
    "        else:\n",
    "            context = torch.matmul(drop_attn, value)\n",
    "            return context\n",
    "\n",
    "\n",
    "class Summarizer(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.max_pos = 512\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            BERT_MODEL_NAME)  # , return_dict=True)\n",
    "        self.ext_layer = ExtTransformerEncoder()\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.loss = nn.BCELoss(reduction='none')\n",
    "\n",
    "        for p in self.ext_layer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)\n",
    "\n",
    "    # , input_ids, attention_mask, labels=None):\n",
    "    def forward(self, src, segs, clss, labels=None):\n",
    "\n",
    "        mask_src = ~(src == 0)  # 1 - (src == 0)\n",
    "        mask_cls = ~(clss == -1)  # 1 - (clss == -1)\n",
    "\n",
    "        top_vec = self.bert(src, token_type_ids=segs, attention_mask=mask_src)\n",
    "        top_vec = top_vec.last_hidden_state\n",
    "\n",
    "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n",
    "        sents_vec = sents_vec * mask_cls[:, :, None].float()\n",
    "\n",
    "        sent_scores = self.ext_layer(sents_vec, mask_cls).squeeze(-1)\n",
    "\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.loss(sent_scores, labels)\n",
    "\n",
    "            loss = (loss * mask_cls.float()).sum() / len(labels)\n",
    "\n",
    "        return loss, sent_scores\n",
    "\n",
    "    def step(self, batch):\n",
    "\n",
    "        src = batch['src']\n",
    "        if len(batch['labels']) > 0:\n",
    "            labels = batch['labels']\n",
    "        else:\n",
    "            labels = None\n",
    "        segs = batch['segs']\n",
    "        clss = batch['clss']\n",
    "\n",
    "        loss, sent_scores = self(src, segs, clss, labels)\n",
    "\n",
    "        return loss, sent_scores, labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def acc_loss(self, outputs):\n",
    "        total_loss = 0\n",
    "        hit_cnt = 0\n",
    "        for outp in outputs:\n",
    "            labels = outp['labels'].cpu()\n",
    "            predictions, idxs = outp['predictions'].cpu().sort()\n",
    "            loss = outp['loss'].cpu()\n",
    "            for label, idx in zip(labels, idxs):\n",
    "                for i in range(1, 3):\n",
    "                    if label[idx[-i-1]] == 1:\n",
    "                        hit_cnt += 1\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "        avg_loss = total_loss / len(outputs)\n",
    "        acc = hit_cnt / (3*len(outputs)*len(labels))\n",
    "\n",
    "        return acc, avg_loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "\n",
    "        print('acc:', acc, 'avg_loss:', avg_loss)\n",
    "\n",
    "        self.log('avg_train_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "\n",
    "        print('val_acc:', acc, 'avg_val_loss:', avg_loss)\n",
    "\n",
    "        self.log('avg_val_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "\n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "\n",
    "        print('test_acc:', acc, 'avg_test_loss:', avg_loss)\n",
    "\n",
    "        self.log('avg_test_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "\n",
    "        steps_per_epoch = 11589 // BATCH_SIZE\n",
    "        total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=steps_per_epoch,\n",
    "            num_training_steps=total_training_steps\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=dict(\n",
    "                scheduler=scheduler,\n",
    "                interval='step'\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "# 문장 분리 함수\n",
    "def data_process(text):\n",
    "    tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "    # 문장 분리 하고,\n",
    "    sents = kss.split_sentences(text)\n",
    "\n",
    "    # 데이터 가공하고,\n",
    "    tokenlist = []\n",
    "    for sent in sents:\n",
    "        tokenlist.append(tokenizer(\n",
    "            text=sent,\n",
    "            add_special_tokens=True))  # , # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "    src = []  # 토크나이징 된 전체 문단\n",
    "    labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
    "    segs = []  # 각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
    "    clss = []  # [CLS]토큰의 포지션값을 지정\n",
    "\n",
    "    odd = 0\n",
    "\n",
    "    for tkns in tokenlist:\n",
    "\n",
    "        if odd > 1:\n",
    "            odd = 0\n",
    "        clss = clss + [len(src)]\n",
    "        src = src + tkns['input_ids']\n",
    "        segs = segs + [odd] * len(tkns['input_ids'])\n",
    "        odd += 1\n",
    "\n",
    "        # truncation\n",
    "        if len(src) == MAX_TOKEN_COUNT:\n",
    "            break\n",
    "        elif len(src) > MAX_TOKEN_COUNT:\n",
    "            src = src[:MAX_TOKEN_COUNT - 1] + [src[-1]]\n",
    "            segs = segs[:MAX_TOKEN_COUNT]\n",
    "            break\n",
    "\n",
    "    # padding\n",
    "    if len(src) < MAX_TOKEN_COUNT:\n",
    "        src = src + [0]*(MAX_TOKEN_COUNT - len(src))\n",
    "        segs = segs + [0]*(MAX_TOKEN_COUNT - len(segs))\n",
    "\n",
    "    if len(clss) < MAX_TOKEN_COUNT:\n",
    "        clss = clss + [-1]*(MAX_TOKEN_COUNT - len(clss))\n",
    "\n",
    "    return dict(\n",
    "        sents=sents,  # 정답 출력을 위해...\n",
    "        src=torch.tensor(src),\n",
    "        segs=torch.tensor(segs),\n",
    "        clss=torch.tensor(clss),\n",
    "    )\n",
    "\n",
    "# 요약본 추출 함수\n",
    "\n",
    "\n",
    "def summarize_test(trained_model, text):\n",
    "    data = data_process(text.replace('\\n', ''))\n",
    "\n",
    "    # trained_model에 넣어 결과값 반환\n",
    "    _, rtn = trained_model(data['src'].unsqueeze(\n",
    "        0), data['segs'].unsqueeze(0), data['clss'].unsqueeze(0))\n",
    "    rtn = rtn.squeeze()\n",
    "\n",
    "    # 예측 결과값을 받기 위한 프로세스\n",
    "    rtn_sort, idx = rtn.sort(descending=True)\n",
    "\n",
    "    rtn_sort = rtn_sort.tolist()\n",
    "    idx = idx.tolist()\n",
    "\n",
    "    end_idx = rtn_sort.index(0)\n",
    "\n",
    "    rtn_sort = rtn_sort[:end_idx]\n",
    "    idx = idx[:end_idx]\n",
    "\n",
    "    if len(idx) > 3:\n",
    "        rslt = idx[:3]\n",
    "    else:\n",
    "        rslt = idx\n",
    "\n",
    "    summ = []\n",
    "    for i, r in enumerate(rslt):\n",
    "        summ.append(data['sents'][r])\n",
    "\n",
    "    return summ\n",
    "\n",
    "# 요약본 결과 반환\n",
    "\n",
    "\n",
    "def summarize_article(trained_model, target_article):\n",
    "    target_summary = summarize_test(trained_model, target_article)\n",
    "    return target_summary\n",
    "\n",
    "\n",
    "# 피어슨 상관계수 구하기\n",
    "def pearson_similarity(a, b):\n",
    "    return np.dot((a-np.mean(a)), (b-np.mean(b)))/((np.linalg.norm(a-np.mean(a)))*(np.linalg.norm(b-np.mean(b))))\n",
    "\n",
    "# 단락 생성\n",
    "\n",
    "\n",
    "def split_into_paragraphs(article, sentences_per_paragraph=3):\n",
    "    sentences = kss.split_sentences(article)\n",
    "    paragraphs = []\n",
    "    paragraph = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 20:\n",
    "            # 보통 한 줄에 20자 정도 넘어가야 유의미한 정보가 포함된 문장임\n",
    "            paragraph.append(sentence)\n",
    "        if len(paragraph) == sentences_per_paragraph:  # 3줄 이상이면\n",
    "            paragraphs.append(\" \".join(paragraph))  # 3줄을 하나로 합치기\n",
    "            paragraph = []\n",
    "\n",
    "        # 남아있는 문장들 중 20자가 넘어가면 단락으로 추가\n",
    "    if paragraph and len(paragraph) > 20:\n",
    "        paragraphs.append(\" \".join(paragraph))\n",
    "\n",
    "    return paragraphs  # 단락 데이터 반환\n",
    "\n",
    "\n",
    "# 크롤링 함수 추가\n",
    "def preprocessing(d):  # 한국어 기사 본문 전처리 함수\n",
    "    d = d.lower()\n",
    "    d = re.sub(r'[a-z0-9\\-_.]{3,}@[a-z0-9\\-_.]{3,}(?:[.]?[a-z]{2})+', ' ', d)\n",
    "    d = re.sub(r'‘’ⓒ\\'\\\"“”…=□*◆:/_]', ' ', d)\n",
    "    d = re.sub(r'\\s+', ' ', d)\n",
    "    d = re.sub(r'^\\s|\\s$', '', d)\n",
    "    d = re.sub(r'[<*>_=\"/■□▷▶]', '', d)\n",
    "    return d\n",
    "\n",
    "\n",
    "def fetch_article_data(article_url):  # 기사 본문, 기자 정보 수집 함수\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    resp = requests.get(article_url, headers=headers)\n",
    "    if resp.status_code != 200:\n",
    "        return \"Failed to retrieve the article\"\n",
    "\n",
    "    article_dom = BeautifulSoup(resp.content, 'html.parser')\n",
    "\n",
    "    # 특정 선택자를 사용하여 기사 본문 추출\n",
    "    content_tag = article_dom.select_one(\n",
    "        'article#dic_area.go_trans._article_content')\n",
    "\n",
    "    content = preprocessing(content_tag.get_text(\n",
    "        strip=True)) if content_tag else ''\n",
    "\n",
    "    # 기자 정보 추출\n",
    "    reporter_tag = article_dom.select_one('div.byline span') or \\\n",
    "        article_dom.select_one('p.byline') or \\\n",
    "        article_dom.select_one('span.byline')\n",
    "\n",
    "    reporter = reporter_tag.get_text(strip=True) if reporter_tag else ''\n",
    "\n",
    "    article_data = {\n",
    "        \"link\": article_url,  # 기사 링크\n",
    "        \"article\": content,  # 기사 본문\n",
    "        \"reporter\": reporter  # 기자\n",
    "    }\n",
    "\n",
    "    return article_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0747321-52c8-4a3f-8f4e-12e40731a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3QAI_TRAIN_OUTPUT_PATH: ./meta_data\n",
      "T3QAI_TRAIN_MODEL_PATH: ./meta_data\n",
      "T3QAI_TRAIN_DATA_PATH: ./meta_data\n",
      "T3QAI_TEST_DATA_PATH: ./meta_data\n",
      "T3QAI_MODULE_PATH: ./meta_data\n",
      "T3QAI_INIT_MODEL_PATH: ./meta_data\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# t3qai_client 클래스: t3qai_client 객체\n",
    "class t3qai_client:\n",
    "    def train_start(self):\n",
    "        return None\n",
    "\n",
    "    def train_finish(self, result, result_msg):\n",
    "        if result_msg != \"success\":\n",
    "            raise Exception(result_msg)\n",
    "        else:\n",
    "            logging.info(result)\n",
    "            logging.info(\"train finish\")\n",
    "\n",
    "    def train_load_param(self):\n",
    "        '''set_param'''\n",
    "        epoch = 10\n",
    "        batch_size = 4\n",
    "        params = {\"epoch\" : epoch, 'batch_size' : batch_size}\n",
    "        return { **params }\n",
    "\n",
    "class PM:\n",
    "    def __init__(self):\n",
    "        self.source_path = './'\n",
    "        self.target_path = './meta_data'\n",
    "\n",
    "\n",
    "class UploadFile:\n",
    "    def __init__(self, file, filename):\n",
    "        self.file = file\n",
    "        self.filename = filename\n",
    "\n",
    "\n",
    "def DownloadFile(file_name, file_obj = None, file_path = None):\n",
    "    file_route = './meta_data/DownloadFiles'\n",
    "    os.makedirs(file_route, exist_ok = True)\n",
    "    file_dir = os.path.join(file_route, file_name)\n",
    "    if (file_obj == None) == (file_path == None):\n",
    "        Err_msg = \"[DownloadFile Error]: Only one of the 'file_path' or 'file_obj' arguments is required.\"\n",
    "        Err_msg += f\"{0 if file_obj==None else 2} arguments entered.\"\n",
    "        raise Exception(Err_msg)\n",
    "    elif(file_obj != None):\n",
    "        file_obj.seek(0)\n",
    "        file_read = base64.b64encode(file_obj.read()).decode('utf-8')\n",
    "        binary_file = base64.b64decode(file_read)\n",
    "        with open(file_dir, 'wb') as f:\n",
    "            f.write(binary_file)\n",
    "    elif(file_path != None):\n",
    "        shutil.copyfile(file_path, file_dir)\n",
    "        \n",
    "    return FileLink(file_dir)\n",
    "\n",
    "\n",
    "pm = PM()\n",
    "\n",
    "T3QAI_TRAIN_OUTPUT_PATH = './meta_data'\n",
    "T3QAI_TRAIN_MODEL_PATH = './meta_data'\n",
    "T3QAI_TRAIN_DATA_PATH = './meta_data'\n",
    "T3QAI_TEST_DATA_PATH = './meta_data'\n",
    "T3QAI_MODULE_PATH = './meta_data'\n",
    "T3QAI_INIT_MODEL_PATH = './meta_data'\n",
    "\n",
    "# t3qai_client 객체\n",
    "tc = t3qai_client()\n",
    "print('T3QAI_TRAIN_OUTPUT_PATH:', T3QAI_TRAIN_OUTPUT_PATH)\n",
    "print('T3QAI_TRAIN_MODEL_PATH:', T3QAI_TRAIN_MODEL_PATH)\n",
    "print('T3QAI_TRAIN_DATA_PATH:', T3QAI_TRAIN_DATA_PATH)\n",
    "print('T3QAI_TEST_DATA_PATH:', T3QAI_TEST_DATA_PATH)\n",
    "print('T3QAI_MODULE_PATH:', T3QAI_MODULE_PATH)\n",
    "print('T3QAI_INIT_MODEL_PATH:', T3QAI_INIT_MODEL_PATH)\n",
    "\n",
    "\n",
    "# init_svc(im, rule) 함수 입력\n",
    "im = None\n",
    "rule = None\n",
    "# transform(df, params, batch_id) 함수 입력\n",
    "batch_id = 0\n",
    "\n",
    "#dataset\n",
    "data=[[\"https://n.news.naver.com/mnews/article/022/0003937314?sid=100\"]]\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# inference_file 함수 추론\n",
    "files = []\n",
    "\n",
    "uploader = FileUpload(accept='*', multiple=True, description='select data', button_style='danger')\n",
    "def uploader_change(change):\n",
    "    uploader.button_style='success'\n",
    "    count = len(uploader.value)\n",
    "    uploader._counter = count\n",
    "    files.clear()\n",
    "    for file_num in range(count):\n",
    "        temp_data = tempfile.TemporaryFile()\n",
    "        if ipywidgets.__version__[0] == '7':\n",
    "            temp_data.write(list(uploader.value.values())[file_num]['content'])\n",
    "            file = UploadFile(temp_data, pd.DataFrame(list(uploader.value.values())[file_num]).iloc[1,0])\n",
    "        elif int(ipywidgets.__version__[0]) > 7:\n",
    "            temp_data.write(uploader.value[file_num].content)\n",
    "            file = UploadFile(temp_data, uploader.value[file_num].name)\n",
    "        files.append(file)\n",
    "\n",
    "uploader.observe(uploader_change, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a106951b-b7b7-4ae5-9e54-c21565c05cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_process]\n",
      "INFO:root:[hunmin log] Files and directories in ./ :\n",
      "INFO:root:[hunmin log] dir_list : ['.jupyter', 'fileviewer', 'lightning_logs', 'dataset.zip', 'meta_data', '.local', '.ipynb_checkpoints', '.nv', '1_local_platform_Perspecive_NewsRec.ipynb', 'test_dataset.zip', '.ipython', '0_local_Perspecive_NewsRec.ipynb', 'checkpoints', '.cache']\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['dataset', 'test_dataset']\n",
      "INFO:root:[hunmin log] the finish line of the function [exec_process]\n",
      "INFO:root:[hunmin log] the end line of the function [process_for_train]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.35 s, sys: 1.38 s, total: 6.73 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_for_train(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0398a0ee-76ea-42de-9415-f5c38a0327d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[train.py] main() start\n",
      "INFO:root:[hunmin log] the start line of the function [exec_train]\n",
      "INFO:root:[hunmin log] T3QAI_TRAIN_DATA_PATH : ./meta_data\n",
      "INFO:root:[hunmin log] pytorch-lightning ver : 1.2.8\n",
      "INFO:root:[hunmin log] train_df : (11589, 5)\n",
      "INFO:root:[hunmin log] val_df : (610, 5)\n",
      "INFO:root:[hunmin log] test_df : (1506, 5)\n",
      "INFO:pytorch_lightning.utilities.seed:Global seed set to 42\n",
      "Some weights of BertModel were not initialized from the model checkpoint at jinmang2/kpfbert and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:'lightning_logs' directory and all its contents have been deleted.\n",
      "INFO:pytorch_lightning.utilities.distributed:EarlyStopping mode set to min for monitoring avg_val_loss.\n",
      "INFO:pytorch_lightning.utilities.distributed:GPU available: True, used: True\n",
      "INFO:pytorch_lightning.utilities.distributed:TPU available: False, using: 0 TPU cores\n",
      "INFO:root:trainer.fit\n",
      "INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.core.lightning:\n",
      "  | Name      | Type                  | Params\n",
      "----------------------------------------------------\n",
      "0 | bert      | BertModel             | 114 M \n",
      "1 | ext_layer | ExtTransformerEncoder | 11.0 M\n",
      "2 | loss      | BCELoss               | 0     \n",
      "----------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "500.230   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]val_acc: 0.125 avg_val_loss: tensor(19.7894)\n",
      "Epoch 0:  88%|████████▊ | 2880/3275 [06:51<00:56,  6.99it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]acc: 1.325971934667587 avg_loss: tensor(5.2949)\n",
      "Epoch 0:  89%|████████▉ | 2910/3275 [06:58<00:52,  6.96it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/377 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 2940/3275 [06:59<00:47,  7.00it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  91%|█████████ | 2970/3275 [07:01<00:43,  7.04it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  92%|█████████▏| 3000/3275 [07:03<00:38,  7.08it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  93%|█████████▎| 3030/3275 [07:05<00:34,  7.12it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  93%|█████████▎| 3060/3275 [07:07<00:30,  7.17it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  94%|█████████▍| 3090/3275 [07:08<00:25,  7.20it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  95%|█████████▌| 3120/3275 [07:10<00:21,  7.24it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  96%|█████████▌| 3150/3275 [07:12<00:17,  7.28it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  97%|█████████▋| 3180/3275 [07:14<00:12,  7.32it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  98%|█████████▊| 3210/3275 [07:16<00:08,  7.36it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0:  99%|█████████▉| 3240/3275 [07:17<00:04,  7.40it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Epoch 0: 100%|█████████▉| 3270/3275 [07:19<00:00,  7.44it/s, loss=4.16, v_num=0, val_loss=19.80, avg_val_loss=19.80, train_loss=2.690]\n",
      "Validating: 100%|██████████| 377/377 [00:22<00:00, 16.74it/s]\u001b[Aval_acc: 0.7360742705570292 avg_val_loss: tensor(4.4717)\n",
      "Epoch 0: 100%|██████████| 3275/3275 [07:20<00:00,  7.43it/s, loss=4.55, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=5.790, avg_train_loss=5.290]\n",
      "                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.distributed:Epoch 0, global step 2897: avg_val_loss reached 4.47167 (best 4.47167), saving model to \"./meta_data/best-checkpoint.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  88%|████████▊ | 2880/3275 [06:52<00:56,  6.98it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]acc: 1.5063262019783759 avg_loss: tensor(4.2561)\n",
      "Epoch 1:  89%|████████▉ | 2910/3275 [06:58<00:52,  6.96it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/377 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 2940/3275 [06:59<00:47,  7.00it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  91%|█████████ | 2970/3275 [07:01<00:43,  7.04it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  92%|█████████▏| 3000/3275 [07:03<00:38,  7.08it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  93%|█████████▎| 3030/3275 [07:05<00:34,  7.12it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  93%|█████████▎| 3060/3275 [07:07<00:30,  7.16it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  94%|█████████▍| 3090/3275 [07:08<00:25,  7.20it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  95%|█████████▌| 3120/3275 [07:10<00:21,  7.24it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  96%|█████████▌| 3150/3275 [07:12<00:17,  7.28it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  97%|█████████▋| 3180/3275 [07:14<00:12,  7.32it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  98%|█████████▊| 3210/3275 [07:16<00:08,  7.36it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1:  99%|█████████▉| 3240/3275 [07:17<00:04,  7.40it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Epoch 1: 100%|█████████▉| 3270/3275 [07:19<00:00,  7.44it/s, loss=4.29, v_num=0, val_loss=4.470, avg_val_loss=4.470, train_loss=4.570, avg_train_loss=5.290]\n",
      "Validating: 100%|██████████| 377/377 [00:22<00:00, 16.74it/s]\u001b[Aval_acc: 0.7329796640141468 avg_val_loss: tensor(4.3586)\n",
      "Epoch 1: 100%|██████████| 3275/3275 [07:20<00:00,  7.43it/s, loss=4.08, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.140, avg_train_loss=4.260]\n",
      "                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.distributed:Epoch 1, global step 5795: avg_val_loss reached 4.35861 (best 4.35861), saving model to \"./meta_data/best-checkpoint.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  88%|████████▊ | 2880/3275 [06:50<00:56,  7.02it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]acc: 1.6111111111111112 avg_loss: tensor(3.7526)\n",
      "Epoch 2:  89%|████████▉ | 2910/3275 [06:56<00:52,  6.99it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/377 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 2940/3275 [06:58<00:47,  7.03it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  91%|█████████ | 2970/3275 [06:59<00:43,  7.07it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  92%|█████████▏| 3000/3275 [07:01<00:38,  7.12it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  93%|█████████▎| 3030/3275 [07:03<00:34,  7.16it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  93%|█████████▎| 3060/3275 [07:05<00:29,  7.20it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  94%|█████████▍| 3090/3275 [07:06<00:25,  7.24it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  95%|█████████▌| 3120/3275 [07:08<00:21,  7.28it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  96%|█████████▌| 3150/3275 [07:10<00:17,  7.31it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  97%|█████████▋| 3180/3275 [07:12<00:12,  7.35it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  98%|█████████▊| 3210/3275 [07:14<00:08,  7.39it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2:  99%|█████████▉| 3240/3275 [07:16<00:04,  7.43it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Epoch 2: 100%|█████████▉| 3270/3275 [07:17<00:00,  7.47it/s, loss=3.55, v_num=0, val_loss=4.360, avg_val_loss=4.360, train_loss=3.690, avg_train_loss=4.260]\n",
      "Validating: 100%|██████████| 377/377 [00:22<00:00, 16.63it/s]\u001b[Aval_acc: 0.7325375773651636 avg_val_loss: tensor(4.5696)\n",
      "Epoch 2: 100%|██████████| 3275/3275 [07:19<00:00,  7.46it/s, loss=3.99, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=4.200, avg_train_loss=3.750]\n",
      "                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.distributed:Epoch 2, step 8693: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  88%|████████▊ | 2880/3275 [06:51<00:56,  7.00it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]acc: 1.8778467908902692 avg_loss: tensor(2.8240)\n",
      "Epoch 3:  89%|████████▉ | 2910/3275 [06:57<00:52,  6.97it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/377 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 2940/3275 [06:59<00:47,  7.01it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  91%|█████████ | 2970/3275 [07:00<00:43,  7.06it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  92%|█████████▏| 3000/3275 [07:02<00:38,  7.10it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  93%|█████████▎| 3030/3275 [07:04<00:34,  7.14it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  93%|█████████▎| 3060/3275 [07:06<00:29,  7.18it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  94%|█████████▍| 3090/3275 [07:08<00:25,  7.22it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  95%|█████████▌| 3120/3275 [07:09<00:21,  7.26it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  96%|█████████▌| 3150/3275 [07:11<00:17,  7.30it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  97%|█████████▋| 3180/3275 [07:13<00:12,  7.34it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  98%|█████████▊| 3210/3275 [07:15<00:08,  7.37it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3:  99%|█████████▉| 3240/3275 [07:17<00:04,  7.41it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Epoch 3: 100%|█████████▉| 3270/3275 [07:18<00:00,  7.45it/s, loss=2.86, v_num=0, val_loss=4.570, avg_val_loss=4.570, train_loss=2.640, avg_train_loss=3.750]\n",
      "Validating: 100%|██████████| 377/377 [00:22<00:00, 16.47it/s]\u001b[Aval_acc: 0.7051282051282052 avg_val_loss: tensor(5.2885)\n",
      "Epoch 3: 100%|██████████| 3275/3275 [07:20<00:00,  7.44it/s, loss=2.77, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=2.160, avg_train_loss=2.820]\n",
      "                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.distributed:Epoch 3, step 11591: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  88%|████████▊ | 2880/3275 [06:50<00:56,  7.02it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]acc: 2.152518978605935 avg_loss: tensor(1.8028)\n",
      "Epoch 4:  89%|████████▉ | 2910/3275 [06:56<00:52,  6.99it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/377 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 2940/3275 [06:58<00:47,  7.03it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  91%|█████████ | 2970/3275 [07:00<00:43,  7.07it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  92%|█████████▏| 3000/3275 [07:02<00:38,  7.11it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  93%|█████████▎| 3030/3275 [07:03<00:34,  7.15it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  93%|█████████▎| 3060/3275 [07:05<00:29,  7.19it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  94%|█████████▍| 3090/3275 [07:07<00:25,  7.23it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  95%|█████████▌| 3120/3275 [07:09<00:21,  7.26it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  96%|█████████▌| 3150/3275 [07:11<00:17,  7.30it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  97%|█████████▋| 3180/3275 [07:13<00:12,  7.34it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  98%|█████████▊| 3210/3275 [07:14<00:08,  7.38it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4:  99%|█████████▉| 3240/3275 [07:16<00:04,  7.42it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Epoch 4: 100%|█████████▉| 3270/3275 [07:18<00:00,  7.46it/s, loss=1.45, v_num=0, val_loss=5.290, avg_val_loss=5.290, train_loss=0.379, avg_train_loss=2.820]\n",
      "Validating: 100%|██████████| 377/377 [00:23<00:00, 16.48it/s]\u001b[Aval_acc: 0.6998231653404067 avg_val_loss: tensor(6.6865)\n",
      "Epoch 4: 100%|██████████| 3275/3275 [07:19<00:00,  7.45it/s, loss=1.57, v_num=0, val_loss=6.690, avg_val_loss=6.690, train_loss=0.351, avg_train_loss=1.800]\n",
      "                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.distributed:Epoch 4, step 14489: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3275/3275 [07:19<00:00,  7.45it/s, loss=1.57, v_num=0, val_loss=6.690, avg_val_loss=6.690, train_loss=0.351, avg_train_loss=1.800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:trainer.test\n",
      "INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 153/153 [00:09<00:00, 17.05it/s]test_acc: 0.775599128540305 avg_test_loss: tensor(4.2092)\n",
      "Testing: 100%|██████████| 153/153 [00:09<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the finish line of the function [exec_train]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_loss': 4.20920467376709, 'test_loss': 4.206791400909424}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the end line of the function [train]\n",
      "INFO:root:None\n",
      "INFO:root:train finish\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33min 10s, sys: 4min 55s, total: 38min 5s\n",
      "Wall time: 38min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# main() 함수에서 train() 함수 실행\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "259f3a9b-f134-459b-96bf-d80ed0d7c470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1e+03 ns, total: 7 µs\n",
      "Wall time: 12.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = init_svc(im, rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3011edda-6ebe-4847-bc39-b90a0240890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#df = transform(df, params, batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cc99375-19bf-4ed9-9d61-f0e8b729af6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] T3QAI_INIT_MODEL_PATH : ./meta_data\n",
      "Some weights of BertModel were not initialized from the model checkpoint at jinmang2/kpfbert and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: bongsoo/kpf-sbert-128d-v1\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n",
      "INFO:root:[hunmin log] the end line of the function [init_model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 49s, sys: 638 ms, total: 1min 49s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_info_dict = init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b648661-6ec4-45d1-aa85-7a2deb4b4759",
   "metadata": {},
   "source": [
    "### CASE [추론 입력 타입 - 추론 출력 타입] : 총 4가지\n",
    "추론 입력 타입 : DataFrame &rarr; 추론 출력 타입 : Dictionary (1가지)    \n",
    "추론 입력 타입 : File &rarr; 추론 출력 타입 : Dictionary, DownloadFile, DownloadFile의 List (3가지)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc9682-8369-453b-b826-060e25e1897b",
   "metadata": {},
   "source": [
    "### CASE  [DataFrame - Dictionary]\n",
    "DataFrame 입력에 대한 추론 결과를 딕셔너리(Dictionary) 형태로 리턴(return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6006a-ab21-49ce-8cde-3283a525f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_inference_dataframe]\n",
      "INFO:root:[hunmin log] news_dataset : (6437, 4)\n",
      "INFO:root:[hunmin log] summary_embedding_dataset : (6437, 128)\n",
      "INFO:root:[hunmin log] paragraph_dataset : (33653, 2)\n",
      "INFO:root:[hunmin log] paragraph_embedding_dataset : (33653, 128)\n",
      "INFO:root:[hunmin log] load dataframe:                                                    0\n",
      "0  https://n.news.naver.com/mnews/article/022/000...\n",
      "WARNING:root:Oh! You have mecab in your environment. Kss will take this as a backend! :D\n",
      "\n",
      "INFO:root:[hunmin log] target_summary : 정부여당을 향해 “차등 지원도 수용하겠다”며 이른 시일 내 협의하자고 제안한 것이다. 당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련법안 당론 채택 예고더불어민주당 이재명 대표가 민생회복지원금과 관련해 고수해오던 ‘보편 지원’ 주장을 내려놨다. 하지만 여당은 ‘차등 지원’을 전제로 하더라도 여전히 민생회복지원금 자체에 부정적인 모습이다.\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "INFO:root:start Similarity\n",
      "INFO:root:end Similarity\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.61it/s]\n",
      "INFO:root:Start BERTopic\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: bongsoo/kpf-sbert-128d-v1\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inference_dataframe(df, model_info_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
