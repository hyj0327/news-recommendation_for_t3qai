{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8ed560-a9f5-4cf5-ba0c-c012f3e790e3",
   "metadata": {},
   "source": [
    "# 로컬 개발 코드\n",
    "- 로컬에서 주피터 노트북(Jupyter Notebook), 주피터 랩(JupyterLab) 또는 파이썬(Python)을 이용한다. \n",
    "- 사이킷 런(scikit-learn), 텐서플로우(tensorflow), 파이토치(pytorch)를 사용하여 딥러닝 프로그램을 개발한다.\n",
    "- 파일명: 0_local_Perspecive_NewsRec.ipynb\n",
    "\n",
    "### 로컬 개발 워크플로우(workflow)  \n",
    "- 로컬 개발 워크플로우를 다음의 4단계로 분리한다.\n",
    "\n",
    "1. 데이터 세트 준비(Data Setup)\n",
    "- 로컬 저장소에서 전처리 및 학습에 필요한 학습 데이터 세트를 준비한다.\n",
    "\n",
    "2. 데이터 전처리(Data Preprocessing)\n",
    "- 데이터 세트의 분석 및 정규화(Normalization)등의 전처리를 수행한다.\n",
    "- 데이터를 모델 학습에 사용할 수 있도록 가공한다.\n",
    "- 추론과정에서 필요한 경우, 데이터 전처리에 사용된 객체를 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "3. 학습 모델 훈련(Train Model)\n",
    "- 데이터를 훈련에 사용할 수 있도록 가공한 뒤에 학습 모델을 구성한다. \n",
    "- 학습 모델을 준비된 데이터 세트로 훈련시킨다.\n",
    "- 정확도(Accuracy)나 손실(Loss)등 학습 모델의 성능을 검증한다.\n",
    "- 학습 모델의 성능 검증 후, 학습 모델을 배포한다.\n",
    "- 배포할 학습 모델을 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "4. 추론(Inference)\n",
    "- 저장된 전처리 객체나 학습 모델 객체를 준비한다.\n",
    "- 추론에 필요한 테스트 데이터 세트를 준비한다.\n",
    "- 배포된 학습 모델을 통해 테스트 데이터에 대한 추론을 진행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29fd662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ ------------\n",
      "absl-py                  2.1.0\n",
      "aiohttp                  3.9.5\n",
      "aiosignal                1.3.1\n",
      "async-timeout            4.0.3\n",
      "bertopic                 0.16.2\n",
      "bidict                   0.23.1\n",
      "bs4                      0.0.2\n",
      "click                    8.1.7\n",
      "cmudict                  1.0.25\n",
      "Cython                   0.29.37\n",
      "Distance                 0.1.3\n",
      "emoji                    1.2.0\n",
      "faiss-gpu                1.7.2\n",
      "filelock                 3.13.1\n",
      "frozenlist               1.4.1\n",
      "fsspec                   2024.2.0\n",
      "future                   1.0.0\n",
      "grpcio                   1.64.1\n",
      "hangul-jamo              1.0.1\n",
      "hdbscan                  0.8.37\n",
      "huggingface-hub          0.23.4\n",
      "importlib_metadata       8.0.0\n",
      "importlib_resources      6.4.0\n",
      "iniconfig                2.0.0\n",
      "jamo                     0.4.1\n",
      "joblib                   1.4.2\n",
      "kollocate                0.0.2\n",
      "koparadigm               0.10.0\n",
      "kss                      6.0.4\n",
      "lightning-utilities      0.11.3.post0\n",
      "llvmlite                 0.43.0\n",
      "Markdown                 3.6\n",
      "mpmath                   1.3.0\n",
      "multidict                6.0.5\n",
      "networkx                 3.2.1\n",
      "nltk                     3.8.1\n",
      "numba                    0.60.0\n",
      "numpy                    1.26.4\n",
      "nvidia-cublas-cu11       11.11.3.6\n",
      "nvidia-cuda-cupti-cu11   11.8.87\n",
      "nvidia-cuda-nvrtc-cu11   11.8.89\n",
      "nvidia-cuda-runtime-cu11 11.8.89\n",
      "nvidia-cudnn-cu11        8.7.0.84\n",
      "nvidia-cufft-cu11        10.9.0.58\n",
      "nvidia-curand-cu11       10.3.0.86\n",
      "nvidia-cusolver-cu11     11.4.1.48\n",
      "nvidia-cusparse-cu11     11.7.5.86\n",
      "nvidia-nccl-cu11         2.19.3\n",
      "nvidia-nvtx-cu11         11.8.86\n",
      "pandas                   2.2.2\n",
      "pecab                    1.0.8\n",
      "pillow                   10.2.0\n",
      "pip                      24.1.1\n",
      "plotly                   5.22.0\n",
      "pluggy                   1.5.0\n",
      "protobuf                 4.25.3\n",
      "pyarrow                  16.1.0\n",
      "pybind11                 2.9.2\n",
      "pynndescent              0.5.13\n",
      "pytest                   8.2.2\n",
      "python-mecab-ko          1.3.5\n",
      "python-mecab-ko-dic      2.1.1.post2\n",
      "pytorch-lightning        1.2.8\n",
      "pytz                     2024.1\n",
      "PyYAML                   6.0\n",
      "regex                    2024.5.15\n",
      "scikit-learn             1.4.2\n",
      "scipy                    1.14.0\n",
      "sentence-transformers    2.2.2\n",
      "sentencepiece            0.2.0\n",
      "sympy                    1.12\n",
      "tenacity                 8.5.0\n",
      "tensorboard              2.17.0\n",
      "tensorboard-data-server  0.7.2\n",
      "threadpoolctl            3.5.0\n",
      "tokenizers               0.13.3\n",
      "torch                    2.2.0+cu118\n",
      "torchaudio               2.2.0+cu118\n",
      "torchmetrics             1.4.0.post0\n",
      "torchvision              0.17.0+cu118\n",
      "tossi                    0.3.1\n",
      "tqdm                     4.66.4\n",
      "transformers             4.23.0\n",
      "triton                   2.2.0\n",
      "tzdata                   2024.1\n",
      "umap-learn               0.5.6\n",
      "Unidecode                1.3.8\n",
      "Werkzeug                 3.0.3\n",
      "Whoosh                   2.7.4\n",
      "xlrd                     1.2.0\n",
      "yarl                     1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4b2b2-b9f5-4d81-868b-fee458aa0dba",
   "metadata": {},
   "source": [
    "## 뉴스에 반하다\n",
    "- 이슈성 정보를 다루는 뉴스에서 기존 관점 다른 관점을 제공해 주어 확증 편향을 완화\n",
    "- 비판적인 사고력과 자기 객관화 능력 및 정보 분별력 등의 능력 신장에 도움을 주는 프로그램 구축을 목표로 함.\n",
    "\n",
    "### 사용할 데이터\n",
    "- (기존)매일 22시마다 기사 자동 수집 -> (변경: 고정 DB 사용) 민희진, 밀양사적제재, 북한 오물풍선, 의사 파업, 25만원 총 5개의 키워드로 각각 크롤링한 뉴스 (총 6437개)\n",
    "- json 파일(기사 데이터), npy 파일 (임베딩 데이터)\n",
    "- 문서 요약 데이터 (AI-HUB 제공)\n",
    "\n",
    "### 사용할 요소\n",
    "- 뉴스 제목, 링크, 기사본문\n",
    "- 요약모델 훈련을 위해 문서 요약 데이터 사용\n",
    "- 수집한 기사 본문 바탕으로 요약문장 뽑아내기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3e1822-3889-469c-83fc-05cbefa9ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import json\n",
    " \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import kss\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "import faiss\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7247ba-2b2f-468e-bc04-ca64b66d73d2",
   "metadata": {},
   "source": [
    "## **1. 데이터셋 준비(Data Setup)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe3d6ae-1deb-407a-9855-7bef893c0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.zip 파일 압축 풀기\n",
    "zip_source_path = './dataset.zip'\n",
    "zip_target_path = './meta_data'\n",
    "\n",
    "extract_zip_file = zipfile.ZipFile(zip_source_path)\n",
    "extract_zip_file.extractall(zip_target_path)\n",
    " \n",
    "extract_zip_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fea1f-45d0-4c30-b641-15b63fc117e3",
   "metadata": {},
   "source": [
    "### 뉴스 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4a017f-3131-473e-8be8-146b2df2d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = './meta_data/dataset/'\n",
    "\n",
    "# 뉴스 데이터셋\n",
    "dataset='news.json'\n",
    "news_dataset=pd.read_json(my_path+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d728d91-2648-4b6d-a345-5227ec8df9a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>1979</td>\n",
       "      <td>영동 야산서 발견된 북한 오물 풍선</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>안성수 기자  9일 낮 12시29분 충북 영동군 황간면 인근 야산 중턱에서 북한 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>4470</td>\n",
       "      <td>세브란스도 멈춘다…환자들 \"고소·고발 불사\"</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/009/000...</td>\n",
       "      <td>◆ 의정갈등 ◆서울대병원에 이어 세브란스병원도 '무기한 휴진'을 결정했다. 또 서울...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>4812</td>\n",
       "      <td>사직 전공의 “의대 증원, 의료 위기 해결 못해”…전세계 의사에 호소</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/056/001...</td>\n",
       "      <td>병원을 집단 사직한 전공의들이 세계의사회 행사에서 정부의 의대 증원 정책을 강하게 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>4036</td>\n",
       "      <td>한덕수 총리 \"의사협회 총파업 예고, 깊은 유감\"</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/421/000...</td>\n",
       "      <td>박정호 기자  한덕수 국무총리가 9일 오후 서울 종로구 세종대로 정부서울청사에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>5159</td>\n",
       "      <td>한국 의료 현실과 성수동의 공통점은?</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/036/000...</td>\n",
       "      <td>성수의원은 요즘 서울 최고의 핫플레이스라는 성동구 성수동에 있는 가정의학과 의원이다...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                   title  \\\n",
       "1979   1979                     영동 야산서 발견된 북한 오물 풍선   \n",
       "4470   4470                세브란스도 멈춘다…환자들 \"고소·고발 불사\"   \n",
       "4812   4812  사직 전공의 “의대 증원, 의료 위기 해결 못해”…전세계 의사에 호소   \n",
       "4036   4036             한덕수 총리 \"의사협회 총파업 예고, 깊은 유감\"   \n",
       "5159   5159                    한국 의료 현실과 성수동의 공통점은?   \n",
       "\n",
       "                                                   link  \\\n",
       "1979  https://n.news.naver.com/mnews/article/003/001...   \n",
       "4470  https://n.news.naver.com/mnews/article/009/000...   \n",
       "4812  https://n.news.naver.com/mnews/article/056/001...   \n",
       "4036  https://n.news.naver.com/mnews/article/421/000...   \n",
       "5159  https://n.news.naver.com/mnews/article/036/000...   \n",
       "\n",
       "                                                article  \n",
       "1979   안성수 기자  9일 낮 12시29분 충북 영동군 황간면 인근 야산 중턱에서 북한 ...  \n",
       "4470  ◆ 의정갈등 ◆서울대병원에 이어 세브란스병원도 '무기한 휴진'을 결정했다. 또 서울...  \n",
       "4812  병원을 집단 사직한 전공의들이 세계의사회 행사에서 정부의 의대 증원 정책을 강하게 ...  \n",
       "4036   박정호 기자  한덕수 국무총리가 9일 오후 서울 종로구 세종대로 정부서울청사에서 ...  \n",
       "5159  성수의원은 요즘 서울 최고의 핫플레이스라는 성동구 성수동에 있는 가정의학과 의원이다...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 뉴스 기사 예시 5개\n",
    "news_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a262b609-3d59-4862-9601-3c2df2d8db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 뉴스기사 수 , 컬럼 수)\n",
      "(6437, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"( 뉴스기사 수 , 컬럼 수)\")\n",
    "print(news_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce121e58-7a82-48ab-bfca-3bc1b54ae645",
   "metadata": {},
   "source": [
    "### 저장된 뉴스들의 요약 임베딩 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c89107-2525-4ab9-b0fb-044f9f0e60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 요약 임베딩 데이터\n",
    "dataset='summary_embedding.npy'\n",
    "summary_embedding_dataset=np.load(my_path+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe09e20-95ea-4f8b-bba3-fe24accb7fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 뉴스 개수 ,임베딩 차원 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6437, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"( 뉴스 개수 ,임베딩 차원 )\")\n",
    "summary_embedding_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be29d176-6ab0-4fc1-b4b6-693cae19a1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.80979604e-01,  6.20539337e-02, -6.83445334e-02, -1.19693622e-01,\n",
       "        2.08823726e-01, -1.24537600e-02,  1.18500881e-01,  2.92633682e-01,\n",
       "        1.27883732e-01, -1.22530796e-01,  1.88773751e-01,  1.58757374e-01,\n",
       "        7.53097832e-02,  9.50985700e-02,  1.99547485e-02,  1.87469363e-01,\n",
       "        2.95771599e-01,  9.03890282e-02,  1.81211784e-01,  5.51250339e-01,\n",
       "        4.68128473e-02, -1.96054339e-01, -2.05385476e-01,  2.59385973e-01,\n",
       "       -2.40323737e-01, -1.36626616e-01,  4.44304973e-01, -2.42111281e-01,\n",
       "       -4.77627926e-02,  2.79585384e-02, -3.09917122e-01,  1.79996401e-01,\n",
       "        1.54761756e-02, -1.70492396e-01, -3.24941099e-01, -8.85238275e-02,\n",
       "        1.71700209e-01, -1.93334967e-02,  1.79288030e-01, -4.81512427e-01,\n",
       "        1.27589509e-01,  7.58003443e-05, -2.44617552e-01, -4.17773165e-02,\n",
       "       -1.59207672e-01,  2.16412395e-02,  2.14116201e-01,  9.37071070e-02,\n",
       "       -2.15679660e-01, -1.72768682e-01,  2.53318340e-01, -1.23410642e-01,\n",
       "       -2.44821072e-01, -3.28746915e-01, -2.58230209e-01,  1.05982825e-01,\n",
       "       -3.59924440e-03, -1.01242088e-01, -1.01576731e-01, -8.44142437e-02,\n",
       "        1.48059860e-01,  1.46052716e-02,  2.17478797e-01,  2.69541532e-01,\n",
       "        1.02762133e-05, -2.64144659e-01, -1.19165450e-01,  1.50048152e-01,\n",
       "        8.67998824e-02, -2.57185876e-01, -1.13905616e-01, -4.41240659e-03,\n",
       "        1.14259906e-01,  1.36371166e-01, -1.90132752e-01, -1.94488063e-01,\n",
       "        4.13919896e-01, -3.44066501e-01,  2.92964756e-01, -1.62649184e-01,\n",
       "        9.74547770e-03, -1.11651383e-01, -6.55310899e-02, -3.39726925e-01,\n",
       "        7.99174979e-02, -1.42821565e-01, -1.11291260e-01, -3.00508142e-01,\n",
       "        5.37751652e-02,  1.71349391e-01, -2.84691840e-01,  3.27201039e-02,\n",
       "       -2.50546962e-01,  1.70688599e-01, -2.44593665e-01,  3.17729115e-01,\n",
       "        4.02716070e-01, -1.70131773e-01, -9.65653807e-02,  2.01350719e-01,\n",
       "        1.56636849e-01,  1.92686573e-01,  2.73971826e-01,  1.20396025e-01,\n",
       "        3.65866840e-01, -1.01585582e-01,  1.60898671e-01,  1.91246435e-01,\n",
       "       -1.90956607e-01, -1.84263036e-01, -6.17366023e-02, -8.01492110e-02,\n",
       "        4.17187475e-02, -1.08386442e-01, -1.29042193e-01,  7.14366436e-02,\n",
       "       -2.84157693e-01, -1.41429156e-01, -2.41391584e-01,  1.33219749e-01,\n",
       "       -2.94684507e-02,  2.42987335e-01, -4.66544293e-02, -7.04013333e-02,\n",
       "        9.11332965e-02, -3.04981936e-02, -2.64742464e-01, -3.51791233e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_embedding_dataset[0] # 첫 번째 기사의 요약 임베딩 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149bb7f-e951-49b0-b994-6a7ce13ea8a3",
   "metadata": {},
   "source": [
    "### 저장된 뉴스들의 단락 데이터\n",
    "- index: 기사 번호\n",
    "- paragraph: 단락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3b1393-1c41-459d-9241-14e0a142ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 기사들의 단락 데이터\n",
    "dataset='paragraph_data.json'\n",
    "paragraph_dataset=pd.read_json(my_path+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cef3e13-bd38-4f9c-ab78-96d49a1cd74b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>과거에 비해 다소 살이 빠진 듯한 방시혁 하이브 의장의 모습이 소셜미디어(sns) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>방 의장은 전날 자신의 인스타그램 계정에 진과 함께 찍은 사진을 공개하며 “성공적인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>이날 개최한 팬 이벤트는 진의 전역 후 첫 행사이자, bts의 데뷔 11주년 행사였...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>방시혁 하이브 의장이 지난달 28일 오후 무함마드 빈 자예드 알 나흐얀 아랍에미리트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>줄곧 침묵을 유지하던 방 의장은 지난달 17일 법원에 제출한 탄원서를 통해 “한 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33648</th>\n",
       "      <td>6435</td>\n",
       "      <td>이 대표는 경남 창원 민주당 경남도당에서 열린 현장 선거대책위원회에서 같은 당 김경...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33649</th>\n",
       "      <td>6435</td>\n",
       "      <td>이 대표는 전날 자신이 내놓은 ‘국민 1인당 25만원씩(총 13조원 추산) 민생회복...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33650</th>\n",
       "      <td>6435</td>\n",
       "      <td>국민의힘은 세 자녀 등록금 면제 대상은 34만명이고, 들어갈 예산은 1조4500억원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33651</th>\n",
       "      <td>6435</td>\n",
       "      <td>세 자녀 가구에 지원되는 전기요금, 도시가스, 지역난방비 감면을 두 자녀 가구로 확...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33652</th>\n",
       "      <td>6436</td>\n",
       "      <td>○…더불어민주당 경기 하남갑에 전략공천된 추미애, 코미디 프로그램에 출연, 이재명과...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33653 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                          paragraph\n",
       "0          0  과거에 비해 다소 살이 빠진 듯한 방시혁 하이브 의장의 모습이 소셜미디어(sns) ...\n",
       "1          0  방 의장은 전날 자신의 인스타그램 계정에 진과 함께 찍은 사진을 공개하며 “성공적인...\n",
       "2          0  이날 개최한 팬 이벤트는 진의 전역 후 첫 행사이자, bts의 데뷔 11주년 행사였...\n",
       "3          0  방시혁 하이브 의장이 지난달 28일 오후 무함마드 빈 자예드 알 나흐얀 아랍에미리트...\n",
       "4          0  줄곧 침묵을 유지하던 방 의장은 지난달 17일 법원에 제출한 탄원서를 통해 “한 사...\n",
       "...      ...                                                ...\n",
       "33648   6435  이 대표는 경남 창원 민주당 경남도당에서 열린 현장 선거대책위원회에서 같은 당 김경...\n",
       "33649   6435  이 대표는 전날 자신이 내놓은 ‘국민 1인당 25만원씩(총 13조원 추산) 민생회복...\n",
       "33650   6435  국민의힘은 세 자녀 등록금 면제 대상은 34만명이고, 들어갈 예산은 1조4500억원...\n",
       "33651   6435  세 자녀 가구에 지원되는 전기요금, 도시가스, 지역난방비 감면을 두 자녀 가구로 확...\n",
       "33652   6436  ○…더불어민주당 경기 하남갑에 전략공천된 추미애, 코미디 프로그램에 출연, 이재명과...\n",
       "\n",
       "[33653 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830d81c4-4c04-4c2f-92da-7ddf99948891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 단락 총 개수 , 컬럼 수)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33653, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"( 단락 총 개수 , 컬럼 수)\")\n",
    "paragraph_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff748b7-d3b2-4493-8f67-d47f757b746b",
   "metadata": {},
   "source": [
    "### 저장된 뉴스들의 단락 임베딩 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7071fc5-8c68-40e1-b4c8-1156d7f24cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 기사들의 단락 임베딩 데이터\n",
    "dataset='paragraph_embedding.npy'\n",
    "paragraph_embedding_dataset=np.load(my_path+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87dc2330-e50f-46e2-bd25-3d537ed43761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 단락 총 개수 , 임베딩 차원 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33653, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"( 단락 총 개수 , 임베딩 차원 )\")\n",
    "paragraph_embedding_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6718ee0a-3954-48c6-959d-d54ab6f679c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.27881664e-01  1.14686206e-01 -3.37897390e-02 -1.89114317e-01\n",
      "  2.53429800e-01  5.00494204e-02  1.96555123e-01  2.81413555e-01\n",
      "  1.71784639e-01 -1.66616380e-01  2.19282180e-01  1.76256597e-01\n",
      " -7.33617367e-03  2.34767750e-01  5.44347195e-03  4.07325588e-02\n",
      "  1.38898820e-01  1.18467353e-01  3.30788307e-02  5.21330237e-01\n",
      "  1.35957694e-03 -1.89961404e-01 -1.63521573e-01  2.78955787e-01\n",
      " -2.86507934e-01 -2.54717767e-01  4.47581232e-01 -1.88536391e-01\n",
      " -8.64003524e-02  1.46690339e-01 -2.52024174e-01  2.27498025e-01\n",
      "  9.02265385e-02 -9.52593833e-02 -3.43573064e-01 -6.72127530e-02\n",
      "  1.05423577e-01  1.75513811e-02  1.22265011e-01 -4.44901586e-01\n",
      "  1.70518607e-01 -1.24860844e-02 -2.04270840e-01 -1.10439554e-01\n",
      " -1.18234046e-02  7.24388808e-02  2.57121265e-01  8.17412436e-02\n",
      " -1.05895422e-01 -1.48167774e-01  1.48221895e-01  4.64897156e-02\n",
      " -5.93772121e-02 -3.49758297e-01 -2.06938535e-01  1.65401340e-01\n",
      " -7.27411285e-02 -3.06901336e-02 -1.07786343e-01 -9.71050113e-02\n",
      "  1.97121829e-01  3.32890861e-02  1.92985997e-01  2.20371261e-01\n",
      " -1.27229886e-02 -3.56303245e-01 -9.87922251e-02  5.62584512e-02\n",
      "  1.33638933e-01 -2.01404244e-01 -9.41236019e-02  2.17463952e-02\n",
      "  1.45707324e-01  1.39304414e-01 -2.37362340e-01 -1.61136881e-01\n",
      "  3.73980194e-01 -4.02835667e-01  3.58195573e-01 -2.82543123e-01\n",
      " -4.82358336e-02 -1.95789099e-01 -1.22501515e-01 -2.48587251e-01\n",
      "  1.39765412e-01 -1.55362114e-01 -3.55676338e-02 -3.03247720e-01\n",
      "  6.18085207e-04  1.32466838e-01 -3.06282729e-01  8.85585602e-03\n",
      " -2.38801792e-01  1.40107781e-01 -2.26175487e-01  3.09051454e-01\n",
      "  3.95781696e-01 -1.41426131e-01 -1.06918842e-01  7.22622573e-02\n",
      "  6.72940984e-02  3.11411768e-01  3.60950619e-01  1.54879302e-01\n",
      "  3.00136983e-01 -1.38371333e-01  2.35705271e-01  1.63807705e-01\n",
      " -2.19902501e-01 -2.53790200e-01 -1.38265789e-01 -7.51607940e-02\n",
      "  4.27093804e-02 -1.32023260e-01 -1.90597564e-01  5.44844642e-02\n",
      " -2.11042255e-01 -1.96340814e-01 -1.63644359e-01  2.56985128e-01\n",
      " -1.84862893e-02  1.99931979e-01 -3.81284468e-02  1.44880265e-04\n",
      "  1.93769746e-02  1.16702979e-02 -2.17091024e-01  1.32574722e-01]\n"
     ]
    }
   ],
   "source": [
    "print(paragraph_embedding_dataset[0])# 첫번째 기사의 1번 단락 임베딩 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ff03a-fdaa-4fd8-ae42-6079fa2e8eb9",
   "metadata": {},
   "source": [
    "### 요약 모델 훈련을 위한 데이터셋\n",
    "- AI Hub 문서요약텍스트 데이터셋 (신문 기사 데이터셋)\n",
    "- https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffe0e181-a750-40bd-b786-af7c984021cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / valid dataset\n",
    "train_dataset=pd.read_json(my_path+'train_original.json')\n",
    "valid_dataset=pd.read_json(my_path+'valid_original.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f4e8e08-da7c-4aff-9a70-3a8c49c5a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340626877', 'category': '정치', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340626896', 'category': '종합', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340626904', 'category': 'IT,과학', 'medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340627450', 'category': '사회', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '340627465', 'category': '경제', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30117</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350851474', 'category': '종합', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30118</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350851925', 'category': '경제', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30119</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350854748', 'category': '종합', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350857648', 'category': '종합', 'media_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30121</th>\n",
       "      <td>문서요약 프로젝트</td>\n",
       "      <td>2020-12-23 12:01:15</td>\n",
       "      <td>{'id': '350861693', 'category': '경제', 'media_t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name        delivery_date  \\\n",
       "0      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "1      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "2      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "3      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "4      문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "...          ...                  ...   \n",
       "30117  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "30118  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "30119  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "30120  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "30121  문서요약 프로젝트  2020-12-23 12:01:15   \n",
       "\n",
       "                                               documents  \n",
       "0      {'id': '340626877', 'category': '정치', 'media_t...  \n",
       "1      {'id': '340626896', 'category': '종합', 'media_t...  \n",
       "2      {'id': '340626904', 'category': 'IT,과학', 'medi...  \n",
       "3      {'id': '340627450', 'category': '사회', 'media_t...  \n",
       "4      {'id': '340627465', 'category': '경제', 'media_t...  \n",
       "...                                                  ...  \n",
       "30117  {'id': '350851474', 'category': '종합', 'media_t...  \n",
       "30118  {'id': '350851925', 'category': '경제', 'media_t...  \n",
       "30119  {'id': '350854748', 'category': '종합', 'media_t...  \n",
       "30120  {'id': '350857648', 'category': '종합', 'media_t...  \n",
       "30121  {'id': '350861693', 'category': '경제', 'media_t...  \n",
       "\n",
       "[30122 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b16a7-2b61-441e-a016-4762593b028d",
   "metadata": {},
   "source": [
    "## **2. 데이터 전처리 (Data Preprocessing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a511f6d-8edd-43f9-8a00-52d83b143813",
   "metadata": {},
   "source": [
    "### 데이터 준비 (Preparing Data)\n",
    "요약모델을 위한 데이터셋을 훈련에 사용할 수 있는 형태로 변형\n",
    "\n",
    "- 결측 데이터 삭제\n",
    "- 훈련/테스트 데이터셋을 9.5:0.5 비율로 나눔\n",
    "- 기존 데이터셋이었던 Bflysoft에서 제공한 뉴스 데이터가 비공개처리 되어 대체 데이터셋인 AI-HUB 문서 요약 데이터셋을 기존 데이터셋처럼 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7813e8b8-42d2-4211-b025-a6cb6fb2b448",
   "metadata": {},
   "source": [
    "#### 결측 데이터 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb70c753-c9cc-4901-adc0-9b521e53974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset 수:243983\n",
      "valid_dataset 수:30122\n"
     ]
    }
   ],
   "source": [
    "train_dataset=train_dataset.dropna()\n",
    "print(\"train_dataset 수:\"+str(len(train_dataset)))\n",
    "\n",
    "valid_dataset=valid_dataset.dropna()\n",
    "print(\"valid_dataset 수:\"+str(len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74946e26-6070-4e06-840f-46b11a21f54c",
   "metadata": {},
   "source": [
    "# 훈련 & 평가 데이터셋 생성\n",
    "\n",
    "훈련 데이터셋에서 0.05를 valid 데이터셋으로 사용 (https://github.com/KPFBERT/kpfbertsum/blob/main/kpfbert_summary.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d49569a0-d6fd-42dd-b789-25de1ed29845",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df=train_test_split(train_dataset, test_size=0.05)\n",
    "test_df=valid_dataset\n",
    "train_df=train_df.reset_index(drop=True)\n",
    "val_df=val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf30642-a62c-4b3b-9f4b-4442a30bc495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 훈련 데이터 개수 , 검증 데이터 수, 테스트 데이터 수)\n",
      "(231783, 3) (12200, 3) (30122, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"( 훈련 데이터 개수 , 검증 데이터 수, 테스트 데이터 수)\")\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfef6ee-0334-4b1f-bf94-242852e97000",
   "metadata": {},
   "source": [
    "#### 기존 Bflysoft-뉴스기사 데이터셋에 맞춰 변환\n",
    "- 기존에 Bflysoft-뉴스기사 데이터셋에 맞춰 작성된 코드이나 해당 데이터셋이 비공개되어 AI-HUB 데이터셋을 변형시켜 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d6a6848-12e7-4ce0-8583-caa1eeb4ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    outs = []\n",
    "    for doc in data['documents']:\n",
    "        line = []\n",
    "        line.append(doc['media_name'])\n",
    "        line.append(doc['id'])\n",
    "        para = []\n",
    "        for sent in doc['text']:\n",
    "            for s in sent:\n",
    "                para.append(s['sentence'])\n",
    "        line.append(para)\n",
    "        line.append(doc['abstractive'][0])\n",
    "        line.append(doc['extractive'])\n",
    "        a = doc['extractive']\n",
    "        if a[0] == None or a[1] == None or a[2] == None:\n",
    "            continue\n",
    "        outs.append(line)\n",
    "\n",
    "    outs_df = pd.DataFrame(outs)\n",
    "    outs_df.columns = ['media', 'id', 'article_original', 'abstractive', 'extractive']\n",
    "    return outs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7dc11e1-523f-45f1-a8b8-577df4b8e907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이데일리</td>\n",
       "      <td>335378515</td>\n",
       "      <td>[주연테크(044380)는 최신 엔비디아 지포스 RTX 그래픽카드를 탑재한 '리오나...</td>\n",
       "      <td>25일 주연테크는 엔비디아 지포스 RTX2060와 RTX2070 Max-Q의 그래픽...</td>\n",
       "      <td>[0, 2, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  이데일리  335378515  [주연테크(044380)는 최신 엔비디아 지포스 RTX 그래픽카드를 탑재한 '리오나...   \n",
       "\n",
       "                                         abstractive extractive  \n",
       "0  25일 주연테크는 엔비디아 지포스 RTX2060와 RTX2070 Max-Q의 그래픽...  [0, 2, 4]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = preprocess_data(train_df)\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "162e65fd-fdff-4eb7-a5d8-848ee143fd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한국경제</td>\n",
       "      <td>340626877</td>\n",
       "      <td>[[ 박재원 기자 ] '대한민국 5G 홍보대사'를 자처한 문재인 대통령은 \"넓고, ...</td>\n",
       "      <td>8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...</td>\n",
       "      <td>[0, 1, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  한국경제  340626877  [[ 박재원 기자 ] '대한민국 5G 홍보대사'를 자처한 문재인 대통령은 \"넓고, ...   \n",
       "\n",
       "                                         abstractive extractive  \n",
       "0  8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...  [0, 1, 3]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = preprocess_data(test_df)\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a83ad4e7-7d14-4e1f-b5d6-8ab5bc401686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전라일보</td>\n",
       "      <td>353958386</td>\n",
       "      <td>[비공개 최고위원 간담회 열고 위원회 구성·총선 전략 논의, 김형민 기자l jal7...</td>\n",
       "      <td>복수의 민주당 관계자들에 따르면 이해찬 대표 등 당 지도부는 내년 4월 총선을 대비...</td>\n",
       "      <td>[2, 5, 14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  전라일보  353958386  [비공개 최고위원 간담회 열고 위원회 구성·총선 전략 논의, 김형민 기자l jal7...   \n",
       "\n",
       "                                         abstractive  extractive  \n",
       "0  복수의 민주당 관계자들에 따르면 이해찬 대표 등 당 지도부는 내년 4월 총선을 대비...  [2, 5, 14]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = preprocess_data(val_df)\n",
    "val_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afdb771a-c927-44f2-a6b3-5eb0ef76d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빠른 훈련을 위해 데이터셋 줄임\n",
    "train_df=train_df.sample(frac=0.05)\n",
    "test_df=test_df.sample(frac=0.05)\n",
    "val_df=val_df.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f360522-b2dc-47c3-922e-f21942a94b72",
   "metadata": {},
   "source": [
    "## **3. 학습 모델 훈련 (Train Model)**\n",
    "요약 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b846670b-2e46-4ee2-968f-b05f60bd3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27271784-7a46-4b44-af9b-d55f9f185552",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = 'jinmang2/kpfbert'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a93e4fda-936e-4360-9708-a903630aa4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 512\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c9099-50ab-4c6f-b28e-0e88c2efe2a0",
   "metadata": {},
   "source": [
    "bert에서 여러문장을 입력하기 위해 presumm 에서 제안한 형식으로 인코딩 한다.\n",
    "\n",
    "- token embedding : < CLS > 문장 < SEP > 문장 < SEP > 문장 ... 문장 < SEP >\n",
    "- interval segment : 0 , 0 , 0 , 1 , 1 , 0 , 0 , ... 1 , 1\n",
    "- position embedding : 1 , 1 , 1 , 1 , 1 , 1 , 1 , ... 1 , 1\n",
    "\n",
    "[입력 전처리]\n",
    "- 문장 분리\n",
    "- BERT 입력 형식 변환\n",
    "- 입력 시퀀스 생성\n",
    "\n",
    "[BERT 인코더]\n",
    "- 문장 인코딩\n",
    "- 문맥 정보 포함"
   ]
  },
  {
   "attachments": {
    "72f5403f-61af-49a9-bcd4-3aa485f5fa5e.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7afa3205-2b27-40ed-8a44-9921628373ef",
   "metadata": {},
   "source": [
    "![image.png](attachment:72f5403f-61af-49a9-bcd4-3aa485f5fa5e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c809980-a4f2-4b9c-a93f-6d1820f560e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset을 BERT 모델을 이용하여 문장을 인코딩함\n",
    "class SummDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        data: pd.DataFrame, \n",
    "        tokenizer: BertTokenizer, # BERTokenizer로 토큰화\n",
    "        max_token_len: int = 512 # 최대 길이 512\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        tokenlist = []\n",
    "        for sent in data_row.article_original:\n",
    "            tokenlist.append(tokenizer(\n",
    "                text = sent,\n",
    "                add_special_tokens = True)) #, # Add '[CLS]' and '[SEP]'\n",
    "    \n",
    "        src = [] # 토크나이징 된 전체 문단\n",
    "        labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
    "        segs = []  #각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
    "        clss = []  #[CLS]토큰의 포지션값을 지정\n",
    "\n",
    "        odd = 0\n",
    "        for tkns in tokenlist:\n",
    "            if odd > 1 : odd = 0\n",
    "            clss = clss + [len(src)]\n",
    "            src = src + tkns['input_ids']\n",
    "            segs = segs + [odd] * len(tkns['input_ids'])\n",
    "            if tokenlist.index(tkns) in data_row.extractive :\n",
    "                labels = labels + [1]\n",
    "            else:\n",
    "                labels = labels + [0]\n",
    "            odd += 1\n",
    "        \n",
    "            #truncation\n",
    "            if len(src) == MAX_TOKEN_COUNT:\n",
    "                break\n",
    "            elif len(src) > MAX_TOKEN_COUNT:\n",
    "                src = src[:self.max_token_len - 1] + [src[-1]]\n",
    "                segs = segs[:self.max_token_len]\n",
    "                break\n",
    "    \n",
    "        #padding\n",
    "        if len(src) < MAX_TOKEN_COUNT:\n",
    "            src = src + [0]*(self.max_token_len - len(src))\n",
    "            segs = segs + [0]*(self.max_token_len - len(segs))\n",
    "            \n",
    "        if len(clss) < MAX_TOKEN_COUNT:\n",
    "            clss = clss + [-1]*(self.max_token_len - len(clss))\n",
    "        if len(labels) < MAX_TOKEN_COUNT:\n",
    "            labels = labels + [0]*(self.max_token_len - len(labels))\n",
    "\n",
    "        return dict(\n",
    "            src = torch.tensor(src),\n",
    "            segs = torch.tensor(segs),\n",
    "            clss = torch.tensor(clss),\n",
    "            labels= torch.FloatTensor(labels)\n",
    "        )\n",
    "\n",
    "\n",
    "# 데이터셋을 SummDataset 함수를 이용하여 모델 입력으로 들어가도록 변환\n",
    "# 이를 하나의 DataModule로 만든다.\n",
    "class SummDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, test_df, val_df, tokenizer, batch_size=1, max_token_len=512):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.val_df = val_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "        \n",
    "    # SummDataset을 이용하여 dataset을 요약모델 입력으로 들어가도록 변환\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = SummDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "        self.test_dataset = SummDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "    \n",
    "        self.val_dataset = SummDataset(\n",
    "            self.val_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
    "        )\n",
    "data_module = SummDataModule(\n",
    "  train_df,\n",
    "  test_df,  \n",
    "  val_df,\n",
    "  tokenizer,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3ed44-6b08-4a29-8bf3-e1fef57cd075",
   "metadata": {},
   "source": [
    "## MODEL\n",
    "kpfBERT를 pretrained_bert로 불러와서 후처리 레이어를 추가하여 문장추출 모델을 만든다.\n",
    "\n",
    "### PreSumm (추출요약 ver.)\n",
    "[문장 중요도 예측]\n",
    "- 문장의 벡터 표현을 입력으로 받아서, 각 문장이 요약문에 포함될 확률 예측\n",
    "\n",
    "[문장 선택]\n",
    "- 상위 문장을 선택하여 요약문 구성(3문장)\n",
    "\n",
    "[모델 구조]\n",
    "- PositionalEncoding: 입력 문장의 위치 정보를 추가 -> 모델이 문장 내 단어의 상대적 위치를 인식, self-Attention의 문맥 이해 향상\n",
    "- TransformerEncoderLayer:  Transformer 인코더 레이어를 정의\n",
    "- ExtTransformerEncoder: 여러 Transformer 인코더 레이어를 쌓아 확장된 Transformer 인코더를 정의\n",
    "- PositionwiseFeedForward: 두 개의 선형 레이어와 잔차 연결을 사용하는 FeedFoward 정의\n",
    "- MultiHeadedAttention: 여러 관점에서의 Self-Attention 수행 -> 문맥 이해 향상\n",
    "- Summarizer: 전체 요약 모델을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e443a18-650b-4965-a443-224df71c1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout, dim, max_len=5000):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) *\n",
    "                              -(math.log(10000.0) / dim)))\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, emb, step=None):\n",
    "        emb = emb * math.sqrt(self.dim)\n",
    "        if (step):\n",
    "            emb = emb + self.pe[:, step][:, None, :]\n",
    "\n",
    "        else:\n",
    "            emb = emb + self.pe[:, :emb.size(1)]\n",
    "        emb = self.dropout(emb)\n",
    "        return emb\n",
    "\n",
    "    def get_emb(self, emb):\n",
    "        return self.pe[:, :emb.size(1)]\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, d_ff, dropout):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadedAttention(\n",
    "            heads, d_model, dropout=dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, iter, query, inputs, mask):\n",
    "        if (iter != 0):\n",
    "            input_norm = self.layer_norm(inputs)\n",
    "        else:\n",
    "            input_norm = inputs\n",
    "\n",
    "        mask = mask.unsqueeze(1)\n",
    "        context = self.self_attn(input_norm, input_norm, input_norm,\n",
    "                                 mask=mask)\n",
    "        out = self.dropout(context) + inputs\n",
    "        return self.feed_forward(out)\n",
    "class ExtTransformerEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size=768, d_ff=2048, heads=8, dropout=0.2, num_inter_layers=2):\n",
    "        super(ExtTransformerEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_inter_layers = num_inter_layers\n",
    "        self.pos_emb = PositionalEncoding(dropout, hidden_size)\n",
    "        self.transformer_inter = nn.ModuleList(\n",
    "            [TransformerEncoderLayer(hidden_size, heads, d_ff, dropout)\n",
    "            for _ in range(num_inter_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.wo = nn.Linear(hidden_size, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, top_vecs, mask):\n",
    "        \"\"\" See :obj:`EncoderBase.forward()`\"\"\"\n",
    "\n",
    "        batch_size, n_sents = top_vecs.size(0), top_vecs.size(1)\n",
    "        pos_emb = self.pos_emb.pe[:, :n_sents]\n",
    "        x = top_vecs * mask[:, :, None].float()\n",
    "        x = x + pos_emb\n",
    "\n",
    "        for i in range(self.num_inter_layers):\n",
    "            x = self.transformer_inter[i](i, x, x, ~mask) \n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        sent_scores = self.sigmoid(self.wo(x))\n",
    "        sent_scores = sent_scores.squeeze(-1) * mask.float()\n",
    "\n",
    "        return sent_scores\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\" A two-layer Feed-Forward-Network with residual layer norm.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): the size of input for the first-layer of the FFN.\n",
    "        d_ff (int): the hidden layer size of the second-layer\n",
    "            of the FNN.\n",
    "        dropout (float): dropout probability in :math:`[0, 1)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def gelu(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        inter = self.dropout_1(self.gelu(self.w_1(self.layer_norm(x))))\n",
    "        output = self.dropout_2(self.w_2(inter))\n",
    "        return output + x\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention module from\n",
    "    \"Attention is All You Need\"\n",
    "    :cite:`DBLP:journals/corr/VaswaniSPUJGKP17`.\n",
    "\n",
    "    Similar to standard `dot` attention but uses\n",
    "    multiple attention distributions simulataneously\n",
    "    to select relevant items.\n",
    "\n",
    "    .. mermaid::\n",
    "\n",
    "       graph BT\n",
    "          A[key]\n",
    "          B[value]\n",
    "          C[query]\n",
    "          O[output]\n",
    "          subgraph Attn\n",
    "            D[Attn 1]\n",
    "            E[Attn 2]\n",
    "            F[Attn N]\n",
    "          end\n",
    "          A --> D\n",
    "          C --> D\n",
    "          A --> E\n",
    "          C --> E\n",
    "          A --> F\n",
    "          C --> F\n",
    "          D --> O\n",
    "          E --> O\n",
    "          F --> O\n",
    "          B --> O\n",
    "\n",
    "    Also includes several additional tricks.\n",
    "\n",
    "    Args:\n",
    "       head_count (int): number of parallel heads\n",
    "       model_dim (int): the dimension of keys/values/queries,\n",
    "           must be divisible by head_count\n",
    "       dropout (float): dropout parameter\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, head_count, model_dim, dropout=0.1, use_final_linear=True):\n",
    "        assert model_dim % head_count == 0\n",
    "        self.dim_per_head = model_dim // head_count\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.head_count = head_count\n",
    "\n",
    "        self.linear_keys = nn.Linear(model_dim,\n",
    "                                     head_count * self.dim_per_head)\n",
    "        self.linear_values = nn.Linear(model_dim,\n",
    "                                       head_count * self.dim_per_head)\n",
    "        self.linear_query = nn.Linear(model_dim,\n",
    "                                      head_count * self.dim_per_head)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.use_final_linear = use_final_linear\n",
    "        if (self.use_final_linear):\n",
    "            self.final_linear = nn.Linear(model_dim, model_dim)\n",
    "\n",
    "    def forward(self, key, value, query, mask=None,\n",
    "                layer_cache=None, type=None, predefined_graph_1=None):\n",
    "        \"\"\"\n",
    "        Compute the context vector and the attention vectors.\n",
    "\n",
    "        Args:\n",
    "           key (`FloatTensor`): set of `key_len`\n",
    "                key vectors `[batch, key_len, dim]`\n",
    "           value (`FloatTensor`): set of `key_len`\n",
    "                value vectors `[batch, key_len, dim]`\n",
    "           query (`FloatTensor`): set of `query_len`\n",
    "                 query vectors  `[batch, query_len, dim]`\n",
    "           mask: binary mask indicating which keys have\n",
    "                 non-zero attention `[batch, query_len, key_len]`\n",
    "        Returns:\n",
    "           (`FloatTensor`, `FloatTensor`) :\n",
    "\n",
    "           * output context vectors `[batch, query_len, dim]`\n",
    "           * one of the attention vectors `[batch, query_len, key_len]`\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = key.size(0)\n",
    "        dim_per_head = self.dim_per_head\n",
    "        head_count = self.head_count\n",
    "        key_len = key.size(1)\n",
    "        query_len = query.size(1)\n",
    "\n",
    "        def shape(x):\n",
    "            \"\"\"  projection \"\"\"\n",
    "            return x.view(batch_size, -1, head_count, dim_per_head) \\\n",
    "                .transpose(1, 2)\n",
    "\n",
    "        def unshape(x):\n",
    "            \"\"\"  compute context \"\"\"\n",
    "            return x.transpose(1, 2).contiguous() \\\n",
    "                .view(batch_size, -1, head_count * dim_per_head)\n",
    "\n",
    "        # 1) Project key, value, and query.\n",
    "        if layer_cache is not None:\n",
    "            if type == \"self\":\n",
    "                query, key, value = self.linear_query(query), \\\n",
    "                                    self.linear_keys(query), \\\n",
    "                                    self.linear_values(query)\n",
    "\n",
    "                key = shape(key)\n",
    "                value = shape(value)\n",
    "\n",
    "                if layer_cache is not None:\n",
    "                    device = key.device\n",
    "                    if layer_cache[\"self_keys\"] is not None:\n",
    "                        key = torch.cat(\n",
    "                            (layer_cache[\"self_keys\"].to(device), key),\n",
    "                            dim=2)\n",
    "                    if layer_cache[\"self_values\"] is not None:\n",
    "                        value = torch.cat(\n",
    "                            (layer_cache[\"self_values\"].to(device), value),\n",
    "                            dim=2)\n",
    "                    layer_cache[\"self_keys\"] = key\n",
    "                    layer_cache[\"self_values\"] = value\n",
    "            elif type == \"context\":\n",
    "                query = self.linear_query(query)\n",
    "                if layer_cache is not None:\n",
    "                    if layer_cache[\"memory_keys\"] is None:\n",
    "                        key, value = self.linear_keys(key), \\\n",
    "                                     self.linear_values(value)\n",
    "                        key = shape(key)\n",
    "                        value = shape(value)\n",
    "                    else:\n",
    "                        key, value = layer_cache[\"memory_keys\"], \\\n",
    "                                     layer_cache[\"memory_values\"]\n",
    "                    layer_cache[\"memory_keys\"] = key\n",
    "                    layer_cache[\"memory_values\"] = value\n",
    "                else:\n",
    "                    key, value = self.linear_keys(key), \\\n",
    "                                 self.linear_values(value)\n",
    "                    key = shape(key)\n",
    "                    value = shape(value)\n",
    "        else:\n",
    "            key = self.linear_keys(key)\n",
    "            value = self.linear_values(value)\n",
    "            query = self.linear_query(query)\n",
    "            key = shape(key)\n",
    "            value = shape(value)\n",
    "\n",
    "        query = shape(query)\n",
    "\n",
    "        key_len = key.size(2)\n",
    "        query_len = query.size(2)\n",
    "\n",
    "        # 2) Calculate and scale scores.\n",
    "        query = query / math.sqrt(dim_per_head)\n",
    "        scores = torch.matmul(query, key.transpose(2, 3))\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).expand_as(scores)\n",
    "            scores = scores.masked_fill(mask, -1e18) # how can i fix it to use fp16...\n",
    "\n",
    "        # 3) Apply attention dropout and compute context vectors.\n",
    "\n",
    "        attn = self.softmax(scores)\n",
    "\n",
    "        if (not predefined_graph_1 is None):\n",
    "            attn_masked = attn[:, -1] * predefined_graph_1\n",
    "            attn_masked = attn_masked / (torch.sum(attn_masked, 2).unsqueeze(2) + 1e-9)\n",
    "\n",
    "            attn = torch.cat([attn[:, :-1], attn_masked.unsqueeze(1)], 1)\n",
    "\n",
    "        drop_attn = self.dropout(attn)\n",
    "        if (self.use_final_linear):\n",
    "            context = unshape(torch.matmul(drop_attn, value))\n",
    "            output = self.final_linear(context)\n",
    "            return output\n",
    "        else:\n",
    "            context = torch.matmul(drop_attn, value)\n",
    "            return context\n",
    "\n",
    "class Summarizer(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.max_pos = 512\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME) #, return_dict=True)\n",
    "        self.ext_layer = ExtTransformerEncoder()\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.loss = nn.BCELoss(reduction='none')\n",
    "    \n",
    "        for p in self.ext_layer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, src, segs, clss, labels=None): #, input_ids, attention_mask, labels=None):\n",
    "        \n",
    "        mask_src = ~(src == 0) #1 - (src == 0)\n",
    "        mask_cls = ~(clss == -1) #1 - (clss == -1)\n",
    "\n",
    "        top_vec = self.bert(src, token_type_ids=segs, attention_mask=mask_src)\n",
    "        top_vec = top_vec.last_hidden_state\n",
    "        \n",
    "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n",
    "        sents_vec = sents_vec * mask_cls[:, :, None].float()\n",
    "\n",
    "        sent_scores = self.ext_layer(sents_vec, mask_cls).squeeze(-1)\n",
    "        \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.loss(sent_scores, labels)\n",
    "            \n",
    "            loss = (loss * mask_cls.float()).sum() / len(labels)\n",
    "        \n",
    "        return loss, sent_scores\n",
    "    \n",
    "    def step(self, batch):\n",
    "\n",
    "        src = batch['src']\n",
    "        if len(batch['labels']) > 0 :\n",
    "            labels = batch['labels']\n",
    "        else:\n",
    "            labels = None\n",
    "        segs = batch['segs']\n",
    "        clss = batch['clss']\n",
    "        \n",
    "        loss, sent_scores = self(src, segs, clss, labels)    \n",
    "        \n",
    "        return loss, sent_scores, labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        loss, sent_scores, labels = self.step(batch)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
    "\n",
    "    def acc_loss(self, outputs):\n",
    "        total_loss = 0\n",
    "        hit_cnt = 0\n",
    "        for outp in outputs:\n",
    "            labels = outp['labels'].cpu()\n",
    "            predictions, idxs = outp['predictions'].cpu().sort()\n",
    "            loss = outp['loss'].cpu()\n",
    "            for label, idx in zip(labels, idxs):\n",
    "                for i in range(1,3):\n",
    "                    if label[idx[-i-1]] == 1 : \n",
    "                        hit_cnt += 1\n",
    "\n",
    "            total_loss += loss\n",
    "            \n",
    "        avg_loss = total_loss / len(outputs)\n",
    "        acc = hit_cnt / (3*len(outputs)*len(labels))\n",
    "        \n",
    "        return acc, avg_loss\n",
    "        \n",
    "    def training_epoch_end(self, outputs):\n",
    "        \n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "        \n",
    "        print('acc:', acc, 'avg_loss:', avg_loss)\n",
    "        \n",
    "        self.log('avg_train_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "        \n",
    "        print('val_acc:', acc, 'avg_val_loss:', avg_loss)\n",
    "        \n",
    "        self.log('avg_val_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        \n",
    "        acc, avg_loss = self.acc_loss(outputs)\n",
    "        \n",
    "        print('test_acc:', acc, 'avg_test_loss:', avg_loss)\n",
    "        \n",
    "        self.log('avg_test_loss', avg_loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "\n",
    "        steps_per_epoch=len(train_df) // BATCH_SIZE\n",
    "        total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "        \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=steps_per_epoch,\n",
    "            num_training_steps=total_training_steps\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=dict(\n",
    "                scheduler=scheduler,\n",
    "                interval='step'\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce3f50-f879-495b-a856-11b311b01c88",
   "metadata": {},
   "source": [
    "### 모델 컴파일 및 학습 (Compile and Train Model)\n",
    "\n",
    "- Fine Tuning\n",
    "- 가장 최적의 결과를 낸 모델을 checkpoints/best-checkpoint.ckpt 로 저장\n",
    "- lightning_logs/kpfBERT_Summary/version_x/ 하위에 fine-tuning 로그가 저장됨, x는 실행순서 번호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45192d76-e02b-410a-b1c4-bff6617f924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jinmang2/kpfbert and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b23d146-53a8-44a7-b37d-b60c93e00f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"avg_val_loss\",\n",
    "    mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27918148-3dc3-4470-ab47-b15a165c250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"kpfBERT_Summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbc17947-5d99-481d-9744-5a118d069b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='avg_val_loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03c03712-f00d-4fe8-8e4b-44d3aa6ce6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    "    gpus=1,\n",
    "    #progress_bar_refresh_rate=30\n",
    "#     precision=16, #소스 수정 또는 패키지 재설치 필요... 런타임 에러.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb39a907-c8a9-4dde-9916-78c007a09712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                  | Params\n",
      "----------------------------------------------------\n",
      "0 | bert      | BertModel             | 114 M \n",
      "1 | ext_layer | ExtTransformerEncoder | 11.0 M\n",
      "2 | loss      | BCELoss               | 0     \n",
      "----------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "500.230   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  1.16it/s]val_acc: 0.08333333333333333 avg_val_loss: tensor(23.4237)\n",
      "Epoch 0:  88%|████████▊ | 2898/3275 [07:06<00:55,  6.80it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]acc: 1.3412698412698412 avg_loss: tensor(5.2519)\n",
      "Epoch 0:  89%|████████▊ | 2899/3275 [07:09<00:55,  6.74it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/377 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 2901/3275 [07:10<00:55,  6.75it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▊ | 2903/3275 [07:10<00:55,  6.75it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▊ | 2905/3275 [07:10<00:54,  6.75it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2907/3275 [07:10<00:54,  6.75it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2909/3275 [07:10<00:54,  6.76it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2911/3275 [07:10<00:53,  6.76it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2913/3275 [07:10<00:53,  6.76it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2915/3275 [07:10<00:53,  6.76it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2917/3275 [07:11<00:52,  6.77it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2919/3275 [07:11<00:52,  6.77it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2921/3275 [07:11<00:52,  6.77it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2923/3275 [07:11<00:51,  6.78it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2925/3275 [07:11<00:51,  6.78it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2927/3275 [07:11<00:51,  6.78it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2929/3275 [07:11<00:51,  6.78it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  89%|████████▉ | 2931/3275 [07:11<00:50,  6.79it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|████████▉ | 2933/3275 [07:12<00:50,  6.79it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|████████▉ | 2935/3275 [07:12<00:50,  6.79it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|████████▉ | 2937/3275 [07:12<00:49,  6.79it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|████████▉ | 2939/3275 [07:12<00:49,  6.80it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|████████▉ | 2941/3275 [07:12<00:49,  6.80it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|████████▉ | 2943/3275 [07:12<00:48,  6.80it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|████████▉ | 2945/3275 [07:12<00:48,  6.81it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|████████▉ | 2947/3275 [07:12<00:48,  6.81it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|█████████ | 2949/3275 [07:12<00:47,  6.81it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|█████████ | 2951/3275 [07:13<00:47,  6.81it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|█████████ | 2953/3275 [07:13<00:47,  6.82it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|█████████ | 2955/3275 [07:13<00:46,  6.82it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|█████████ | 2957/3275 [07:13<00:46,  6.82it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|█████████ | 2959/3275 [07:13<00:46,  6.82it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|█████████ | 2961/3275 [07:13<00:45,  6.83it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  90%|█████████ | 2963/3275 [07:13<00:45,  6.83it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2965/3275 [07:14<00:45,  6.83it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2967/3275 [07:14<00:45,  6.83it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2969/3275 [07:14<00:44,  6.84it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2971/3275 [07:14<00:44,  6.84it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2973/3275 [07:14<00:44,  6.84it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2975/3275 [07:14<00:43,  6.84it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2977/3275 [07:14<00:43,  6.85it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2979/3275 [07:14<00:43,  6.85it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2981/3275 [07:15<00:42,  6.85it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2983/3275 [07:15<00:42,  6.85it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2985/3275 [07:15<00:42,  6.86it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████ | 2987/3275 [07:15<00:41,  6.86it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████▏| 2989/3275 [07:15<00:41,  6.86it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████▏| 2991/3275 [07:15<00:41,  6.87it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████▏| 2993/3275 [07:15<00:41,  6.87it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  91%|█████████▏| 2995/3275 [07:15<00:40,  6.87it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 2997/3275 [07:16<00:40,  6.87it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 2999/3275 [07:16<00:40,  6.88it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3001/3275 [07:16<00:39,  6.88it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3003/3275 [07:16<00:39,  6.88it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3005/3275 [07:16<00:39,  6.88it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3007/3275 [07:16<00:38,  6.89it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3009/3275 [07:16<00:38,  6.89it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3011/3275 [07:16<00:38,  6.89it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3013/3275 [07:17<00:38,  6.89it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3015/3275 [07:17<00:37,  6.90it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3017/3275 [07:17<00:37,  6.90it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3019/3275 [07:17<00:37,  6.90it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3021/3275 [07:17<00:36,  6.90it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3023/3275 [07:17<00:36,  6.91it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3025/3275 [07:17<00:36,  6.91it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3027/3275 [07:17<00:35,  6.91it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  92%|█████████▏| 3029/3275 [07:18<00:35,  6.91it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3031/3275 [07:18<00:35,  6.92it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3033/3275 [07:18<00:34,  6.92it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3035/3275 [07:18<00:34,  6.92it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3037/3275 [07:18<00:34,  6.93it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3039/3275 [07:18<00:34,  6.93it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3041/3275 [07:18<00:33,  6.93it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3043/3275 [07:18<00:33,  6.93it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3045/3275 [07:19<00:33,  6.94it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3047/3275 [07:19<00:32,  6.94it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3049/3275 [07:19<00:32,  6.94it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3051/3275 [07:19<00:32,  6.94it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3053/3275 [07:19<00:31,  6.95it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3055/3275 [07:19<00:31,  6.95it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3057/3275 [07:19<00:31,  6.95it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3059/3275 [07:19<00:31,  6.95it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  93%|█████████▎| 3061/3275 [07:20<00:30,  6.96it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▎| 3063/3275 [07:20<00:30,  6.96it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▎| 3065/3275 [07:20<00:30,  6.96it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▎| 3067/3275 [07:20<00:29,  6.96it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▎| 3069/3275 [07:20<00:29,  6.97it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3071/3275 [07:20<00:29,  6.97it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3073/3275 [07:20<00:28,  6.97it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3075/3275 [07:20<00:28,  6.97it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3077/3275 [07:21<00:28,  6.98it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3079/3275 [07:21<00:28,  6.98it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3081/3275 [07:21<00:27,  6.98it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3083/3275 [07:21<00:27,  6.98it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3085/3275 [07:21<00:27,  6.99it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3087/3275 [07:21<00:26,  6.99it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3089/3275 [07:21<00:26,  6.99it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3091/3275 [07:21<00:26,  7.00it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  94%|█████████▍| 3093/3275 [07:21<00:26,  7.00it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▍| 3095/3275 [07:22<00:25,  7.00it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▍| 3097/3275 [07:22<00:25,  7.00it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▍| 3099/3275 [07:22<00:25,  7.01it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▍| 3101/3275 [07:22<00:24,  7.01it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▍| 3103/3275 [07:22<00:24,  7.01it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▍| 3105/3275 [07:22<00:24,  7.01it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▍| 3107/3275 [07:22<00:23,  7.02it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▍| 3109/3275 [07:22<00:23,  7.02it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▍| 3111/3275 [07:23<00:23,  7.02it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▌| 3113/3275 [07:23<00:23,  7.02it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▌| 3115/3275 [07:23<00:22,  7.03it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▌| 3117/3275 [07:23<00:22,  7.03it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▌| 3119/3275 [07:23<00:22,  7.03it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▌| 3121/3275 [07:23<00:21,  7.03it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▌| 3123/3275 [07:23<00:21,  7.04it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▌| 3125/3275 [07:23<00:21,  7.04it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  95%|█████████▌| 3127/3275 [07:24<00:21,  7.04it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3129/3275 [07:24<00:20,  7.04it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3131/3275 [07:24<00:20,  7.05it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3133/3275 [07:24<00:20,  7.05it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3135/3275 [07:24<00:19,  7.05it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3137/3275 [07:24<00:19,  7.05it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3139/3275 [07:24<00:19,  7.06it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3141/3275 [07:25<00:18,  7.06it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3143/3275 [07:25<00:18,  7.06it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3145/3275 [07:25<00:18,  7.06it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3147/3275 [07:25<00:18,  7.07it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3149/3275 [07:25<00:17,  7.07it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▌| 3151/3275 [07:25<00:17,  7.07it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▋| 3153/3275 [07:25<00:17,  7.07it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▋| 3155/3275 [07:25<00:16,  7.08it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▋| 3157/3275 [07:25<00:16,  7.08it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  96%|█████████▋| 3159/3275 [07:26<00:16,  7.08it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3161/3275 [07:26<00:16,  7.08it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3163/3275 [07:26<00:15,  7.09it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3165/3275 [07:26<00:15,  7.09it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3167/3275 [07:26<00:15,  7.09it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3169/3275 [07:26<00:14,  7.09it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3171/3275 [07:26<00:14,  7.10it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3173/3275 [07:26<00:14,  7.10it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3175/3275 [07:27<00:14,  7.10it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3177/3275 [07:27<00:13,  7.10it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3179/3275 [07:27<00:13,  7.11it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3181/3275 [07:27<00:13,  7.11it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3183/3275 [07:27<00:12,  7.11it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3185/3275 [07:27<00:12,  7.11it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3187/3275 [07:27<00:12,  7.12it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3189/3275 [07:27<00:12,  7.12it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3191/3275 [07:28<00:11,  7.12it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  97%|█████████▋| 3193/3275 [07:28<00:11,  7.12it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3195/3275 [07:28<00:11,  7.13it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3197/3275 [07:28<00:10,  7.13it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3199/3275 [07:28<00:10,  7.13it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3201/3275 [07:28<00:10,  7.13it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3203/3275 [07:28<00:10,  7.14it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3205/3275 [07:28<00:09,  7.14it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3207/3275 [07:29<00:09,  7.14it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3209/3275 [07:29<00:09,  7.14it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3211/3275 [07:29<00:08,  7.15it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3213/3275 [07:29<00:08,  7.15it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3215/3275 [07:29<00:08,  7.15it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3217/3275 [07:29<00:08,  7.15it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3219/3275 [07:29<00:07,  7.16it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3221/3275 [07:29<00:07,  7.16it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3223/3275 [07:30<00:07,  7.16it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  98%|█████████▊| 3225/3275 [07:30<00:06,  7.16it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▊| 3227/3275 [07:30<00:06,  7.17it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▊| 3229/3275 [07:30<00:06,  7.17it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▊| 3231/3275 [07:30<00:06,  7.17it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▊| 3233/3275 [07:30<00:05,  7.17it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3235/3275 [07:30<00:05,  7.17it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3237/3275 [07:31<00:05,  7.18it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3239/3275 [07:31<00:05,  7.18it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3241/3275 [07:31<00:04,  7.18it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3243/3275 [07:31<00:04,  7.18it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3245/3275 [07:31<00:04,  7.19it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3247/3275 [07:31<00:03,  7.19it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3249/3275 [07:31<00:03,  7.19it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3251/3275 [07:31<00:03,  7.20it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3253/3275 [07:31<00:03,  7.20it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3255/3275 [07:32<00:02,  7.20it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0:  99%|█████████▉| 3257/3275 [07:32<00:02,  7.20it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0: 100%|█████████▉| 3259/3275 [07:32<00:02,  7.20it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0: 100%|█████████▉| 3261/3275 [07:32<00:01,  7.21it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0: 100%|█████████▉| 3263/3275 [07:32<00:01,  7.21it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0: 100%|█████████▉| 3265/3275 [07:32<00:01,  7.21it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0: 100%|█████████▉| 3267/3275 [07:32<00:01,  7.21it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0: 100%|█████████▉| 3269/3275 [07:32<00:00,  7.22it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0: 100%|█████████▉| 3271/3275 [07:33<00:00,  7.22it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0: 100%|█████████▉| 3273/3275 [07:33<00:00,  7.22it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]\n",
      "Epoch 0: 100%|██████████| 3275/3275 [07:33<00:00,  7.22it/s, loss=4.63, v_num=1, val_loss=23.40, avg_val_loss=23.40, train_loss=3.020]val_acc: 0.7475685234305924 avg_val_loss: tensor(4.4443)\n",
      "Epoch 0: 100%|██████████| 3275/3275 [07:33<00:00,  7.22it/s, loss=4.63, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.320, avg_train_loss=5.250]\n",
      "                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 2897: avg_val_loss reached 4.44431 (best 4.44431), saving model to \"checkpoints/best-checkpoint.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  88%|████████▊ | 2898/3275 [07:00<00:54,  6.90it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]acc: 1.5170232344145387 avg_loss: tensor(4.2152)\n",
      "Epoch 1:  89%|████████▊ | 2899/3275 [07:03<00:54,  6.84it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/377 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 2901/3275 [07:04<00:54,  6.84it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▊ | 2903/3275 [07:04<00:54,  6.84it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▊ | 2905/3275 [07:04<00:54,  6.85it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2907/3275 [07:04<00:53,  6.85it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2909/3275 [07:04<00:53,  6.85it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2911/3275 [07:04<00:53,  6.85it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2913/3275 [07:04<00:52,  6.86it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2915/3275 [07:04<00:52,  6.86it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2917/3275 [07:05<00:52,  6.86it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2919/3275 [07:05<00:51,  6.86it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2921/3275 [07:05<00:51,  6.87it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2923/3275 [07:05<00:51,  6.87it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2925/3275 [07:05<00:50,  6.87it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2927/3275 [07:05<00:50,  6.88it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2929/3275 [07:05<00:50,  6.88it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  89%|████████▉ | 2931/3275 [07:05<00:49,  6.88it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|████████▉ | 2933/3275 [07:06<00:49,  6.88it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|████████▉ | 2935/3275 [07:06<00:49,  6.89it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|████████▉ | 2937/3275 [07:06<00:49,  6.89it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|████████▉ | 2939/3275 [07:06<00:48,  6.89it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|████████▉ | 2941/3275 [07:06<00:48,  6.89it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|████████▉ | 2943/3275 [07:06<00:48,  6.90it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|████████▉ | 2945/3275 [07:06<00:47,  6.90it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|████████▉ | 2947/3275 [07:06<00:47,  6.90it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|█████████ | 2949/3275 [07:07<00:47,  6.91it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|█████████ | 2951/3275 [07:07<00:46,  6.91it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|█████████ | 2953/3275 [07:07<00:46,  6.91it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|█████████ | 2955/3275 [07:07<00:46,  6.91it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|█████████ | 2957/3275 [07:07<00:45,  6.92it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|█████████ | 2959/3275 [07:07<00:45,  6.92it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|█████████ | 2961/3275 [07:07<00:45,  6.92it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  90%|█████████ | 2963/3275 [07:07<00:45,  6.92it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2965/3275 [07:08<00:44,  6.93it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2967/3275 [07:08<00:44,  6.93it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2969/3275 [07:08<00:44,  6.93it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2971/3275 [07:08<00:43,  6.93it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2973/3275 [07:08<00:43,  6.94it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2975/3275 [07:08<00:43,  6.94it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2977/3275 [07:08<00:42,  6.94it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2979/3275 [07:08<00:42,  6.94it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2981/3275 [07:09<00:42,  6.95it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2983/3275 [07:09<00:42,  6.95it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2985/3275 [07:09<00:41,  6.95it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████ | 2987/3275 [07:09<00:41,  6.96it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████▏| 2989/3275 [07:09<00:41,  6.96it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████▏| 2991/3275 [07:09<00:40,  6.96it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████▏| 2993/3275 [07:09<00:40,  6.96it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  91%|█████████▏| 2995/3275 [07:09<00:40,  6.97it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 2997/3275 [07:10<00:39,  6.97it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 2999/3275 [07:10<00:39,  6.97it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3001/3275 [07:10<00:39,  6.97it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3003/3275 [07:10<00:38,  6.98it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3005/3275 [07:10<00:38,  6.98it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3007/3275 [07:10<00:38,  6.98it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3009/3275 [07:10<00:38,  6.98it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3011/3275 [07:10<00:37,  6.99it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3013/3275 [07:11<00:37,  6.99it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3015/3275 [07:11<00:37,  6.99it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3017/3275 [07:11<00:36,  7.00it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3019/3275 [07:11<00:36,  7.00it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3021/3275 [07:11<00:36,  7.00it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3023/3275 [07:11<00:35,  7.00it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3025/3275 [07:11<00:35,  7.01it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3027/3275 [07:11<00:35,  7.01it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  92%|█████████▏| 3029/3275 [07:12<00:35,  7.01it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3031/3275 [07:12<00:34,  7.01it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3033/3275 [07:12<00:34,  7.02it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3035/3275 [07:12<00:34,  7.02it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3037/3275 [07:12<00:33,  7.02it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3039/3275 [07:12<00:33,  7.02it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3041/3275 [07:12<00:33,  7.03it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3043/3275 [07:12<00:33,  7.03it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3045/3275 [07:13<00:32,  7.03it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3047/3275 [07:13<00:32,  7.03it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3049/3275 [07:13<00:32,  7.04it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3051/3275 [07:13<00:31,  7.04it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3053/3275 [07:13<00:31,  7.04it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3055/3275 [07:13<00:31,  7.04it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3057/3275 [07:13<00:30,  7.05it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3059/3275 [07:13<00:30,  7.05it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  93%|█████████▎| 3061/3275 [07:14<00:30,  7.05it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▎| 3063/3275 [07:14<00:30,  7.06it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▎| 3065/3275 [07:14<00:29,  7.06it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▎| 3067/3275 [07:14<00:29,  7.06it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▎| 3069/3275 [07:14<00:29,  7.06it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3071/3275 [07:14<00:28,  7.07it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3073/3275 [07:14<00:28,  7.07it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3075/3275 [07:14<00:28,  7.07it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3077/3275 [07:14<00:27,  7.07it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3079/3275 [07:15<00:27,  7.08it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3081/3275 [07:15<00:27,  7.08it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3083/3275 [07:15<00:27,  7.08it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3085/3275 [07:15<00:26,  7.08it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3087/3275 [07:15<00:26,  7.09it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3089/3275 [07:15<00:26,  7.09it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3091/3275 [07:15<00:25,  7.09it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  94%|█████████▍| 3093/3275 [07:15<00:25,  7.10it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▍| 3095/3275 [07:16<00:25,  7.10it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▍| 3097/3275 [07:16<00:25,  7.10it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▍| 3099/3275 [07:16<00:24,  7.10it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▍| 3101/3275 [07:16<00:24,  7.11it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▍| 3103/3275 [07:16<00:24,  7.11it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▍| 3105/3275 [07:16<00:23,  7.11it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▍| 3107/3275 [07:16<00:23,  7.11it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▍| 3109/3275 [07:16<00:23,  7.12it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▍| 3111/3275 [07:17<00:23,  7.12it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▌| 3113/3275 [07:17<00:22,  7.12it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▌| 3115/3275 [07:17<00:22,  7.12it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▌| 3117/3275 [07:17<00:22,  7.13it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▌| 3119/3275 [07:17<00:21,  7.13it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▌| 3121/3275 [07:17<00:21,  7.13it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▌| 3123/3275 [07:17<00:21,  7.13it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▌| 3125/3275 [07:17<00:21,  7.14it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  95%|█████████▌| 3127/3275 [07:18<00:20,  7.14it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3129/3275 [07:18<00:20,  7.14it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3131/3275 [07:18<00:20,  7.14it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3133/3275 [07:18<00:19,  7.15it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3135/3275 [07:18<00:19,  7.15it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3137/3275 [07:18<00:19,  7.15it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3139/3275 [07:18<00:19,  7.15it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3141/3275 [07:18<00:18,  7.16it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3143/3275 [07:19<00:18,  7.16it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3145/3275 [07:19<00:18,  7.16it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3147/3275 [07:19<00:17,  7.16it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3149/3275 [07:19<00:17,  7.17it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▌| 3151/3275 [07:19<00:17,  7.17it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▋| 3153/3275 [07:19<00:17,  7.17it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▋| 3155/3275 [07:19<00:16,  7.17it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▋| 3157/3275 [07:19<00:16,  7.18it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  96%|█████████▋| 3159/3275 [07:20<00:16,  7.18it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3161/3275 [07:20<00:15,  7.18it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3163/3275 [07:20<00:15,  7.18it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3165/3275 [07:20<00:15,  7.19it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3167/3275 [07:20<00:15,  7.19it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3169/3275 [07:20<00:14,  7.19it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3171/3275 [07:20<00:14,  7.19it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3173/3275 [07:20<00:14,  7.20it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3175/3275 [07:20<00:13,  7.20it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3177/3275 [07:21<00:13,  7.20it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3179/3275 [07:21<00:13,  7.20it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3181/3275 [07:21<00:13,  7.21it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3183/3275 [07:21<00:12,  7.21it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3185/3275 [07:21<00:12,  7.21it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3187/3275 [07:21<00:12,  7.22it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3189/3275 [07:21<00:11,  7.22it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3191/3275 [07:21<00:11,  7.22it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  97%|█████████▋| 3193/3275 [07:22<00:11,  7.22it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3195/3275 [07:22<00:11,  7.23it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3197/3275 [07:22<00:10,  7.23it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3199/3275 [07:22<00:10,  7.23it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3201/3275 [07:22<00:10,  7.23it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3203/3275 [07:22<00:09,  7.24it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3205/3275 [07:22<00:09,  7.24it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3207/3275 [07:22<00:09,  7.24it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3209/3275 [07:23<00:09,  7.24it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3211/3275 [07:23<00:08,  7.25it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3213/3275 [07:23<00:08,  7.25it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3215/3275 [07:23<00:08,  7.25it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3217/3275 [07:23<00:07,  7.25it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3219/3275 [07:23<00:07,  7.26it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3221/3275 [07:23<00:07,  7.26it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3223/3275 [07:23<00:07,  7.26it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  98%|█████████▊| 3225/3275 [07:24<00:06,  7.26it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▊| 3227/3275 [07:24<00:06,  7.27it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▊| 3229/3275 [07:24<00:06,  7.27it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▊| 3231/3275 [07:24<00:06,  7.27it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▊| 3233/3275 [07:24<00:05,  7.27it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3235/3275 [07:24<00:05,  7.28it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3237/3275 [07:24<00:05,  7.28it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3239/3275 [07:24<00:04,  7.28it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3241/3275 [07:25<00:04,  7.28it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3243/3275 [07:25<00:04,  7.29it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3245/3275 [07:25<00:04,  7.29it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3247/3275 [07:25<00:03,  7.29it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3249/3275 [07:25<00:03,  7.29it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3251/3275 [07:25<00:03,  7.30it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3253/3275 [07:25<00:03,  7.30it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3255/3275 [07:25<00:02,  7.30it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1:  99%|█████████▉| 3257/3275 [07:25<00:02,  7.30it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1: 100%|█████████▉| 3259/3275 [07:26<00:02,  7.31it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1: 100%|█████████▉| 3261/3275 [07:26<00:01,  7.31it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1: 100%|█████████▉| 3263/3275 [07:26<00:01,  7.31it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1: 100%|█████████▉| 3265/3275 [07:26<00:01,  7.31it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1: 100%|█████████▉| 3267/3275 [07:26<00:01,  7.32it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1: 100%|█████████▉| 3269/3275 [07:26<00:00,  7.32it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1: 100%|█████████▉| 3271/3275 [07:26<00:00,  7.32it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1: 100%|█████████▉| 3273/3275 [07:26<00:00,  7.32it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]\n",
      "Epoch 1: 100%|██████████| 3275/3275 [07:27<00:00,  7.33it/s, loss=4.04, v_num=1, val_loss=4.450, avg_val_loss=4.440, train_loss=3.050, avg_train_loss=5.250]val_acc: 0.7396109637488948 avg_val_loss: tensor(4.5490)\n",
      "Epoch 1: 100%|██████████| 3275/3275 [07:27<00:00,  7.32it/s, loss=4.04, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=2.690, avg_train_loss=4.220]\n",
      "                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 5795: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  88%|████████▊ | 2898/3275 [06:59<00:54,  6.90it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]acc: 1.656889809063722 avg_loss: tensor(3.6567)\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 2900/3275 [07:03<00:54,  6.86it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▊ | 2902/3275 [07:03<00:54,  6.86it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▊ | 2904/3275 [07:03<00:54,  6.86it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▊ | 2906/3275 [07:03<00:53,  6.86it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2908/3275 [07:03<00:53,  6.87it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2910/3275 [07:03<00:53,  6.87it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2912/3275 [07:03<00:52,  6.87it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2914/3275 [07:03<00:52,  6.87it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2916/3275 [07:04<00:52,  6.88it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2918/3275 [07:04<00:51,  6.88it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2920/3275 [07:04<00:51,  6.88it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2922/3275 [07:04<00:51,  6.88it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2924/3275 [07:04<00:50,  6.89it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2926/3275 [07:04<00:50,  6.89it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2928/3275 [07:04<00:50,  6.89it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  89%|████████▉ | 2930/3275 [07:04<00:50,  6.90it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|████████▉ | 2932/3275 [07:05<00:49,  6.90it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|████████▉ | 2934/3275 [07:05<00:49,  6.90it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|████████▉ | 2936/3275 [07:05<00:49,  6.90it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|████████▉ | 2938/3275 [07:05<00:48,  6.91it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|████████▉ | 2940/3275 [07:05<00:48,  6.91it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|████████▉ | 2942/3275 [07:05<00:48,  6.91it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|████████▉ | 2944/3275 [07:05<00:47,  6.91it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|████████▉ | 2946/3275 [07:05<00:47,  6.92it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|█████████ | 2948/3275 [07:05<00:47,  6.92it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|█████████ | 2950/3275 [07:06<00:46,  6.92it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|█████████ | 2952/3275 [07:06<00:46,  6.93it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|█████████ | 2954/3275 [07:06<00:46,  6.93it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|█████████ | 2956/3275 [07:06<00:46,  6.93it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|█████████ | 2958/3275 [07:06<00:45,  6.93it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|█████████ | 2960/3275 [07:06<00:45,  6.94it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  90%|█████████ | 2962/3275 [07:06<00:45,  6.94it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2964/3275 [07:06<00:44,  6.94it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2966/3275 [07:07<00:44,  6.94it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2968/3275 [07:07<00:44,  6.95it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2970/3275 [07:07<00:43,  6.95it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2972/3275 [07:07<00:43,  6.95it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2974/3275 [07:07<00:43,  6.96it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2976/3275 [07:07<00:42,  6.96it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2978/3275 [07:07<00:42,  6.96it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2980/3275 [07:07<00:42,  6.96it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2982/3275 [07:08<00:42,  6.97it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2984/3275 [07:08<00:41,  6.97it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2986/3275 [07:08<00:41,  6.97it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████ | 2988/3275 [07:08<00:41,  6.97it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████▏| 2990/3275 [07:08<00:40,  6.98it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████▏| 2992/3275 [07:08<00:40,  6.98it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████▏| 2994/3275 [07:08<00:40,  6.98it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  91%|█████████▏| 2996/3275 [07:08<00:39,  6.99it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 2998/3275 [07:09<00:39,  6.99it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3000/3275 [07:09<00:39,  6.99it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3002/3275 [07:09<00:39,  6.99it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3004/3275 [07:09<00:38,  7.00it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3006/3275 [07:09<00:38,  7.00it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3008/3275 [07:09<00:38,  7.00it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3010/3275 [07:09<00:37,  7.00it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3012/3275 [07:09<00:37,  7.01it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3014/3275 [07:10<00:37,  7.01it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3016/3275 [07:10<00:36,  7.01it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3018/3275 [07:10<00:36,  7.01it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3020/3275 [07:10<00:36,  7.02it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3022/3275 [07:10<00:36,  7.02it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3024/3275 [07:10<00:35,  7.02it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3026/3275 [07:10<00:35,  7.02it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  92%|█████████▏| 3028/3275 [07:10<00:35,  7.03it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3030/3275 [07:11<00:34,  7.03it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3032/3275 [07:11<00:34,  7.03it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3034/3275 [07:11<00:34,  7.04it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3036/3275 [07:11<00:33,  7.04it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3038/3275 [07:11<00:33,  7.04it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3040/3275 [07:11<00:33,  7.04it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3042/3275 [07:11<00:33,  7.05it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3044/3275 [07:11<00:32,  7.05it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3046/3275 [07:12<00:32,  7.05it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3048/3275 [07:12<00:32,  7.05it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3050/3275 [07:12<00:31,  7.06it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3052/3275 [07:12<00:31,  7.06it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3054/3275 [07:12<00:31,  7.06it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3056/3275 [07:12<00:31,  7.06it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3058/3275 [07:12<00:30,  7.07it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3060/3275 [07:12<00:30,  7.07it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  93%|█████████▎| 3062/3275 [07:13<00:30,  7.07it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▎| 3064/3275 [07:13<00:29,  7.07it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▎| 3066/3275 [07:13<00:29,  7.08it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▎| 3068/3275 [07:13<00:29,  7.08it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▎| 3070/3275 [07:13<00:28,  7.08it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3072/3275 [07:13<00:28,  7.08it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3074/3275 [07:13<00:28,  7.09it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3076/3275 [07:13<00:28,  7.09it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3078/3275 [07:14<00:27,  7.09it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3080/3275 [07:14<00:27,  7.09it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3082/3275 [07:14<00:27,  7.10it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3084/3275 [07:14<00:26,  7.10it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3086/3275 [07:14<00:26,  7.10it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3088/3275 [07:14<00:26,  7.10it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3090/3275 [07:14<00:26,  7.11it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3092/3275 [07:14<00:25,  7.11it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  94%|█████████▍| 3094/3275 [07:14<00:25,  7.11it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▍| 3096/3275 [07:15<00:25,  7.12it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▍| 3098/3275 [07:15<00:24,  7.12it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▍| 3100/3275 [07:15<00:24,  7.12it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▍| 3102/3275 [07:15<00:24,  7.12it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▍| 3104/3275 [07:15<00:23,  7.13it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▍| 3106/3275 [07:15<00:23,  7.13it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▍| 3108/3275 [07:15<00:23,  7.13it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▍| 3110/3275 [07:16<00:23,  7.13it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▌| 3112/3275 [07:16<00:22,  7.14it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▌| 3114/3275 [07:16<00:22,  7.14it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▌| 3116/3275 [07:16<00:22,  7.14it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▌| 3118/3275 [07:16<00:21,  7.14it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▌| 3120/3275 [07:16<00:21,  7.15it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▌| 3122/3275 [07:16<00:21,  7.15it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▌| 3124/3275 [07:16<00:21,  7.15it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  95%|█████████▌| 3126/3275 [07:16<00:20,  7.15it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3128/3275 [07:17<00:20,  7.16it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3130/3275 [07:17<00:20,  7.16it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3132/3275 [07:17<00:19,  7.16it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3134/3275 [07:17<00:19,  7.16it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3136/3275 [07:17<00:19,  7.17it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3138/3275 [07:17<00:19,  7.17it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3140/3275 [07:17<00:18,  7.17it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3142/3275 [07:17<00:18,  7.17it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3144/3275 [07:18<00:18,  7.18it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3146/3275 [07:18<00:17,  7.18it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3148/3275 [07:18<00:17,  7.18it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3150/3275 [07:18<00:17,  7.18it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▌| 3152/3275 [07:18<00:17,  7.19it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▋| 3154/3275 [07:18<00:16,  7.19it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▋| 3156/3275 [07:18<00:16,  7.19it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▋| 3158/3275 [07:18<00:16,  7.19it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  96%|█████████▋| 3160/3275 [07:19<00:15,  7.20it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3162/3275 [07:19<00:15,  7.20it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3164/3275 [07:19<00:15,  7.20it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3166/3275 [07:19<00:15,  7.20it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3168/3275 [07:19<00:14,  7.21it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3170/3275 [07:19<00:14,  7.21it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3172/3275 [07:19<00:14,  7.21it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3174/3275 [07:19<00:14,  7.21it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3176/3275 [07:20<00:13,  7.22it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3178/3275 [07:20<00:13,  7.22it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3180/3275 [07:20<00:13,  7.22it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3182/3275 [07:20<00:12,  7.22it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3184/3275 [07:20<00:12,  7.23it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3186/3275 [07:20<00:12,  7.23it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3188/3275 [07:20<00:12,  7.23it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3190/3275 [07:20<00:11,  7.23it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  97%|█████████▋| 3192/3275 [07:21<00:11,  7.24it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3194/3275 [07:21<00:11,  7.24it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3196/3275 [07:21<00:10,  7.24it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3198/3275 [07:21<00:10,  7.24it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3200/3275 [07:21<00:10,  7.25it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3202/3275 [07:21<00:10,  7.25it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3204/3275 [07:21<00:09,  7.25it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3206/3275 [07:21<00:09,  7.25it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3208/3275 [07:22<00:09,  7.26it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3210/3275 [07:22<00:08,  7.26it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3212/3275 [07:22<00:08,  7.26it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3214/3275 [07:22<00:08,  7.27it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3216/3275 [07:22<00:08,  7.27it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3218/3275 [07:22<00:07,  7.27it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3220/3275 [07:22<00:07,  7.27it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3222/3275 [07:22<00:07,  7.28it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  98%|█████████▊| 3224/3275 [07:22<00:07,  7.28it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▊| 3226/3275 [07:23<00:06,  7.28it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▊| 3228/3275 [07:23<00:06,  7.28it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▊| 3230/3275 [07:23<00:06,  7.28it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▊| 3232/3275 [07:23<00:05,  7.29it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▊| 3234/3275 [07:23<00:05,  7.29it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3236/3275 [07:23<00:05,  7.29it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3238/3275 [07:23<00:05,  7.29it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3240/3275 [07:24<00:04,  7.30it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3242/3275 [07:24<00:04,  7.30it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3244/3275 [07:24<00:04,  7.30it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3246/3275 [07:24<00:03,  7.30it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3248/3275 [07:24<00:03,  7.31it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3250/3275 [07:24<00:03,  7.31it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3252/3275 [07:24<00:03,  7.31it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3254/3275 [07:24<00:02,  7.31it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3256/3275 [07:24<00:02,  7.32it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2:  99%|█████████▉| 3258/3275 [07:25<00:02,  7.32it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2: 100%|█████████▉| 3260/3275 [07:25<00:02,  7.32it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2: 100%|█████████▉| 3262/3275 [07:25<00:01,  7.32it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2: 100%|█████████▉| 3264/3275 [07:25<00:01,  7.33it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2: 100%|█████████▉| 3266/3275 [07:25<00:01,  7.33it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2: 100%|█████████▉| 3268/3275 [07:25<00:00,  7.33it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2: 100%|█████████▉| 3270/3275 [07:25<00:00,  7.33it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2: 100%|█████████▉| 3272/3275 [07:25<00:00,  7.34it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Epoch 2: 100%|█████████▉| 3274/3275 [07:26<00:00,  7.34it/s, loss=3.61, v_num=1, val_loss=4.550, avg_val_loss=4.550, train_loss=4.030, avg_train_loss=4.220]\n",
      "Validating: 100%|█████████▉| 376/377 [00:23<00:00, 16.03it/s]\u001b[Aval_acc: 0.7360742705570292 avg_val_loss: tensor(4.6195)\n",
      "Epoch 2: 100%|██████████| 3275/3275 [07:26<00:00,  7.34it/s, loss=3.61, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=4.890, avg_train_loss=3.660]\n",
      "                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, step 8693: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  88%|████████▊ | 2898/3275 [06:59<00:54,  6.90it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]acc: 1.955371520588912 avg_loss: tensor(2.6011)\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 2900/3275 [07:02<00:54,  6.86it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▊ | 2902/3275 [07:03<00:54,  6.86it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▊ | 2904/3275 [07:03<00:54,  6.86it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▊ | 2906/3275 [07:03<00:53,  6.86it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2908/3275 [07:03<00:53,  6.87it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2910/3275 [07:03<00:53,  6.87it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2912/3275 [07:03<00:52,  6.87it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2914/3275 [07:03<00:52,  6.87it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2916/3275 [07:03<00:52,  6.88it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2918/3275 [07:04<00:51,  6.88it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2920/3275 [07:04<00:51,  6.88it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2922/3275 [07:04<00:51,  6.89it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2924/3275 [07:04<00:50,  6.89it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2926/3275 [07:04<00:50,  6.89it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2928/3275 [07:04<00:50,  6.89it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  89%|████████▉ | 2930/3275 [07:04<00:50,  6.90it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|████████▉ | 2932/3275 [07:04<00:49,  6.90it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|████████▉ | 2934/3275 [07:05<00:49,  6.90it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|████████▉ | 2936/3275 [07:05<00:49,  6.90it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|████████▉ | 2938/3275 [07:05<00:48,  6.91it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|████████▉ | 2940/3275 [07:05<00:48,  6.91it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|████████▉ | 2942/3275 [07:05<00:48,  6.91it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|████████▉ | 2944/3275 [07:05<00:47,  6.92it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|████████▉ | 2946/3275 [07:05<00:47,  6.92it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|█████████ | 2948/3275 [07:05<00:47,  6.92it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|█████████ | 2950/3275 [07:06<00:46,  6.92it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|█████████ | 2952/3275 [07:06<00:46,  6.93it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|█████████ | 2954/3275 [07:06<00:46,  6.93it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|█████████ | 2956/3275 [07:06<00:46,  6.93it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|█████████ | 2958/3275 [07:06<00:45,  6.93it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|█████████ | 2960/3275 [07:06<00:45,  6.94it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  90%|█████████ | 2962/3275 [07:06<00:45,  6.94it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2964/3275 [07:06<00:44,  6.94it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2966/3275 [07:07<00:44,  6.95it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2968/3275 [07:07<00:44,  6.95it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2970/3275 [07:07<00:43,  6.95it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2972/3275 [07:07<00:43,  6.95it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2974/3275 [07:07<00:43,  6.96it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2976/3275 [07:07<00:42,  6.96it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2978/3275 [07:07<00:42,  6.96it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2980/3275 [07:07<00:42,  6.96it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2982/3275 [07:08<00:42,  6.97it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2984/3275 [07:08<00:41,  6.97it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2986/3275 [07:08<00:41,  6.97it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████ | 2988/3275 [07:08<00:41,  6.97it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████▏| 2990/3275 [07:08<00:40,  6.98it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████▏| 2992/3275 [07:08<00:40,  6.98it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████▏| 2994/3275 [07:08<00:40,  6.98it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  91%|█████████▏| 2996/3275 [07:08<00:39,  6.98it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 2998/3275 [07:09<00:39,  6.99it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3000/3275 [07:09<00:39,  6.99it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3002/3275 [07:09<00:39,  6.99it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3004/3275 [07:09<00:38,  7.00it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3006/3275 [07:09<00:38,  7.00it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3008/3275 [07:09<00:38,  7.00it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3010/3275 [07:09<00:37,  7.00it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3012/3275 [07:09<00:37,  7.01it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3014/3275 [07:10<00:37,  7.01it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3016/3275 [07:10<00:36,  7.01it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3018/3275 [07:10<00:36,  7.01it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3020/3275 [07:10<00:36,  7.02it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3022/3275 [07:10<00:36,  7.02it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3024/3275 [07:10<00:35,  7.02it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3026/3275 [07:10<00:35,  7.02it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  92%|█████████▏| 3028/3275 [07:10<00:35,  7.03it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3030/3275 [07:11<00:34,  7.03it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3032/3275 [07:11<00:34,  7.03it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3034/3275 [07:11<00:34,  7.03it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3036/3275 [07:11<00:33,  7.04it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3038/3275 [07:11<00:33,  7.04it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3040/3275 [07:11<00:33,  7.04it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3042/3275 [07:11<00:33,  7.05it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3044/3275 [07:11<00:32,  7.05it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3046/3275 [07:12<00:32,  7.05it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3048/3275 [07:12<00:32,  7.05it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3050/3275 [07:12<00:31,  7.06it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3052/3275 [07:12<00:31,  7.06it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3054/3275 [07:12<00:31,  7.06it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3056/3275 [07:12<00:31,  7.06it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3058/3275 [07:12<00:30,  7.07it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3060/3275 [07:12<00:30,  7.07it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  93%|█████████▎| 3062/3275 [07:13<00:30,  7.07it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▎| 3064/3275 [07:13<00:29,  7.07it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▎| 3066/3275 [07:13<00:29,  7.08it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▎| 3068/3275 [07:13<00:29,  7.08it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▎| 3070/3275 [07:13<00:28,  7.08it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3072/3275 [07:13<00:28,  7.08it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3074/3275 [07:13<00:28,  7.09it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3076/3275 [07:13<00:28,  7.09it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3078/3275 [07:13<00:27,  7.09it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3080/3275 [07:14<00:27,  7.09it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3082/3275 [07:14<00:27,  7.10it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3084/3275 [07:14<00:26,  7.10it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3086/3275 [07:14<00:26,  7.10it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3088/3275 [07:14<00:26,  7.11it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3090/3275 [07:14<00:26,  7.11it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3092/3275 [07:14<00:25,  7.11it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  94%|█████████▍| 3094/3275 [07:14<00:25,  7.11it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▍| 3096/3275 [07:15<00:25,  7.12it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▍| 3098/3275 [07:15<00:24,  7.12it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▍| 3100/3275 [07:15<00:24,  7.12it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▍| 3102/3275 [07:15<00:24,  7.12it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▍| 3104/3275 [07:15<00:23,  7.13it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▍| 3106/3275 [07:15<00:23,  7.13it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▍| 3108/3275 [07:15<00:23,  7.13it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▍| 3110/3275 [07:15<00:23,  7.13it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▌| 3112/3275 [07:16<00:22,  7.14it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▌| 3114/3275 [07:16<00:22,  7.14it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▌| 3116/3275 [07:16<00:22,  7.14it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▌| 3118/3275 [07:16<00:21,  7.14it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▌| 3120/3275 [07:16<00:21,  7.15it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▌| 3122/3275 [07:16<00:21,  7.15it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▌| 3124/3275 [07:16<00:21,  7.15it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  95%|█████████▌| 3126/3275 [07:16<00:20,  7.15it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3128/3275 [07:17<00:20,  7.16it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3130/3275 [07:17<00:20,  7.16it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3132/3275 [07:17<00:19,  7.16it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3134/3275 [07:17<00:19,  7.16it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3136/3275 [07:17<00:19,  7.17it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3138/3275 [07:17<00:19,  7.17it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3140/3275 [07:17<00:18,  7.17it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3142/3275 [07:17<00:18,  7.17it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3144/3275 [07:18<00:18,  7.18it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3146/3275 [07:18<00:17,  7.18it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3148/3275 [07:18<00:17,  7.18it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3150/3275 [07:18<00:17,  7.18it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▌| 3152/3275 [07:18<00:17,  7.19it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▋| 3154/3275 [07:18<00:16,  7.19it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▋| 3156/3275 [07:18<00:16,  7.19it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▋| 3158/3275 [07:18<00:16,  7.19it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  96%|█████████▋| 3160/3275 [07:19<00:15,  7.20it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3162/3275 [07:19<00:15,  7.20it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3164/3275 [07:19<00:15,  7.20it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3166/3275 [07:19<00:15,  7.21it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3168/3275 [07:19<00:14,  7.21it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3170/3275 [07:19<00:14,  7.21it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3172/3275 [07:19<00:14,  7.21it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3174/3275 [07:19<00:13,  7.22it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3176/3275 [07:20<00:13,  7.22it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3178/3275 [07:20<00:13,  7.22it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3180/3275 [07:20<00:13,  7.22it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3182/3275 [07:20<00:12,  7.23it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3184/3275 [07:20<00:12,  7.23it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3186/3275 [07:20<00:12,  7.23it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3188/3275 [07:20<00:12,  7.23it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3190/3275 [07:20<00:11,  7.24it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  97%|█████████▋| 3192/3275 [07:20<00:11,  7.24it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3194/3275 [07:21<00:11,  7.24it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3196/3275 [07:21<00:10,  7.24it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3198/3275 [07:21<00:10,  7.25it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3200/3275 [07:21<00:10,  7.25it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3202/3275 [07:21<00:10,  7.25it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3204/3275 [07:21<00:09,  7.25it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3206/3275 [07:21<00:09,  7.26it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3208/3275 [07:21<00:09,  7.26it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3210/3275 [07:22<00:08,  7.26it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3212/3275 [07:22<00:08,  7.26it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3214/3275 [07:22<00:08,  7.27it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3216/3275 [07:22<00:08,  7.27it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3218/3275 [07:22<00:07,  7.27it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3220/3275 [07:22<00:07,  7.27it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3222/3275 [07:22<00:07,  7.28it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  98%|█████████▊| 3224/3275 [07:22<00:07,  7.28it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▊| 3226/3275 [07:23<00:06,  7.28it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▊| 3228/3275 [07:23<00:06,  7.28it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▊| 3230/3275 [07:23<00:06,  7.29it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▊| 3232/3275 [07:23<00:05,  7.29it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▊| 3234/3275 [07:23<00:05,  7.29it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3236/3275 [07:23<00:05,  7.29it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3238/3275 [07:23<00:05,  7.30it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3240/3275 [07:23<00:04,  7.30it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3242/3275 [07:24<00:04,  7.30it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3244/3275 [07:24<00:04,  7.30it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3246/3275 [07:24<00:03,  7.31it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3248/3275 [07:24<00:03,  7.31it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3250/3275 [07:24<00:03,  7.31it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3252/3275 [07:24<00:03,  7.31it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3254/3275 [07:24<00:02,  7.32it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3256/3275 [07:24<00:02,  7.32it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3:  99%|█████████▉| 3258/3275 [07:24<00:02,  7.32it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3: 100%|█████████▉| 3260/3275 [07:25<00:02,  7.32it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3: 100%|█████████▉| 3262/3275 [07:25<00:01,  7.33it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3: 100%|█████████▉| 3264/3275 [07:25<00:01,  7.33it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3: 100%|█████████▉| 3266/3275 [07:25<00:01,  7.33it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3: 100%|█████████▉| 3268/3275 [07:25<00:00,  7.33it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3: 100%|█████████▉| 3270/3275 [07:25<00:00,  7.34it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3: 100%|█████████▉| 3272/3275 [07:25<00:00,  7.34it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Epoch 3: 100%|█████████▉| 3274/3275 [07:25<00:00,  7.34it/s, loss=2.38, v_num=1, val_loss=4.620, avg_val_loss=4.620, train_loss=3.270, avg_train_loss=3.660]\n",
      "Validating: 100%|█████████▉| 376/377 [00:23<00:00, 16.36it/s]\u001b[Aval_acc: 0.6883289124668435 avg_val_loss: tensor(5.6843)\n",
      "Epoch 3: 100%|██████████| 3275/3275 [07:26<00:00,  7.34it/s, loss=2.38, v_num=1, val_loss=5.690, avg_val_loss=5.680, train_loss=3.710, avg_train_loss=2.600]\n",
      "                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 11591: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3275/3275 [07:26<00:00,  7.34it/s, loss=2.38, v_num=1, val_loss=5.690, avg_val_loss=5.680, train_loss=3.710, avg_train_loss=2.600]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46891ece-23e9-422a-8b44-c44003404d9b",
   "metadata": {},
   "source": [
    "### 모델 평가 (Evaluate Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de7f1aef-e304-463c-9b03-4a4bd4aff754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:  99%|█████████▉| 152/153 [00:09<00:00, 16.88it/s]test_acc: 0.7559912854030502 avg_test_loss: tensor(4.2882)\n",
      "Testing: 100%|██████████| 153/153 [00:09<00:00, 16.81it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_loss': 4.288243770599365, 'test_loss': 4.287829399108887}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 4.287829399108887, 'avg_test_loss': 4.288243770599365}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ba85f-4824-41f4-af85-03c8493513a7",
   "metadata": {},
   "source": [
    "## **4. 추론 (Inference)**\n",
    "\n",
    "1. 훈련한 요약 모델을 바탕으로 테스트 뉴스 데이터의 요약본 추출 및 임베딩\n",
    "3. 피어슨 상관관계를 이용하여 기존 뉴스 요약 임베딩 데이터와 비교 (threshold=0.55)\n",
    "4. 높은 유사도를 가진 뉴스 데이터(최대 100개)를 추출\n",
    "5. 테스트 뉴스의 단락 데이터 생성 및 임베딩\n",
    "6. 저장된 단락 임베딩 데이터와 테스트 뉴스의 단락 데이터를 이용하여 BERTopic으로 클러스터링 진행\n",
    "7. 클러스터링 결과 바탕으로 다른 뉴스 3개 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d2d22-653b-4bca-8172-3d12961413c3",
   "metadata": {},
   "source": [
    "##### 테스트 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72b9ada3-f20c-460c-ac4c-f9844ae0c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.zip 파일을 dataset 폴더에 압축을 풀어준다.\n",
    "zip_source_path = './test_dataset.zip'\n",
    "zip_target_path = './meta_data'\n",
    "\n",
    "extract_zip_file = zipfile.ZipFile(zip_source_path)\n",
    "extract_zip_file.extractall(zip_target_path)\n",
    " \n",
    "extract_zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77ded224-54e1-4747-9f1b-8ded8c8b975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b1e920-eddc-45bc-b888-e058ea92b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path='./meta_data/test_dataset/'\n",
    "\n",
    "test_name='test.json'\n",
    "with open(my_path+test_name, encoding='utf8') as f:\n",
    "    test_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cadd2e9-49f7-40c5-88c8-9e03ebc77d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_link=test_dataset['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aa736cf-1947-4608-be02-7f540b526d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://n.news.naver.com/mnews/article/022/0003937314?sid=100'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb2bfec2-4a70-478d-a61c-9f4a3bb978f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd0865-65a8-4a8d-938c-59f45849ecee",
   "metadata": {},
   "source": [
    "#### 기사 링크 바탕으로 기사 본문 크롤링해오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "428de2a1-b9fc-4128-9e54-e50ae0d2dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 함수 추가\n",
    "def preprocessing(d):  # 한국어 기사 본문 전처리 함수\n",
    "    d = d.lower()\n",
    "    d = re.sub(r'[a-z0-9\\-_.]{3,}@[a-z0-9\\-_.]{3,}(?:[.]?[a-z]{2})+', ' ', d)\n",
    "    d = re.sub(r'‘’ⓒ\\'\\\"“”…=□*◆:/_]', ' ', d)\n",
    "    d = re.sub(r'\\s+', ' ', d)\n",
    "    d = re.sub(r'^\\s|\\s$', '', d)\n",
    "    d = re.sub(r'[<*>_=\"/■□▷▶]', '', d)\n",
    "    return d\n",
    "\n",
    "\n",
    "def fetch_article_data(article_url):  # 기사 본문, 기자 정보 수집 함수\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    resp = requests.get(article_url, headers=headers)\n",
    "    if resp.status_code != 200:\n",
    "        return \"Failed to retrieve the article\"\n",
    "\n",
    "    article_dom = BeautifulSoup(resp.content, 'html.parser')\n",
    "\n",
    "    # 특정 선택자를 사용하여 기사 본문 추출\n",
    "    content_tag = article_dom.select_one(\n",
    "        'article#dic_area.go_trans._article_content')\n",
    "\n",
    "    content = preprocessing(content_tag.get_text(\n",
    "        strip=True)) if content_tag else ''\n",
    "\n",
    "    # 기자 정보 추출\n",
    "    reporter_tag = article_dom.select_one('div.byline span') or \\\n",
    "        article_dom.select_one('p.byline') or \\\n",
    "        article_dom.select_one('span.byline')\n",
    "\n",
    "    reporter = reporter_tag.get_text(strip=True) if reporter_tag else ''\n",
    "\n",
    "    article_data = {\n",
    "        \"link\": article_url,  # 기사 링크\n",
    "        \"article\": content,  # 기사 본문\n",
    "        \"reporter\": reporter  # 기자\n",
    "    }\n",
    "\n",
    "    return article_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573bf4d-647e-46e2-a025-211831a4cf58",
   "metadata": {},
   "source": [
    "#### 테스트 뉴스의 본문 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c315201-3b4f-49bf-939a-663e21f26a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_data = fetch_article_data(target_link)\n",
    "target_article = target_data['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7efca68-e8b8-4e80-ba69-c5daf2a29fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련법안 당론 채택 예고더불어민주당 이재명 대표가 민생회복지원금과 관련해 고수해오던 ‘보편 지원’ 주장을 내려놨다. 정부여당을 향해 “차등 지원도 수용하겠다”며 이른 시일 내 협의하자고 제안한 것이다. 하지만 여당은 ‘차등 지원’을 전제로 하더라도 여전히 민생회복지원금 자체에 부정적인 모습이다. 민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금 제도 시행을 촉구해왔다.이 대표는 29일 당 최고위원회의에서 “민생회복지원금은 소득 지원 효과도 있지만 지역·지방 소비를 늘려서 경제를 활성화하는 경제 정책이다. 반드시 지원해야 한다”며 “골목경제가 살아나면 정부여당 지지율도 올라가고 좋지 않냐”고 말했다.끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열린 최고위원회의에서 윤석열 대통령과 이종섭 전 국방부 장관의 통화 사실을 보도한 자료를 보며 정청래 최고위원과 대화하고 있다. 남제현 선임기자이 대표는 윤석열 대통령과 정부여당을 향해 “우리가 지원금을 반드시 (전 국민에게) 똑같이 지급하라는 주장을 더 이상 하지 않겠다”며 “우리가 지향하는 가치는 보편 지원에 있긴 하지만 굳이 어렵다면 차등 지원도 수용하겠다”고 했다. 그러면서 고소득층 대상 매칭 지원 등 구체적 방안도 제시했다. 이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫기 때문”이라며 “우리가 양보할 테니 경기도 살리고 민생도 살리는 정책을 수용해주시고, 구체적 내용은 신속하게 만나서 협의하면 좋겠다”고 했다.이번 제안은 이 대표의 ‘실용 정치’ 행보의 일환으로 해석된다. 연금개혁안에 이어 민생 관련 사안에 대한 책임정당 모습을 선점하기 위한 포석이기도 하다. 민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시 한 번 양보한 안을 냈다”며 “민생과 경제를 책임지는 대통령과 정부여당의 답이 있을 것”이라고 말했다. 이 대표는 여야가 연금개혁과 관련해 이견을 보이던 소득대체율과 관련해 여당안인 ‘44%안’을 수용하겠단 뜻을 밝히며 연금개혁 처리를 압박했지만, 대통령실과 여당이 협상에 응하지 않으면서 21대 국회 임기 내 연금개혁 처리가 불발된 터다.민주당은 30일 22대 국회 첫 의원총회를 열고 민생회복지원금 지급을 포함한 민생위기특별조치법을 당론으로 채택한 뒤 발의할 예정이다.끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열린 기자간담회에서 야당이 단독 처리한 5개 법안 중 세월호지원법을 제외한 4개 법안에 대통령의 재의요구권을 건의하겠다고 밝히고 있다. 남제현 선임기자다만 여당에선 이 대표 제안에 대해 부정적 기류가 여전히 강한 모습이다. 국민의힘 추경호 원내대표는 이날 기자간담회에서 이 대표 제안과 관련해 “민생회복지원금 관련해서는 입장을 여러 차례 말씀드렸다. 그걸로 대신하겠다”고 답했다. 국민의힘은 최근 민주당 진성준 정책위의장이 선별 지원 협의 가능성을 언급한 데 대해 “추경으로 빚내서 현금 지원하겠다는 발상은 결코 해결책이 될 수 없다”고 비판한 바 있다.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d809526-48a6-418d-9654-f45d681a899a",
   "metadata": {},
   "source": [
    "### 요약모델 이용해서 테스트 뉴스의 요약본 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43c0789e-380b-46e3-b1e3-d793a146c668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jinmang2/kpfbert and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 훈련된 요약 모델 로드\n",
    "trained_model = Summarizer.load_from_checkpoint(\n",
    "    'checkpoints/best-checkpoint.ckpt',\n",
    "    strict=False\n",
    ")\n",
    "trained_model.eval()\n",
    "trained_model.freeze()\n",
    "\n",
    "# 문장 분리 함수\n",
    "def data_process(text):\n",
    "    # 문장 분리 하고,\n",
    "    sents = kss.split_sentences(text)\n",
    "\n",
    "    # 데이터 가공하고,\n",
    "    tokenlist = []\n",
    "    for sent in sents:\n",
    "        tokenlist.append(tokenizer(\n",
    "            text=sent,\n",
    "            add_special_tokens=True))  # , # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "    src = []  # 토크나이징 된 전체 문단\n",
    "    labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
    "    segs = []  # 각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
    "    clss = []  # [CLS]토큰의 포지션값을 지정\n",
    "\n",
    "    odd = 0\n",
    "\n",
    "    for tkns in tokenlist:\n",
    "\n",
    "        if odd > 1:\n",
    "            odd = 0\n",
    "        clss = clss + [len(src)]\n",
    "        src = src + tkns['input_ids']\n",
    "        segs = segs + [odd] * len(tkns['input_ids'])\n",
    "        odd += 1\n",
    "\n",
    "        # truncation\n",
    "        if len(src) == MAX_TOKEN_COUNT:\n",
    "            break\n",
    "        elif len(src) > MAX_TOKEN_COUNT:\n",
    "            src = src[:MAX_TOKEN_COUNT - 1] + [src[-1]]\n",
    "            segs = segs[:MAX_TOKEN_COUNT]\n",
    "            break\n",
    "\n",
    "    # padding\n",
    "    if len(src) < MAX_TOKEN_COUNT:\n",
    "        src = src + [0]*(MAX_TOKEN_COUNT - len(src))\n",
    "        segs = segs + [0]*(MAX_TOKEN_COUNT - len(segs))\n",
    "\n",
    "    if len(clss) < MAX_TOKEN_COUNT:\n",
    "        clss = clss + [-1]*(MAX_TOKEN_COUNT - len(clss))\n",
    "\n",
    "    return dict(\n",
    "        sents=sents,  # 정답 출력을 위해...\n",
    "        src=torch.tensor(src),\n",
    "        segs=torch.tensor(segs),\n",
    "        clss=torch.tensor(clss),\n",
    "    )\n",
    "\n",
    "# 요약본 추출 함수\n",
    "def summarize_test(text):\n",
    "    data = data_process(text.replace('\\n', ''))\n",
    "\n",
    "    # trained_model에 넣어 결과값 반환\n",
    "    _, rtn = trained_model(data['src'].unsqueeze(\n",
    "        0), data['segs'].unsqueeze(0), data['clss'].unsqueeze(0))\n",
    "    rtn = rtn.squeeze()\n",
    "\n",
    "    # 예측 결과값을 받기 위한 프로세스\n",
    "    rtn_sort, idx = rtn.sort(descending=True)\n",
    "\n",
    "    rtn_sort = rtn_sort.tolist()\n",
    "    idx = idx.tolist()\n",
    "\n",
    "    end_idx = rtn_sort.index(0)\n",
    "\n",
    "    rtn_sort = rtn_sort[:end_idx]\n",
    "    idx = idx[:end_idx]\n",
    "\n",
    "    if len(idx) > 3:\n",
    "        rslt = idx[:3]\n",
    "    else:\n",
    "        rslt = idx\n",
    "\n",
    "    summ = []\n",
    "    for i, r in enumerate(rslt):\n",
    "        summ.append(data['sents'][r])\n",
    "\n",
    "    return summ\n",
    "\n",
    "# 요약본 결과 반환\n",
    "def summarize_article(target_article):\n",
    "    target_summary = summarize_test(target_article)\n",
    "    return target_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a830588-8981-48ce-9090-3085b48686be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: Oh! You have mecab in your environment. Kss will take this as a backend! :D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_summary=summarize_article(target_article)\n",
    "target_summary=\" \".join(target_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17f66461-d724-4949-8c4a-2b3feac1787e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련법안 당론 채택 예고더불어민주당 이재명 대표가 민생회복지원금과 관련해 고수해오던 ‘보편 지원’ 주장을 내려놨다. 정부여당을 향해 “차등 지원도 수용하겠다”며 이른 시일 내 협의하자고 제안한 것이다. 하지만 여당은 ‘차등 지원’을 전제로 하더라도 여전히 민생회복지원금 자체에 부정적인 모습이다.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7bf1b1-52d8-4ed1-a603-c48f62229000",
   "metadata": {},
   "source": [
    "### 추출한 요약모델 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42161209-4e8a-4c80-b546-be22aaf65126",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('bongsoo/kpf-sbert-128d-v1')  # 임베딩 모델\n",
    "model.max_seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1af141a-92a7-4bf1-adc3-7b33e81f9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_summary_embedding = model.encode(target_summary,normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f172ff5f-9e7f-48ff-a4c1-b1935580eef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_summary_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43486f44-c560-4690-9d59-2a170ff6b20a",
   "metadata": {},
   "source": [
    "### 테스트 요약 임베딩과 수집 기사 요약 임베딩 유사도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3804283-f46a-4957-954e-2a468cc1c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피어슨 상관계수 구하기\n",
    "def pearson_similarity(a, b):\n",
    "    return np.dot((a-np.mean(a)), (b-np.mean(b)))/((np.linalg.norm(a-np.mean(a)))*(np.linalg.norm(b-np.mean(b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00754be7-6bcd-4114-a2bf-4e8d1a5fefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피어슨 상관계수 기반으로 계산\n",
    "threshold = 0.55  # 최소 유사도 threshold\n",
    "similar_list = []\n",
    "for i in range(len(summary_embedding_dataset)):\n",
    "    similarity = pearson_similarity(target_summary_embedding, summary_embedding_dataset[i])\n",
    "\n",
    "    if similarity > threshold:\n",
    "        similar_list.append((similarity, i)) # threshold 이상이면 유사한 기사 리스트에 추가\n",
    "\n",
    "# 유사도 기준 내림차순 정렬\n",
    "sorted_similar_list = sorted(similar_list, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# 100개 이상이면 100개만 추려서 반환\n",
    "if len(similar_list) > 100:\n",
    "    similar_index_list=[item[1] for item in sorted_similar_list[:100]]\n",
    "\n",
    "# 100개 이하면 모두 반환\n",
    "else:\n",
    "    similar_index_list=[item[1] for item in sorted_similar_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2123b84-08ea-4116-99a1-58d138a6ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5523, 5532, 5525, 5530, 5545, 5527, 5544, 5542, 6280, 5721, 5619, 5540, 5751, 5849, 6214, 5974, 3921, 5538, 5853, 6120, 5992, 5960, 5776, 5990, 5878, 6129, 6315, 5938, 5707, 6140, 5732, 6048, 6376, 6099, 5882, 5533, 4890, 5936, 5625, 5631, 5621, 6124, 5594, 6066, 6217, 5943, 5675, 5807, 5697, 5877, 6395, 5955, 5578, 5976]\n"
     ]
    }
   ],
   "source": [
    "print(similar_index_list) # 유사한 기사들의 index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d41dd5-41c5-4920-9cd0-8c9f559fb79c",
   "metadata": {},
   "source": [
    "### 테스트 기사의 단락 생성\n",
    "- 1 단락 = 3 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f2ac48c-62dd-4f3c-a21d-5d5be341790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_paragraphs(article, sentences_per_paragraph=3):\n",
    "    sentences = kss.split_sentences(article)\n",
    "    paragraphs = []\n",
    "    paragraph = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 20:\n",
    "            # 보통 한 줄에 20자 정도 넘어가야 유의미한 정보가 포함된 문장임\n",
    "            paragraph.append(sentence)\n",
    "        if len(paragraph) == sentences_per_paragraph:  # 3줄 이상이면\n",
    "            paragraphs.append(\" \".join(paragraph))  # 3줄을 하나로 합치기\n",
    "            paragraph = []\n",
    "\n",
    "        # 남아있는 문장들 중 20자가 넘어가면 단락으로 추가\n",
    "    if paragraph and len(paragraph) > 20:\n",
    "        paragraphs.append(\" \".join(paragraph))\n",
    "\n",
    "    return paragraphs  # 단락 데이터 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "471ad700-94a5-4393-a7e3-55bb7431e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_paragraphs=split_into_paragraphs(target_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50f668ea-7a21-4c3c-9469-f9e61ebc5824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련법안 당론 채택 예고더불어민주당 이재명 대표가 민생회복지원금과 관련해 고수해오던 ‘보편 지원’ 주장을 내려놨다. 정부여당을 향해 “차등 지원도 수용하겠다”며 이른 시일 내 협의하자고 제안한 것이다. 하지만 여당은 ‘차등 지원’을 전제로 하더라도 여전히 민생회복지원금 자체에 부정적인 모습이다.',\n",
       " '민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금 제도 시행을 촉구해왔다. 이 대표는 29일 당 최고위원회의에서 “민생회복지원금은 소득 지원 효과도 있지만 지역·지방 소비를 늘려서 경제를 활성화하는 경제 정책이다. 반드시 지원해야 한다”며 “골목경제가 살아나면 정부여당 지지율도 올라가고 좋지 않냐”고 말했다.',\n",
       " '끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열린 최고위원회의에서 윤석열 대통령과 이종섭 전 국방부 장관의 통화 사실을 보도한 자료를 보며 정청래 최고위원과 대화하고 있다. 남제현 선임기자이 대표는 윤석열 대통령과 정부여당을 향해 “우리가 지원금을 반드시 (전 국민에게) 똑같이 지급하라는 주장을 더 이상 하지 않겠다”며 “우리가 지향하는 가치는 보편 지원에 있긴 하지만 굳이 어렵다면 차등 지원도 수용하겠다”고 했다. 그러면서 고소득층 대상 매칭 지원 등 구체적 방안도 제시했다.',\n",
       " '이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫기 때문”이라며 “우리가 양보할 테니 경기도 살리고 민생도 살리는 정책을 수용해주시고, 구체적 내용은 신속하게 만나서 협의하면 좋겠다”고 했다. 이번 제안은 이 대표의 ‘실용 정치’ 행보의 일환으로 해석된다. 연금개혁안에 이어 민생 관련 사안에 대한 책임정당 모습을 선점하기 위한 포석이기도 하다.',\n",
       " '민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시 한 번 양보한 안을 냈다”며 “민생과 경제를 책임지는 대통령과 정부여당의 답이 있을 것”이라고 말했다. 이 대표는 여야가 연금개혁과 관련해 이견을 보이던 소득대체율과 관련해 여당안인 ‘44%안’을 수용하겠단 뜻을 밝히며 연금개혁 처리를 압박했지만, 대통령실과 여당이 협상에 응하지 않으면서 21대 국회 임기 내 연금개혁 처리가 불발된 터다. 민주당은 30일 22대 국회 첫 의원총회를 열고 민생회복지원금 지급을 포함한 민생위기특별조치법을 당론으로 채택한 뒤 발의할 예정이다.',\n",
       " '끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열린 기자간담회에서 야당이 단독 처리한 5개 법안 중 세월호지원법을 제외한 4개 법안에 대통령의 재의요구권을 건의하겠다고 밝히고 있다. 남제현 선임기자다만 여당에선 이 대표 제안에 대해 부정적 기류가 여전히 강한 모습이다. 국민의힘 추경호 원내대표는 이날 기자간담회에서 이 대표 제안과 관련해 “민생회복지원금 관련해서는 입장을 여러 차례 말씀드렸다. 그걸로 대신하겠다”고 답했다.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34448faf-b5cc-441f-b1c3-d093873670e4",
   "metadata": {},
   "source": [
    "#### pandas 형식으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46633ccb-f976-4cec-a009-87f000483d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_paragraph_data = []\n",
    "for data in target_paragraphs:\n",
    "    target_paragraph_data.append([-1]+[data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0356e419-3064-48af-9f8b-a95b508d2fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1,\n",
       "  '당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련법안 당론 채택 예고더불어민주당 이재명 대표가 민생회복지원금과 관련해 고수해오던 ‘보편 지원’ 주장을 내려놨다. 정부여당을 향해 “차등 지원도 수용하겠다”며 이른 시일 내 협의하자고 제안한 것이다. 하지만 여당은 ‘차등 지원’을 전제로 하더라도 여전히 민생회복지원금 자체에 부정적인 모습이다.'],\n",
       " [-1,\n",
       "  '민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금 제도 시행을 촉구해왔다. 이 대표는 29일 당 최고위원회의에서 “민생회복지원금은 소득 지원 효과도 있지만 지역·지방 소비를 늘려서 경제를 활성화하는 경제 정책이다. 반드시 지원해야 한다”며 “골목경제가 살아나면 정부여당 지지율도 올라가고 좋지 않냐”고 말했다.'],\n",
       " [-1,\n",
       "  '끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열린 최고위원회의에서 윤석열 대통령과 이종섭 전 국방부 장관의 통화 사실을 보도한 자료를 보며 정청래 최고위원과 대화하고 있다. 남제현 선임기자이 대표는 윤석열 대통령과 정부여당을 향해 “우리가 지원금을 반드시 (전 국민에게) 똑같이 지급하라는 주장을 더 이상 하지 않겠다”며 “우리가 지향하는 가치는 보편 지원에 있긴 하지만 굳이 어렵다면 차등 지원도 수용하겠다”고 했다. 그러면서 고소득층 대상 매칭 지원 등 구체적 방안도 제시했다.'],\n",
       " [-1,\n",
       "  '이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫기 때문”이라며 “우리가 양보할 테니 경기도 살리고 민생도 살리는 정책을 수용해주시고, 구체적 내용은 신속하게 만나서 협의하면 좋겠다”고 했다. 이번 제안은 이 대표의 ‘실용 정치’ 행보의 일환으로 해석된다. 연금개혁안에 이어 민생 관련 사안에 대한 책임정당 모습을 선점하기 위한 포석이기도 하다.'],\n",
       " [-1,\n",
       "  '민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시 한 번 양보한 안을 냈다”며 “민생과 경제를 책임지는 대통령과 정부여당의 답이 있을 것”이라고 말했다. 이 대표는 여야가 연금개혁과 관련해 이견을 보이던 소득대체율과 관련해 여당안인 ‘44%안’을 수용하겠단 뜻을 밝히며 연금개혁 처리를 압박했지만, 대통령실과 여당이 협상에 응하지 않으면서 21대 국회 임기 내 연금개혁 처리가 불발된 터다. 민주당은 30일 22대 국회 첫 의원총회를 열고 민생회복지원금 지급을 포함한 민생위기특별조치법을 당론으로 채택한 뒤 발의할 예정이다.'],\n",
       " [-1,\n",
       "  '끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열린 기자간담회에서 야당이 단독 처리한 5개 법안 중 세월호지원법을 제외한 4개 법안에 대통령의 재의요구권을 건의하겠다고 밝히고 있다. 남제현 선임기자다만 여당에선 이 대표 제안에 대해 부정적 기류가 여전히 강한 모습이다. 국민의힘 추경호 원내대표는 이날 기자간담회에서 이 대표 제안과 관련해 “민생회복지원금 관련해서는 입장을 여러 차례 말씀드렸다. 그걸로 대신하겠다”고 답했다.']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_paragraph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cc3ebd5-b135-41c1-9cc4-9dba8e315626",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_paragraph_data = pd.DataFrame(data=target_paragraph_data, columns=['index', 'paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bbcc6140-6f19-4683-bc3d-0de412081819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          paragraph\n",
       "0     -1  당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련...\n",
       "1     -1  민주당은 4·10 총선 때부터 ‘전 국민 25만원 지급’을 골자로 한 민생회복지원금...\n",
       "2     -1  끝까지 대결 정치더불어민주당 이재명 대표(오른쪽)가 29일 서울 여의도 국회에서 열...\n",
       "3     -1  이 대표는 그간 고수해온 ‘보편 지원’ 원칙을 철회한 데 대해 “안 하는 것보다 낫...\n",
       "4     -1  민주당 한민수 대변인은 이날 이 대표 제안에 대해 “이 대표가 연금개혁에 이어 다시...\n",
       "5     -1  끝까지 대결 정치국민의힘 추경호 원내대표(오른쪽)가 29일 서울 여의도 국회에서 열..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_paragraph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3f235-0f9a-459a-b1e4-77e2e83d332f",
   "metadata": {},
   "source": [
    "#### 위에서 구한 유사한 기사 인덱스를 이용해서 유사한 기사 데이터만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc2cec1d-04c9-4a16-9b4b-ddb1b38e8521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>과거에 비해 다소 살이 빠진 듯한 방시혁 하이브 의장의 모습이 소셜미디어(sns) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>방 의장은 전날 자신의 인스타그램 계정에 진과 함께 찍은 사진을 공개하며 “성공적인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>이날 개최한 팬 이벤트는 진의 전역 후 첫 행사이자, bts의 데뷔 11주년 행사였...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>방시혁 하이브 의장이 지난달 28일 오후 무함마드 빈 자예드 알 나흐얀 아랍에미리트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>줄곧 침묵을 유지하던 방 의장은 지난달 17일 법원에 제출한 탄원서를 통해 “한 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33648</th>\n",
       "      <td>6435</td>\n",
       "      <td>이 대표는 경남 창원 민주당 경남도당에서 열린 현장 선거대책위원회에서 같은 당 김경...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33649</th>\n",
       "      <td>6435</td>\n",
       "      <td>이 대표는 전날 자신이 내놓은 ‘국민 1인당 25만원씩(총 13조원 추산) 민생회복...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33650</th>\n",
       "      <td>6435</td>\n",
       "      <td>국민의힘은 세 자녀 등록금 면제 대상은 34만명이고, 들어갈 예산은 1조4500억원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33651</th>\n",
       "      <td>6435</td>\n",
       "      <td>세 자녀 가구에 지원되는 전기요금, 도시가스, 지역난방비 감면을 두 자녀 가구로 확...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33652</th>\n",
       "      <td>6436</td>\n",
       "      <td>○…더불어민주당 경기 하남갑에 전략공천된 추미애, 코미디 프로그램에 출연, 이재명과...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33653 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                          paragraph\n",
       "0          0  과거에 비해 다소 살이 빠진 듯한 방시혁 하이브 의장의 모습이 소셜미디어(sns) ...\n",
       "1          0  방 의장은 전날 자신의 인스타그램 계정에 진과 함께 찍은 사진을 공개하며 “성공적인...\n",
       "2          0  이날 개최한 팬 이벤트는 진의 전역 후 첫 행사이자, bts의 데뷔 11주년 행사였...\n",
       "3          0  방시혁 하이브 의장이 지난달 28일 오후 무함마드 빈 자예드 알 나흐얀 아랍에미리트...\n",
       "4          0  줄곧 침묵을 유지하던 방 의장은 지난달 17일 법원에 제출한 탄원서를 통해 “한 사...\n",
       "...      ...                                                ...\n",
       "33648   6435  이 대표는 경남 창원 민주당 경남도당에서 열린 현장 선거대책위원회에서 같은 당 김경...\n",
       "33649   6435  이 대표는 전날 자신이 내놓은 ‘국민 1인당 25만원씩(총 13조원 추산) 민생회복...\n",
       "33650   6435  국민의힘은 세 자녀 등록금 면제 대상은 34만명이고, 들어갈 예산은 1조4500억원...\n",
       "33651   6435  세 자녀 가구에 지원되는 전기요금, 도시가스, 지역난방비 감면을 두 자녀 가구로 확...\n",
       "33652   6436  ○…더불어민주당 경기 하남갑에 전략공천된 추미애, 코미디 프로그램에 출연, 이재명과...\n",
       "\n",
       "[33653 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e04d8eb-ce6c-4690-b64b-0c231b18f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_embedding_dataset=paragraph_embedding_dataset[paragraph_dataset['index'].isin(similar_index_list)] \n",
    "paragraph_dataset=paragraph_dataset[paragraph_dataset['index'].isin(similar_index_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62c21c7d-ac3c-47f9-abc8-532d92b36531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18165</th>\n",
       "      <td>3921</td>\n",
       "      <td>진성준 더불어민주당 정책위원회 의장이 이른바 ‘공공보건의료기관’ 확충과 ‘지역의사제...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18166</th>\n",
       "      <td>3921</td>\n",
       "      <td>의정갈등 증폭으로 인한 의료 현장의 혼란과 국민의 불편·불안이 아주 극심해질 것이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23410</th>\n",
       "      <td>4890</td>\n",
       "      <td>박민수 보건복지부 제2차관이 (의과대학 증원 문제는) 의정 갈등이 아닌 국민과 특권...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23411</th>\n",
       "      <td>4890</td>\n",
       "      <td>박 차관은 의료계와의 대화가 잘 안되는 이유는 의료계의 대화 조건 때문이라고 지적했...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23412</th>\n",
       "      <td>4890</td>\n",
       "      <td>의사 총파업 예고에 대해서는 현장에서 환자를 위해 묵묵히 일하는 대다수 의료진들의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33352</th>\n",
       "      <td>6395</td>\n",
       "      <td>윤 대통령은 여당인 국민의힘이 이번 총선에서 108석에 그치면서 제1야당인 민주당의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33353</th>\n",
       "      <td>6395</td>\n",
       "      <td>대통령실 관계자는 “일·북, 미·북 관계 개선에 대해 유연한 태도를 주문하는 건의도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33354</th>\n",
       "      <td>6395</td>\n",
       "      <td>윤 대통령과 이 대표의 회동 합의까지 상황은 롤러코스터를 탔다. 이날 오전 이 대표...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33355</th>\n",
       "      <td>6395</td>\n",
       "      <td>이 대표가 윤 대통령을 향해 “당신이 상대해야 할 야권의 리더는 이재명”이라는 메시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33356</th>\n",
       "      <td>6395</td>\n",
       "      <td>윤 대통령이 비명·친문계와 손을 잡고 이 대표를 고립시키는 정계 개편을 시도할 경우...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                          paragraph\n",
       "18165   3921  진성준 더불어민주당 정책위원회 의장이 이른바 ‘공공보건의료기관’ 확충과 ‘지역의사제...\n",
       "18166   3921  의정갈등 증폭으로 인한 의료 현장의 혼란과 국민의 불편·불안이 아주 극심해질 것이 ...\n",
       "23410   4890  박민수 보건복지부 제2차관이 (의과대학 증원 문제는) 의정 갈등이 아닌 국민과 특권...\n",
       "23411   4890  박 차관은 의료계와의 대화가 잘 안되는 이유는 의료계의 대화 조건 때문이라고 지적했...\n",
       "23412   4890  의사 총파업 예고에 대해서는 현장에서 환자를 위해 묵묵히 일하는 대다수 의료진들의 ...\n",
       "...      ...                                                ...\n",
       "33352   6395  윤 대통령은 여당인 국민의힘이 이번 총선에서 108석에 그치면서 제1야당인 민주당의...\n",
       "33353   6395  대통령실 관계자는 “일·북, 미·북 관계 개선에 대해 유연한 태도를 주문하는 건의도...\n",
       "33354   6395  윤 대통령과 이 대표의 회동 합의까지 상황은 롤러코스터를 탔다. 이날 오전 이 대표...\n",
       "33355   6395  이 대표가 윤 대통령을 향해 “당신이 상대해야 할 야권의 리더는 이재명”이라는 메시...\n",
       "33356   6395  윤 대통령이 비명·친문계와 손을 잡고 이 대표를 고립시키는 정계 개편을 시도할 경우...\n",
       "\n",
       "[356 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65ba2054-fce7-4a14-8214-6c4385fa1f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08908042,  0.20798394, -0.06499963, ..., -0.25593156,\n",
       "        -0.20581357, -0.24641436],\n",
       "       [-0.3097833 , -0.14721525,  0.07676742, ..., -0.4218608 ,\n",
       "        -0.40678966, -0.24442568],\n",
       "       [-0.18602537,  0.03118506, -0.23421107, ..., -0.4586038 ,\n",
       "        -0.18968455, -0.12873745],\n",
       "       ...,\n",
       "       [-0.2835967 ,  0.06727279, -0.2279469 , ...,  0.00244158,\n",
       "        -0.49878109, -0.21334545],\n",
       "       [-0.33893758, -0.02922696, -0.00344811, ..., -0.04495711,\n",
       "        -0.33378547,  0.02141661],\n",
       "       [-0.2819834 , -0.13019925, -0.04943895, ...,  0.02847405,\n",
       "        -0.29306567, -0.3358939 ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_embedding_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d82b8ae-716b-4c24-935e-52cb744b4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embeddings = model.encode(target_paragraph_data['paragraph'].tolist())  # 현재 읽고 있는 기사 단락 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5b6c739-ac3e-4ec1-915c-3ea90a9dd987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 128)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68abd510-695d-4d01-8f40-3d37daa550fc",
   "metadata": {},
   "source": [
    "#### 현재 읽고 있는 기사 데이터와 유사한 기사 데이터를 합쳐서 훈련 데이터로 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13a0b8ef-61d4-461d-8e5d-3e4cc829a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paragraph_embeddings=np.vstack((target_embeddings, paragraph_embedding_dataset))\n",
    "train_paragraph_data = pd.concat([target_paragraph_data, paragraph_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43643edc-7c73-4479-92fa-1a7e4ae3883d",
   "metadata": {},
   "source": [
    "## BERTopic을 이용한 클러스터링\n",
    "\n",
    "### BERTopic\n",
    "- SBERT를 이용한 토픽 모델\n",
    "- UMAP 이용하여 임베딩 차원 축소 -> HDBSCAN을 이용하여 클러스터링: 의미적으로 유사한 문서 클러스터 생성\n",
    "- TF-IDF를 이용하여 토픽 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4de1a2f0-e893-47da-9b85-e12063f6b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTopic(embedding_model='bongsoo/kpf-sbert-128d-v1', min_topic_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35fec701-8762-4d4c-ad73-06d21e58d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = model.fit_transform(documents=train_paragraph_data['paragraph'], embeddings=train_paragraph_embeddings)  # 클러스터링 만들기\n",
    "train_paragraph_data['topic'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d5f16e4-383c-44e0-85bb-526e2bdb84dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 읽고 있는 기사의 토픽 모델링\n",
    "target_paragraph_data = pd.merge(target_paragraph_data, train_paragraph_data[['paragraph', 'topic']], on='paragraph', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ffdf1f2a-003a-401a-91d1-c27aadf027fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽이 -1, 0은 제외\n",
    "target_paragraph_data = target_paragraph_data[target_paragraph_data['topic'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354264b6-add8-4acf-aaa3-854c85cd772b",
   "metadata": {},
   "source": [
    "#### 결과 출력을 위한 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a9661d6-c271-4108-9bf8-0a25f8eff107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Topic\n"
     ]
    }
   ],
   "source": [
    "if len(target_paragraph_data)==0: # 만약 토픽이 없다면\n",
    "    print('No Topic')\n",
    "    various_news_index=similar_index_list # 유사한 기사 3개 출력\n",
    "\n",
    "else:\n",
    "    paragraph_dataset=pd.merge(paragraph_dataset, train_paragraph_data[['paragraph','topic']], on='paragraph', how='inner')\n",
    "    paragraph_dataset=paragraph_dataset[paragraph_dataset['topic']>0]\n",
    "\n",
    "    topic_embeddings=model.topic_embeddings_\n",
    "    topic_embeddings=topic_embeddings[1:]\n",
    "\n",
    "    target_topic = target_paragraph_data['topic'].value_counts().idxmax()\n",
    "    target_topic_embedding = topic_embeddings[target_topic]\n",
    "\n",
    "    num_topics = len(model.get_topic_freq()) - 1\n",
    "\n",
    "    # faiss를 이용해서 토픽 간 코사인 유사도 계산\n",
    "    index = faiss.IndexFlatIP(128)\n",
    "    faiss.normalize_L2(topic_embeddings)\n",
    "    index.add(topic_embeddings)\n",
    "    distances, indices = index.search(np.expand_dims(target_topic_embedding, axis=0), num_topics)\n",
    "\n",
    "    # 가장 유사도가 낮은 토픽 순으로 단락 정렬\n",
    "    indices = indices[0][::-1]\n",
    "    indices = np.delete(indices, np.where(indices == 0)[0][0])\n",
    "    paragraph_dataset['topic'] = pd.Categorical(paragraph_dataset['topic'], categories=indices, ordered=True)\n",
    "    paragraph_dataset = paragraph_dataset.sort_values('topic')\n",
    "\n",
    "\n",
    "\n",
    "    # 토픽이 3개 이상이면\n",
    "    if num_topics - 2 > 3:\n",
    "        index_counts = paragraph_dataset.groupby(\n",
    "            'topic')['index'].value_counts().rename('count').reset_index()\n",
    "        most_common_index_per_topic = index_counts.loc[index_counts.groupby('topic')[\n",
    "            'count'].idxmax()]\n",
    "        most_common_index_per_topic=most_common_index_per_topic.drop_duplicates(subset='index') # 중복 제거\n",
    "\n",
    "        various_news_index=most_common_index_per_topic['index'].tolist()\n",
    "\n",
    "    else: # 토픽이 3개 이하이면 나온 것 모두 반환\n",
    "        paragraph_dataset=paragraph_dataset.drop_duplicates(subset='index') #중복 제거\n",
    "        various_news_index=paragraph_dataset['index'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bcd75e-9a2d-460c-bd62-9bf0e6604489",
   "metadata": {},
   "source": [
    "#### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b417da6-d2fd-4ec1-9b9c-2981cc7446f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5523,\n",
       " 5532,\n",
       " 5525,\n",
       " 5530,\n",
       " 5545,\n",
       " 5527,\n",
       " 5544,\n",
       " 5542,\n",
       " 6280,\n",
       " 5721,\n",
       " 5619,\n",
       " 5540,\n",
       " 5751,\n",
       " 5849,\n",
       " 6214,\n",
       " 5974,\n",
       " 3921,\n",
       " 5538,\n",
       " 5853,\n",
       " 6120,\n",
       " 5992,\n",
       " 5960,\n",
       " 5776,\n",
       " 5990,\n",
       " 5878,\n",
       " 6129,\n",
       " 6315,\n",
       " 5938,\n",
       " 5707,\n",
       " 6140,\n",
       " 5732,\n",
       " 6048,\n",
       " 6376,\n",
       " 6099,\n",
       " 5882,\n",
       " 5533,\n",
       " 4890,\n",
       " 5936,\n",
       " 5625,\n",
       " 5631,\n",
       " 5621,\n",
       " 6124,\n",
       " 5594,\n",
       " 6066,\n",
       " 6217,\n",
       " 5943,\n",
       " 5675,\n",
       " 5807,\n",
       " 5697,\n",
       " 5877,\n",
       " 6395,\n",
       " 5955,\n",
       " 5578,\n",
       " 5976]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "various_news_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81c30b24-bdbe-4f8e-9c7d-b3bb697b55ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_link in news_dataset['link']:\n",
    "    same_news_index=news_dataset[news_dataset['link']==target_link].index\n",
    "    various_news_index.remove(same_news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5979db1-f87a-4dde-a848-1454c863bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "various_news=news_dataset.loc[various_news_index][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e6a49be-8a98-49a7-99fd-c837837de3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>5523</td>\n",
       "      <td>이재명 “민생지원금 25만원, 차등 지급도 수용”</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/022/000...</td>\n",
       "      <td>당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>5532</td>\n",
       "      <td>‘보편 지원’ 양보한 이재명…“민생지원금 안주는 것보단 나아”</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/022/000...</td>\n",
       "      <td>당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>5525</td>\n",
       "      <td>이재명 “민생지원금 차등 지원 수용”…'전국민 25만원'서 후퇴</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/011/000...</td>\n",
       "      <td>연금개혁·종부세 이어 유연한 정책 행보 눈길이재명 더불어민주당 대표가 29일 오전 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                title  \\\n",
       "5523   5523          이재명 “민생지원금 25만원, 차등 지급도 수용”   \n",
       "5532   5532   ‘보편 지원’ 양보한 이재명…“민생지원금 안주는 것보단 나아”   \n",
       "5525   5525  이재명 “민생지원금 차등 지원 수용”…'전국민 25만원'서 후퇴   \n",
       "\n",
       "                                                   link  \\\n",
       "5523  https://n.news.naver.com/mnews/article/022/000...   \n",
       "5532  https://n.news.naver.com/mnews/article/022/000...   \n",
       "5525  https://n.news.naver.com/mnews/article/011/000...   \n",
       "\n",
       "                                                article  \n",
       "5523  당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련...  \n",
       "5532  당정에 “구체안 신속 논의” 제안연금개혁안 이은 ‘실용 정치’ 포석野, 30일 관련...  \n",
       "5525  연금개혁·종부세 이어 유연한 정책 행보 눈길이재명 더불어민주당 대표가 29일 오전 ...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "various_news"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
